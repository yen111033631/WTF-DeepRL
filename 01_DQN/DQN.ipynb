{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WTF 深度强化学习教程 1. Deep Q-Network\n",
        "\n",
        "WTF 深度强化学习教程，帮助新人快速入门 Deep RL，算法使用pytorch 2.0版本实现。\n",
        "\n",
        "**推特**：[@WTFAcademy_](https://twitter.com/WTFAcademy_) ｜ [@0xAA_Science](https://twitter.com/0xAA_Science)\n",
        "\n",
        "**WTF Academy 社群：** [官网 wtf.academy](https://wtf.academy/) | [WTF Solidity 教程](https://github.com/AmazingAng/WTFSolidity) | [discord](https://discord.wtf.academy/) | [微信群申请](https://docs.google.com/forms/d/e/1FAIpQLSe4KGT8Sh6sJ7hedQRuIYirOoZK_85miz3dw7vA1-YjodgJ-A/viewform?usp=sf_link)\n",
        "\n",
        "所有代码和教程开源在 github: [github.com/AmazingAng/WTF-DeepRL](https://github.com/WTFAcademy/WTF-DeepRL)\n",
        "\n",
        "---\n",
        "\n",
        "这一讲，我们将尝试利用pytorch实现深度强化学习的开山之作 Deep Q-Network，DQN，推荐你先阅读 [DQN 论文](https://arxiv.org/abs/1312.5602)。\n",
        "\n",
        "## 0. 先修课程\n",
        "\n",
        "在开始之前，你需要先完成先修课程：\n",
        "\n",
        "1. 强化学习理论：推荐 Sutton 和 Barto 写的[强化学习圣经](http://incompleteideas.net/book/RLbook2020.pdf)。\n",
        "\n",
        "    ![](./img/1-1.png)\n",
        "\n",
        "2. 机器学习：你可以在网上找到很多机器学习的公开课，比如coursera上Andrew Ng的课程。\n",
        "\n",
        "3. python编程：网上你可以找到很多的python入门公开课，我推荐哈佛大学的CS50 python版。\n",
        "\n",
        "## 1. 深度强化学习中的元素\n",
        "\n",
        "强化学习研究的是智能体（Agent）和环境（Environment）交互中如何学习最优策略，以获得最大收益（Cumulative rewards）。Agent需要能够观察环境(observe)的到所处的状态，评判（value）状态下每个动作的价值，选出最优的动作（act）来和环境交互，同时通过从经验中学习不断改善自己的策略（learn from experience）。因此，observe，value，act和learn是强化学习Agent必不可少的元素。\n",
        "\n",
        "![](./img/1-2.png)\n",
        "\n",
        "如果我们给Agent写一个类，大体会长这样的：\n",
        "\n",
        "```python\n",
        "class Agent: \n",
        "\n",
        "    def __init__(self):\n",
        "        ...\n",
        "\n",
        "    def observe(self, observation):\n",
        "        ...\n",
        "        return state\n",
        "\n",
        "    def value(self, state,):\n",
        "        ...\n",
        "        return value_of_actions\n",
        "    \n",
        "    def act(value_of_actions):\n",
        "        ...\n",
        "        return selected_action\n",
        "    \n",
        "    def learn_from_experience(self, batch_size):\n",
        "        ...\n",
        "```\n",
        "\n",
        "这个教程中，我们会使用经典的Atari游戏来训练强化学习算法，下面我们探讨一下这几个函数在Atari环境中起到什么作用：\n",
        "\n",
        "- `observe`: 在Atari中，环境每一步给出的observation（84x84x1的array）可以直接作为state。那么observe()函数只需要把numpy array转换为torch tensor，方便模型后续使用就好了。在更复杂的partial observable环境，我们需要利用observation来推断所处的state，这时observe()函数会由更多功能。\n",
        "- `value`: 在DQN中，`value`函数主要是给出当前state下每个action的Q value，帮助智能体选择最优策略。\n",
        "- `act`: 在DQN中，根据`value`函数给出的Q值，采用epsilon greedy policy选出action。\n",
        "- `learn_from_experience`: 根据收集的经验计算TD Loss（temporal-difference loss），再通过梯度下降算法更新深度神经网络的参数，改善策略。其中TD Loss由Bellman Equation给出：\n",
        "\n",
        "    $$Loss_{TD}=R_t+\\gamma Q(s_{t+1},a_{t+1})−Q(s_t,a_t)$$\n",
        "\n",
        "下面，我们开始完成DQN算法。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 引入包\n",
        "你需要安装相应的包，然后在 jupyter notebook 中导入他们，如果你使用的是Google Colab Research，则需要安装`gym[atari]`和`autorom[accept-rom-license]`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yy1WnM9NroP",
        "outputId": "c6789b55-af8d-443e-ae3f-ad61d485f163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# 在 Google Colab Rsearch 中需要安装的库\n",
        "# !pip install gym[atari]\n",
        "# !pip install autorom[accept-rom-license]\n",
        "\n",
        "import gym, random, pickle, os.path, math, glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "import pdb\n",
        "\n",
        "from gym.wrappers import AtariPreprocessing, LazyFrames, FrameStack\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "print(USE_CUDA)\n",
        "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.cuda.FloatTensor"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function __main__.<lambda>(*args, **kwargs)>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Variable"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Atari游戏中的Pong\n",
        "\n",
        "Pong是Atari中一个仿真打乒乓球的游戏：玩家和电脑每人拿一个板子，接对方弹来的球，没接住的话，对方得一分，先得到21分的获胜。\n",
        "\n",
        "我们使用 DQN 论文中的设定，在丢失声明时会结束游戏，并且4帧画面会合并为1个输入，加快学习。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "TaTmabj6NroQ",
        "outputId": "f8ad7d9e-07b3-4ae7-9dd6-5ee3d63c15d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
            "[Powered by Stella]\n",
            "/home/neaf2080/.pyenv/versions/3.8.18/envs/RL_gym/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f230162ca60>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create and wrap the environment\n",
        "env = gym.make('PongNoFrameskip-v4')\n",
        "env = AtariPreprocessing(env,\n",
        "                         scale_obs=False,\n",
        "                         terminal_on_life_loss=True,\n",
        "                         )\n",
        "env = FrameStack(env, num_stack=4)\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "# env.render()\n",
        "test = env.reset()\n",
        "for i in range(100):\n",
        "    test = env.step(env.action_space.sample())[0]\n",
        "\n",
        "plt.imshow(test.__array__()[0,...])\n",
        "\n",
        "# env.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Deep-Q Network\n",
        "\n",
        "对于复杂的问题，state维度非常大，我们很难基于tabular method来判断每一个(state, action)的价值。这种情况下，我们利用function approximation方法，构建一个深度神经网络(Deep-Q Network, DQN)，来估计(state, action)的价值。value()中Deep-Q Network模块就是一个神经网络，输入是atari game中的一帧图像，输出是每个action的价值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X_yXh2wANroR"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, in_channels=4, num_actions=5):\n",
        "        \"\"\"\n",
        "        Initialize a deep Q-learning network as described in\n",
        "        https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf\n",
        "        Arguments:\n",
        "            in_channels: number of channel of input.\n",
        "                i.e The number of most recent frames stacked together as describe in the paper\n",
        "            num_actions: number of action-value to output, one-to-one correspondence to action in game.\n",
        "        \"\"\"\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
        "        self.fc5 = nn.Linear(512, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.fc4(x.reshape(x.size(0), -1)))\n",
        "        return self.fc5(x)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Memory\n",
        "因为深度神经网络收敛很慢，需要非常多的样本，如果只根据环境交互来训练网络，将非常的没效率。因此DQN引入了一个memory buffer来进行memory replay，就是把之前和环境交互的经验存下来，在训练时重复利用。memory buffer主要实现两个函数：`push`函数将经验存入，`sample`函数将经验取出用于训练。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pFHzSKOqNroS"
      },
      "outputs": [],
      "source": [
        "class Memory_Buffer(object):\n",
        "    def __init__(self, memory_size=100000):\n",
        "        self.buffer = []\n",
        "        self.memory_size = memory_size\n",
        "        self.next_idx = 0\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        data = (state, action, reward, next_state, done)\n",
        "        if len(self.buffer) <= self.memory_size: # buffer not full\n",
        "            self.buffer.append(data)\n",
        "        else: # buffer is full\n",
        "            self.buffer[self.next_idx] = data\n",
        "        self.next_idx = (self.next_idx + 1) % self.memory_size\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            idx = random.randint(0, self.size() - 1)\n",
        "            data = self.buffer[idx]\n",
        "            state, action, reward, next_state, done= data\n",
        "            states.append(state)\n",
        "            actions.append(action)\n",
        "            rewards.append(reward)\n",
        "            next_states.append(next_state)\n",
        "            dones.append(done)\n",
        "\n",
        "        return np.concatenate(states), actions, rewards, np.concatenate(next_states), dones\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Agent\n",
        "\n",
        "下面，我们要写最复杂的部分，实现基于DQN的智能体。我们分别实现了下列函数：\n",
        "\n",
        "- `__init__`: 初始化DQN智能体的参数和网络。\n",
        "- `observe`: 将Atari环境每一步返回的observation（numpy矩阵）转为状态（pytorch tensor）。\n",
        "- `value`: 返回状态的Q值。\n",
        "- `act`: 给定状态，根据epsilon greedy算法给出当前动作。\n",
        "- `sample_from_buffer`: 学习相关，从memory buffer抽样经验。\n",
        "- `compute_td_loss`: 学习相关，利用从memory buffer抽样的经验计算TD Loss。\n",
        "- `learn_from_experience`: 学习相关，利用TD Loss进行梯度下降，优化网络。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2VnmExe-NroS"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, in_channels = 1, action_space = [], USE_CUDA = False, memory_size = 10000, epsilon  = 1, lr = 1e-4):\n",
        "        self.epsilon = epsilon\n",
        "        self.action_space = action_space\n",
        "        self.memory_buffer = Memory_Buffer(memory_size)\n",
        "        self.DQN = DQN(in_channels = in_channels, num_actions = action_space.n)\n",
        "        self.DQN_target = DQN(in_channels = in_channels, num_actions = action_space.n)\n",
        "        self.DQN_target.load_state_dict(self.DQN.state_dict())\n",
        "\n",
        "        self.USE_CUDA = USE_CUDA\n",
        "        if USE_CUDA:\n",
        "            self.DQN = self.DQN.cuda()\n",
        "            self.DQN_target = self.DQN_target.cuda()\n",
        "        self.optimizer = optim.RMSprop(self.DQN.parameters(),lr=lr, eps=0.001, alpha=0.95)\n",
        "\n",
        "    def observe(self, lazyframe):\n",
        "        # from Lazy frame to tensor\n",
        "        state =  torch.from_numpy(lazyframe.__array__()[None]/255).float()\n",
        "        if self.USE_CUDA:\n",
        "            state = state.cuda()\n",
        "        return state\n",
        "\n",
        "    def value(self, state):\n",
        "        q_values = self.DQN(state)\n",
        "        return q_values\n",
        "\n",
        "    def act(self, state, epsilon = None):\n",
        "        \"\"\"\n",
        "        sample actions with epsilon-greedy policy\n",
        "        recap: with p = epsilon pick random action, else pick action with highest Q(s,a)\n",
        "        \"\"\"\n",
        "        if epsilon is None: epsilon = self.epsilon\n",
        "\n",
        "        q_values = self.value(state).cpu().detach().numpy()\n",
        "        if random.random()<epsilon:\n",
        "            aciton = random.randrange(self.action_space.n)\n",
        "        else:\n",
        "            aciton = q_values.argmax(1)[0]\n",
        "        return aciton\n",
        "\n",
        "    def compute_td_loss(self, states, actions, rewards, next_states, is_done, gamma=0.99):\n",
        "        \"\"\" Compute td loss using torch operations only. Use the formula above. \"\"\"\n",
        "        actions = torch.tensor(actions).long()    # shape: [batch_size]\n",
        "        rewards = torch.tensor(rewards, dtype =torch.float)  # shape: [batch_size]\n",
        "        is_done = torch.tensor(is_done).bool()  # shape: [batch_size]\n",
        "\n",
        "        if self.USE_CUDA:\n",
        "            actions = actions.cuda()\n",
        "            rewards = rewards.cuda()\n",
        "            is_done = is_done.cuda()\n",
        "\n",
        "        # get q-values for all actions in current states\n",
        "        predicted_qvalues = self.DQN(states)\n",
        "\n",
        "        # select q-values for chosen actions\n",
        "        predicted_qvalues_for_actions = predicted_qvalues[\n",
        "          range(states.shape[0]), actions\n",
        "        ]\n",
        "\n",
        "        # compute q-values for all actions in next states\n",
        "        predicted_next_qvalues = self.DQN_target(next_states) # YOUR CODE\n",
        "\n",
        "        # compute V*(next_states) using predicted next q-values\n",
        "        next_state_values =  predicted_next_qvalues.max(-1)[0] # YOUR CODE\n",
        "\n",
        "        # compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
        "        target_qvalues_for_actions = rewards + gamma *next_state_values # YOUR CODE\n",
        "\n",
        "        # at the last state we shall use simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
        "        target_qvalues_for_actions = torch.where(\n",
        "            is_done, rewards, target_qvalues_for_actions)\n",
        "\n",
        "        # mean squared error loss to minimize\n",
        "        #loss = torch.mean((predicted_qvalues_for_actions -\n",
        "        #                   target_qvalues_for_actions.detach()) ** 2)\n",
        "        loss = F.smooth_l1_loss(predicted_qvalues_for_actions, target_qvalues_for_actions.detach())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def sample_from_buffer(self, batch_size):\n",
        "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
        "        for i in range(batch_size):\n",
        "            idx = random.randint(0, self.memory_buffer.size() - 1)\n",
        "            data = self.memory_buffer.buffer[idx]\n",
        "            frame, action, reward, next_frame, done= data\n",
        "            states.append(self.observe(frame))\n",
        "            actions.append(action)\n",
        "            rewards.append(reward)\n",
        "            next_states.append(self.observe(next_frame))\n",
        "            dones.append(done)\n",
        "        return torch.cat(states), actions, rewards, torch.cat(next_states), dones\n",
        "\n",
        "    def learn_from_experience(self, batch_size):\n",
        "        if self.memory_buffer.size() > batch_size:\n",
        "            states, actions, rewards, next_states, dones = self.sample_from_buffer(batch_size)\n",
        "            td_loss = self.compute_td_loss(states, actions, rewards, next_states, dones)\n",
        "            self.optimizer.zero_grad()\n",
        "            td_loss.backward()\n",
        "            for param in self.DQN.parameters():\n",
        "                param.grad.data.clamp_(-1, 1)\n",
        "\n",
        "            self.optimizer.step()\n",
        "            return(td_loss.item())\n",
        "        else:\n",
        "            return(0)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Traning\n",
        "\n",
        "接下来是最重要的训练部分，基本上就是定好初始参数，要训练的总帧数，然后让智能体与环境交互并学习。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsrAIr7TNroT",
        "outputId": "e1577d15-195e-4649-b798-e1d34c63adcd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/neaf2080/.pyenv/versions/3.8.18/envs/RL_gym/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "/home/neaf2080/.pyenv/versions/3.8.18/envs/RL_gym/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/home/neaf2080/.pyenv/versions/3.8.18/envs/RL_gym/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frames:     0, reward:   nan, loss: 0.000000, epsilon: 1.000000, episode:    0\n",
            "frames:  1000, reward: -21.000000, loss: 0.000000, epsilon: 0.968855, episode:    1\n",
            "frames:  2000, reward: -21.000000, loss: 0.000000, epsilon: 0.938732, episode:    2\n",
            "frames:  3000, reward: -20.666667, loss: 0.000000, epsilon: 0.909596, episode:    3\n",
            "frames:  4000, reward: -20.250000, loss: 0.000000, epsilon: 0.881415, episode:    4\n",
            "frames:  5000, reward: -20.400000, loss: 0.000000, epsilon: 0.854158, episode:    5\n",
            "frames:  6000, reward: -20.500000, loss: 0.000000, epsilon: 0.827794, episode:    6\n",
            "frames:  7000, reward: -20.285714, loss: 0.000000, epsilon: 0.802295, episode:    7\n",
            "frames:  8000, reward: -20.375000, loss: 0.000000, epsilon: 0.777632, episode:    8\n",
            "frames:  9000, reward: -20.444444, loss: 0.000000, epsilon: 0.753777, episode:    9\n",
            "frames: 10000, reward: -20.400000, loss: 0.016045, epsilon: 0.730705, episode:   11\n",
            "frames: 11000, reward: -20.400000, loss: 0.029948, epsilon: 0.708389, episode:   12\n",
            "frames: 12000, reward: -20.500000, loss: 0.029886, epsilon: 0.686804, episode:   13\n",
            "frames: 13000, reward: -20.600000, loss: 0.000446, epsilon: 0.665927, episode:   14\n",
            "frames: 14000, reward: -20.500000, loss: 0.000348, epsilon: 0.645735, episode:   15\n",
            "frames: 15000, reward: -20.500000, loss: 0.029802, epsilon: 0.626204, episode:   16\n",
            "frames: 16000, reward: -20.700000, loss: 0.015099, epsilon: 0.607314, episode:   17\n",
            "frames: 17000, reward: -20.600000, loss: 0.059693, epsilon: 0.589043, episode:   18\n",
            "frames: 18000, reward: -20.700000, loss: 0.030576, epsilon: 0.571371, episode:   20\n",
            "frames: 19000, reward: -20.500000, loss: 0.000626, epsilon: 0.554278, episode:   21\n",
            "frames: 20000, reward: -20.400000, loss: 0.015111, epsilon: 0.537746, episode:   22\n",
            "frames: 21000, reward: -20.400000, loss: 0.000349, epsilon: 0.521756, episode:   23\n",
            "frames: 22000, reward: -20.400000, loss: 0.030193, epsilon: 0.506290, episode:   24\n",
            "frames: 23000, reward: -20.300000, loss: 0.000276, epsilon: 0.491331, episode:   25\n",
            "frames: 24000, reward: -20.300000, loss: 0.000233, epsilon: 0.476863, episode:   26\n",
            "frames: 25000, reward: -20.100000, loss: 0.000111, epsilon: 0.462868, episode:   27\n",
            "frames: 26000, reward: -20.100000, loss: 0.000285, epsilon: 0.449333, episode:   28\n",
            "frames: 27000, reward: -20.100000, loss: 0.015570, epsilon: 0.436241, episode:   29\n",
            "frames: 28000, reward: -20.100000, loss: 0.000413, epsilon: 0.423579, episode:   30\n",
            "frames: 29000, reward: -20.300000, loss: 0.001203, epsilon: 0.411331, episode:   32\n",
            "frames: 30000, reward: -20.300000, loss: 0.000397, epsilon: 0.399485, episode:   32\n",
            "frames: 31000, reward: -20.300000, loss: 0.000448, epsilon: 0.388028, episode:   34\n",
            "frames: 32000, reward: -20.400000, loss: 0.015097, epsilon: 0.376946, episode:   35\n",
            "frames: 33000, reward: -20.400000, loss: 0.014553, epsilon: 0.366228, episode:   36\n",
            "frames: 34000, reward: -20.500000, loss: 0.015366, epsilon: 0.355860, episode:   37\n",
            "frames: 35000, reward: -20.600000, loss: 0.031400, epsilon: 0.345833, episode:   38\n",
            "frames: 36000, reward: -20.500000, loss: 0.000311, epsilon: 0.336135, episode:   40\n",
            "frames: 37000, reward: -20.500000, loss: 0.000377, epsilon: 0.326754, episode:   40\n",
            "frames: 38000, reward: -20.300000, loss: 0.000404, epsilon: 0.317681, episode:   42\n",
            "frames: 39000, reward: -20.300000, loss: 0.015408, epsilon: 0.308905, episode:   43\n",
            "frames: 40000, reward: -20.200000, loss: 0.015409, epsilon: 0.300417, episode:   44\n",
            "frames: 41000, reward: -20.200000, loss: 0.000376, epsilon: 0.292208, episode:   45\n",
            "frames: 42000, reward: -20.200000, loss: 0.015367, epsilon: 0.284267, episode:   46\n",
            "frames: 43000, reward: -20.100000, loss: 0.000530, epsilon: 0.276587, episode:   47\n",
            "frames: 44000, reward: -20.000000, loss: 0.029211, epsilon: 0.269159, episode:   48\n",
            "frames: 45000, reward: -20.000000, loss: 0.016064, epsilon: 0.261974, episode:   49\n",
            "frames: 46000, reward: -19.900000, loss: 0.030139, epsilon: 0.255024, episode:   50\n",
            "frames: 47000, reward: -20.100000, loss: 0.000201, epsilon: 0.248303, episode:   52\n",
            "frames: 48000, reward: -20.200000, loss: 0.000251, epsilon: 0.241802, episode:   53\n",
            "frames: 49000, reward: -20.200000, loss: 0.029654, epsilon: 0.235514, episode:   54\n",
            "frames: 50000, reward: -20.000000, loss: 0.012970, epsilon: 0.229432, episode:   55\n",
            "frames: 51000, reward: -19.900000, loss: 0.024700, epsilon: 0.223549, episode:   56\n",
            "frames: 52000, reward: -20.000000, loss: 0.031705, epsilon: 0.217860, episode:   57\n",
            "frames: 53000, reward: -20.100000, loss: 0.016993, epsilon: 0.212357, episode:   58\n",
            "frames: 54000, reward: -20.100000, loss: 0.019564, epsilon: 0.207034, episode:   59\n",
            "frames: 55000, reward: -20.100000, loss: 0.011684, epsilon: 0.201886, episode:   60\n",
            "frames: 56000, reward: -19.900000, loss: 0.002987, epsilon: 0.196906, episode:   61\n",
            "frames: 57000, reward: -20.000000, loss: 0.001355, epsilon: 0.192090, episode:   63\n",
            "frames: 58000, reward: -20.100000, loss: 0.010351, epsilon: 0.187432, episode:   64\n",
            "frames: 59000, reward: -20.400000, loss: 0.015649, epsilon: 0.182926, episode:   65\n",
            "frames: 60000, reward: -20.400000, loss: 0.006495, epsilon: 0.178569, episode:   66\n",
            "frames: 61000, reward: -20.400000, loss: 0.001491, epsilon: 0.174354, episode:   67\n",
            "frames: 62000, reward: -20.300000, loss: 0.014459, epsilon: 0.170277, episode:   68\n",
            "frames: 63000, reward: -20.500000, loss: 0.016780, epsilon: 0.166334, episode:   70\n",
            "frames: 64000, reward: -20.700000, loss: 0.005422, epsilon: 0.162520, episode:   71\n",
            "frames: 65000, reward: -20.700000, loss: 0.013943, epsilon: 0.158831, episode:   72\n",
            "frames: 66000, reward: -20.700000, loss: 0.003196, epsilon: 0.155263, episode:   73\n",
            "frames: 67000, reward: -20.600000, loss: 0.001957, epsilon: 0.151812, episode:   75\n",
            "frames: 68000, reward: -20.600000, loss: 0.001043, epsilon: 0.148474, episode:   76\n",
            "frames: 69000, reward: -20.500000, loss: 0.001290, epsilon: 0.145246, episode:   77\n",
            "frames: 70000, reward: -20.600000, loss: 0.001114, epsilon: 0.142123, episode:   78\n",
            "frames: 71000, reward: -20.500000, loss: 0.002469, epsilon: 0.139103, episode:   79\n",
            "frames: 72000, reward: -20.500000, loss: 0.001746, epsilon: 0.136182, episode:   80\n",
            "frames: 73000, reward: -20.500000, loss: 0.002964, epsilon: 0.133357, episode:   81\n",
            "frames: 74000, reward: -20.500000, loss: 0.003007, epsilon: 0.130624, episode:   83\n",
            "frames: 75000, reward: -20.400000, loss: 0.001901, epsilon: 0.127981, episode:   84\n",
            "frames: 76000, reward: -20.400000, loss: 0.001725, epsilon: 0.125424, episode:   85\n",
            "frames: 77000, reward: -20.400000, loss: 0.002424, epsilon: 0.122952, episode:   86\n",
            "frames: 78000, reward: -20.500000, loss: 0.001853, epsilon: 0.120560, episode:   87\n",
            "frames: 79000, reward: -20.400000, loss: 0.000885, epsilon: 0.118247, episode:   88\n",
            "frames: 80000, reward: -20.500000, loss: 0.000916, epsilon: 0.116009, episode:   89\n",
            "frames: 81000, reward: -20.500000, loss: 0.002991, epsilon: 0.113845, episode:   90\n",
            "frames: 82000, reward: -20.300000, loss: 0.000274, epsilon: 0.111752, episode:   92\n",
            "frames: 83000, reward: -20.200000, loss: 0.001827, epsilon: 0.109728, episode:   93\n",
            "frames: 84000, reward: -20.100000, loss: 0.000428, epsilon: 0.107770, episode:   94\n",
            "frames: 85000, reward: -20.200000, loss: 0.001163, epsilon: 0.105876, episode:   95\n",
            "frames: 86000, reward: -20.300000, loss: 0.000800, epsilon: 0.104044, episode:   96\n",
            "frames: 87000, reward: -20.300000, loss: 0.001679, epsilon: 0.102272, episode:   97\n",
            "frames: 88000, reward: -20.200000, loss: 0.003571, epsilon: 0.100558, episode:   98\n",
            "frames: 89000, reward: -20.200000, loss: 0.004270, epsilon: 0.098901, episode:   99\n",
            "frames: 90000, reward: -20.200000, loss: 0.002153, epsilon: 0.097298, episode:  100\n",
            "frames: 91000, reward: -20.300000, loss: 0.001021, epsilon: 0.095747, episode:  102\n",
            "frames: 92000, reward: -20.300000, loss: 0.002429, epsilon: 0.094247, episode:  103\n",
            "frames: 93000, reward: -20.500000, loss: 0.000765, epsilon: 0.092797, episode:  104\n",
            "frames: 94000, reward: -20.400000, loss: 0.001307, epsilon: 0.091394, episode:  105\n",
            "frames: 95000, reward: -20.200000, loss: 0.001266, epsilon: 0.090037, episode:  106\n",
            "frames: 96000, reward: -20.200000, loss: 0.002324, epsilon: 0.088724, episode:  107\n",
            "frames: 97000, reward: -20.200000, loss: 0.001761, epsilon: 0.087455, episode:  107\n",
            "frames: 98000, reward: -20.200000, loss: 0.003069, epsilon: 0.086227, episode:  109\n",
            "frames: 99000, reward: -20.200000, loss: 0.003757, epsilon: 0.085039, episode:  110\n",
            "frames: 100000, reward: -20.100000, loss: 0.001073, epsilon: 0.083890, episode:  111\n",
            "frames: 101000, reward: -20.000000, loss: 0.005433, epsilon: 0.082779, episode:  112\n",
            "frames: 102000, reward: -19.800000, loss: 0.002038, epsilon: 0.081705, episode:  113\n",
            "frames: 103000, reward: -19.800000, loss: 0.003965, epsilon: 0.080665, episode:  113\n",
            "frames: 104000, reward: -19.700000, loss: 0.004986, epsilon: 0.079660, episode:  114\n",
            "frames: 105000, reward: -19.800000, loss: 0.004441, epsilon: 0.078688, episode:  115\n",
            "frames: 106000, reward: -19.900000, loss: 0.001198, epsilon: 0.077747, episode:  116\n",
            "frames: 107000, reward: -20.000000, loss: 0.002331, epsilon: 0.076837, episode:  117\n",
            "frames: 108000, reward: -19.800000, loss: 0.002468, epsilon: 0.075958, episode:  118\n",
            "frames: 109000, reward: -19.700000, loss: 0.000544, epsilon: 0.075107, episode:  119\n",
            "frames: 110000, reward: -19.700000, loss: 0.005230, epsilon: 0.074283, episode:  119\n",
            "frames: 111000, reward: -19.100000, loss: 0.001355, epsilon: 0.073487, episode:  120\n",
            "frames: 112000, reward: -19.200000, loss: 0.002678, epsilon: 0.072717, episode:  121\n",
            "frames: 113000, reward: -19.200000, loss: 0.001522, epsilon: 0.071973, episode:  122\n",
            "frames: 114000, reward: -19.300000, loss: 0.001308, epsilon: 0.071252, episode:  123\n",
            "frames: 115000, reward: -19.200000, loss: 0.002866, epsilon: 0.070556, episode:  124\n",
            "frames: 116000, reward: -19.100000, loss: 0.002301, epsilon: 0.069882, episode:  125\n",
            "frames: 117000, reward: -19.200000, loss: 0.004805, epsilon: 0.069230, episode:  126\n",
            "frames: 118000, reward: -19.100000, loss: 0.004858, epsilon: 0.068599, episode:  127\n",
            "frames: 119000, reward: -19.500000, loss: 0.002226, epsilon: 0.067990, episode:  128\n",
            "frames: 120000, reward: -19.200000, loss: 0.006783, epsilon: 0.067400, episode:  129\n",
            "frames: 121000, reward: -19.800000, loss: 0.006304, epsilon: 0.066829, episode:  130\n",
            "frames: 122000, reward: -19.500000, loss: 0.003069, epsilon: 0.066278, episode:  131\n",
            "frames: 123000, reward: -19.600000, loss: 0.000712, epsilon: 0.065744, episode:  132\n",
            "frames: 124000, reward: -19.700000, loss: 0.000935, epsilon: 0.065228, episode:  133\n",
            "frames: 125000, reward: -19.700000, loss: 0.002954, epsilon: 0.064729, episode:  134\n",
            "frames: 126000, reward: -19.700000, loss: 0.001172, epsilon: 0.064246, episode:  134\n",
            "frames: 127000, reward: -19.400000, loss: 0.001786, epsilon: 0.063779, episode:  135\n",
            "frames: 128000, reward: -19.000000, loss: 0.001883, epsilon: 0.063327, episode:  136\n",
            "frames: 129000, reward: -19.100000, loss: 0.001082, epsilon: 0.062890, episode:  137\n",
            "frames: 130000, reward: -19.100000, loss: 0.001229, epsilon: 0.062468, episode:  138\n",
            "frames: 131000, reward: -19.300000, loss: 0.006310, epsilon: 0.062059, episode:  139\n",
            "frames: 132000, reward: -18.800000, loss: 0.002041, epsilon: 0.061663, episode:  140\n",
            "frames: 133000, reward: -18.800000, loss: 0.003205, epsilon: 0.061281, episode:  140\n",
            "frames: 134000, reward: -18.900000, loss: 0.003001, epsilon: 0.060911, episode:  141\n",
            "frames: 135000, reward: -19.000000, loss: 0.002574, epsilon: 0.060554, episode:  142\n",
            "frames: 136000, reward: -19.000000, loss: 0.004015, epsilon: 0.060208, episode:  143\n",
            "frames: 137000, reward: -19.000000, loss: 0.006380, epsilon: 0.059873, episode:  144\n",
            "frames: 138000, reward: -19.100000, loss: 0.002379, epsilon: 0.059549, episode:  145\n",
            "frames: 139000, reward: -19.500000, loss: 0.005126, epsilon: 0.059236, episode:  146\n",
            "frames: 140000, reward: -19.500000, loss: 0.001571, epsilon: 0.058933, episode:  146\n",
            "frames: 141000, reward: -19.200000, loss: 0.002713, epsilon: 0.058641, episode:  147\n",
            "frames: 142000, reward: -18.700000, loss: 0.013851, epsilon: 0.058357, episode:  148\n",
            "frames: 143000, reward: -18.600000, loss: 0.000839, epsilon: 0.058083, episode:  149\n",
            "frames: 144000, reward: -18.600000, loss: 0.000964, epsilon: 0.057818, episode:  149\n",
            "frames: 145000, reward: -18.600000, loss: 0.001544, epsilon: 0.057562, episode:  150\n",
            "frames: 146000, reward: -18.600000, loss: 0.002106, epsilon: 0.057314, episode:  151\n",
            "frames: 147000, reward: -18.600000, loss: 0.001892, epsilon: 0.057074, episode:  151\n",
            "frames: 148000, reward: -18.400000, loss: 0.007387, epsilon: 0.056842, episode:  152\n",
            "frames: 149000, reward: -18.400000, loss: 0.003214, epsilon: 0.056618, episode:  153\n",
            "frames: 150000, reward: -18.400000, loss: 0.005427, epsilon: 0.056401, episode:  154\n",
            "frames: 151000, reward: -18.400000, loss: 0.001486, epsilon: 0.056191, episode:  154\n",
            "frames: 152000, reward: -18.000000, loss: 0.002330, epsilon: 0.055988, episode:  155\n",
            "frames: 153000, reward: -18.000000, loss: 0.005964, epsilon: 0.055792, episode:  155\n",
            "frames: 154000, reward: -16.900000, loss: 0.002961, epsilon: 0.055602, episode:  156\n",
            "frames: 155000, reward: -16.800000, loss: 0.001144, epsilon: 0.055418, episode:  157\n",
            "frames: 156000, reward: -16.800000, loss: 0.001367, epsilon: 0.055241, episode:  157\n",
            "frames: 157000, reward: -16.700000, loss: 0.003320, epsilon: 0.055069, episode:  158\n",
            "frames: 158000, reward: -17.000000, loss: 0.002813, epsilon: 0.054903, episode:  159\n",
            "frames: 159000, reward: -17.000000, loss: 0.003810, epsilon: 0.054742, episode:  159\n",
            "frames: 160000, reward: -16.400000, loss: 0.002235, epsilon: 0.054587, episode:  160\n",
            "frames: 161000, reward: -16.100000, loss: 0.001432, epsilon: 0.054436, episode:  161\n",
            "frames: 162000, reward: -16.100000, loss: 0.003800, epsilon: 0.054291, episode:  161\n",
            "frames: 163000, reward: -16.000000, loss: 0.001682, epsilon: 0.054150, episode:  162\n",
            "frames: 164000, reward: -16.000000, loss: 0.004956, epsilon: 0.054014, episode:  163\n",
            "frames: 165000, reward: -16.000000, loss: 0.002096, epsilon: 0.053882, episode:  163\n",
            "frames: 166000, reward: -15.300000, loss: 0.005478, epsilon: 0.053755, episode:  164\n",
            "frames: 167000, reward: -15.300000, loss: 0.003270, epsilon: 0.053632, episode:  164\n",
            "frames: 168000, reward: -15.200000, loss: 0.003812, epsilon: 0.053513, episode:  165\n",
            "frames: 169000, reward: -16.200000, loss: 0.000720, epsilon: 0.053398, episode:  166\n",
            "frames: 170000, reward: -16.200000, loss: 0.001913, epsilon: 0.053286, episode:  166\n",
            "frames: 171000, reward: -15.800000, loss: 0.005543, epsilon: 0.053179, episode:  167\n",
            "frames: 172000, reward: -15.800000, loss: 0.005901, epsilon: 0.053074, episode:  167\n",
            "frames: 173000, reward: -15.500000, loss: 0.003563, epsilon: 0.052974, episode:  168\n",
            "frames: 174000, reward: -15.500000, loss: 0.004568, epsilon: 0.052876, episode:  168\n",
            "frames: 175000, reward: -14.700000, loss: 0.001455, epsilon: 0.052782, episode:  169\n",
            "frames: 176000, reward: -15.300000, loss: 0.003150, epsilon: 0.052691, episode:  170\n",
            "frames: 177000, reward: -15.300000, loss: 0.001771, epsilon: 0.052602, episode:  170\n",
            "frames: 178000, reward: -15.400000, loss: 0.001252, epsilon: 0.052517, episode:  171\n",
            "frames: 179000, reward: -15.400000, loss: 0.002830, epsilon: 0.052435, episode:  171\n",
            "frames: 180000, reward: -14.800000, loss: 0.002368, epsilon: 0.052355, episode:  172\n",
            "frames: 181000, reward: -14.600000, loss: 0.003114, epsilon: 0.052278, episode:  173\n",
            "frames: 182000, reward: -15.300000, loss: 0.005504, epsilon: 0.052203, episode:  174\n",
            "frames: 183000, reward: -15.300000, loss: 0.001161, epsilon: 0.052131, episode:  174\n",
            "frames: 184000, reward: -15.300000, loss: 0.002975, epsilon: 0.052061, episode:  174\n",
            "frames: 185000, reward: -15.400000, loss: 0.001815, epsilon: 0.051993, episode:  175\n",
            "frames: 186000, reward: -14.500000, loss: 0.001720, epsilon: 0.051928, episode:  176\n",
            "frames: 187000, reward: -15.200000, loss: 0.002522, epsilon: 0.051865, episode:  177\n",
            "frames: 188000, reward: -15.200000, loss: 0.007032, epsilon: 0.051804, episode:  177\n",
            "frames: 189000, reward: -15.200000, loss: 0.001179, epsilon: 0.051744, episode:  178\n",
            "frames: 190000, reward: -15.200000, loss: 0.002670, epsilon: 0.051687, episode:  178\n",
            "frames: 191000, reward: -15.600000, loss: 0.005662, epsilon: 0.051632, episode:  179\n",
            "frames: 192000, reward: -15.600000, loss: 0.001879, epsilon: 0.051578, episode:  179\n",
            "frames: 193000, reward: -15.300000, loss: 0.006260, epsilon: 0.051527, episode:  180\n",
            "frames: 194000, reward: -15.300000, loss: 0.002283, epsilon: 0.051477, episode:  180\n",
            "frames: 195000, reward: -15.400000, loss: 0.001844, epsilon: 0.051428, episode:  181\n",
            "frames: 196000, reward: -16.300000, loss: 0.007204, epsilon: 0.051381, episode:  182\n",
            "frames: 197000, reward: -16.300000, loss: 0.001290, epsilon: 0.051336, episode:  182\n",
            "frames: 198000, reward: -16.400000, loss: 0.001236, epsilon: 0.051292, episode:  183\n",
            "frames: 199000, reward: -16.400000, loss: 0.001709, epsilon: 0.051250, episode:  183\n",
            "frames: 200000, reward: -16.600000, loss: 0.002857, epsilon: 0.051209, episode:  184\n",
            "frames: 201000, reward: -16.600000, loss: 0.002248, epsilon: 0.051169, episode:  184\n",
            "frames: 202000, reward: -16.700000, loss: 0.003457, epsilon: 0.051131, episode:  185\n",
            "frames: 203000, reward: -16.700000, loss: 0.004000, epsilon: 0.051094, episode:  185\n",
            "frames: 204000, reward: -16.900000, loss: 0.001855, epsilon: 0.051058, episode:  186\n",
            "frames: 205000, reward: -16.900000, loss: 0.003594, epsilon: 0.051023, episode:  186\n",
            "frames: 206000, reward: -16.000000, loss: 0.003061, epsilon: 0.050990, episode:  187\n",
            "frames: 207000, reward: -16.000000, loss: 0.003653, epsilon: 0.050957, episode:  187\n",
            "frames: 208000, reward: -15.600000, loss: 0.003906, epsilon: 0.050926, episode:  188\n",
            "frames: 209000, reward: -15.600000, loss: 0.001535, epsilon: 0.050896, episode:  188\n",
            "frames: 210000, reward: -15.900000, loss: 0.004507, epsilon: 0.050866, episode:  189\n",
            "frames: 211000, reward: -15.900000, loss: 0.005394, epsilon: 0.050838, episode:  189\n",
            "frames: 212000, reward: -16.500000, loss: 0.004679, epsilon: 0.050810, episode:  190\n",
            "frames: 213000, reward: -16.500000, loss: 0.001844, epsilon: 0.050784, episode:  190\n",
            "frames: 214000, reward: -16.200000, loss: 0.001644, epsilon: 0.050758, episode:  191\n",
            "frames: 215000, reward: -16.100000, loss: 0.001934, epsilon: 0.050733, episode:  192\n",
            "frames: 216000, reward: -16.100000, loss: 0.004273, epsilon: 0.050709, episode:  192\n",
            "frames: 217000, reward: -14.900000, loss: 0.001819, epsilon: 0.050686, episode:  193\n",
            "frames: 218000, reward: -14.900000, loss: 0.003061, epsilon: 0.050664, episode:  193\n",
            "frames: 219000, reward: -14.900000, loss: 0.002854, epsilon: 0.050642, episode:  193\n",
            "frames: 220000, reward: -13.700000, loss: 0.002835, epsilon: 0.050621, episode:  194\n",
            "frames: 221000, reward: -13.700000, loss: 0.004294, epsilon: 0.050600, episode:  194\n",
            "frames: 222000, reward: -13.800000, loss: 0.001635, epsilon: 0.050581, episode:  195\n",
            "frames: 223000, reward: -13.800000, loss: 0.004376, epsilon: 0.050562, episode:  195\n",
            "frames: 224000, reward: -13.800000, loss: 0.003115, epsilon: 0.050543, episode:  196\n",
            "frames: 225000, reward: -13.800000, loss: 0.003241, epsilon: 0.050525, episode:  196\n",
            "frames: 226000, reward: -14.000000, loss: 0.001470, epsilon: 0.050508, episode:  197\n",
            "frames: 227000, reward: -14.000000, loss: 0.002069, epsilon: 0.050492, episode:  197\n",
            "frames: 228000, reward: -13.900000, loss: 0.002648, epsilon: 0.050475, episode:  198\n",
            "frames: 229000, reward: -13.900000, loss: 0.003674, epsilon: 0.050460, episode:  198\n",
            "frames: 230000, reward: -12.900000, loss: 0.001594, epsilon: 0.050445, episode:  199\n",
            "frames: 231000, reward: -12.900000, loss: 0.000969, epsilon: 0.050430, episode:  199\n",
            "frames: 232000, reward: -11.600000, loss: 0.005581, epsilon: 0.050416, episode:  200\n",
            "frames: 233000, reward: -11.600000, loss: 0.005490, epsilon: 0.050402, episode:  200\n",
            "frames: 234000, reward: -11.600000, loss: 0.004086, epsilon: 0.050389, episode:  200\n",
            "frames: 235000, reward: -11.200000, loss: 0.001306, epsilon: 0.050376, episode:  201\n",
            "frames: 236000, reward: -11.200000, loss: 0.010302, epsilon: 0.050364, episode:  201\n",
            "frames: 237000, reward: -10.100000, loss: 0.002523, epsilon: 0.050352, episode:  202\n",
            "frames: 238000, reward: -10.100000, loss: 0.002035, epsilon: 0.050341, episode:  202\n",
            "frames: 239000, reward: -10.100000, loss: 0.003328, epsilon: 0.050329, episode:  202\n",
            "frames: 240000, reward: -9.900000, loss: 0.004028, epsilon: 0.050319, episode:  203\n",
            "frames: 241000, reward: -9.900000, loss: 0.002467, epsilon: 0.050308, episode:  203\n",
            "frames: 242000, reward: -10.000000, loss: 0.001826, epsilon: 0.050298, episode:  204\n",
            "frames: 243000, reward: -10.000000, loss: 0.008717, epsilon: 0.050288, episode:  204\n",
            "frames: 244000, reward: -10.000000, loss: 0.002874, epsilon: 0.050279, episode:  204\n",
            "frames: 245000, reward: -8.600000, loss: 0.003908, epsilon: 0.050270, episode:  205\n",
            "frames: 246000, reward: -8.600000, loss: 0.004120, epsilon: 0.050261, episode:  205\n",
            "frames: 247000, reward: -8.600000, loss: 0.002007, epsilon: 0.050252, episode:  205\n",
            "frames: 248000, reward: -7.900000, loss: 0.003763, epsilon: 0.050244, episode:  206\n",
            "frames: 249000, reward: -7.900000, loss: 0.001914, epsilon: 0.050236, episode:  206\n",
            "frames: 250000, reward: -7.900000, loss: 0.001763, epsilon: 0.050228, episode:  206\n",
            "frames: 251000, reward: -7.700000, loss: 0.004054, epsilon: 0.050221, episode:  207\n",
            "frames: 252000, reward: -7.700000, loss: 0.001298, epsilon: 0.050214, episode:  207\n",
            "frames: 253000, reward: -7.900000, loss: 0.007550, epsilon: 0.050207, episode:  208\n",
            "frames: 254000, reward: -7.900000, loss: 0.003124, epsilon: 0.050200, episode:  208\n",
            "frames: 255000, reward: -7.900000, loss: 0.002530, epsilon: 0.050193, episode:  208\n",
            "frames: 256000, reward: -7.300000, loss: 0.002135, epsilon: 0.050187, episode:  209\n",
            "frames: 257000, reward: -7.300000, loss: 0.002393, epsilon: 0.050181, episode:  209\n",
            "frames: 258000, reward: -7.300000, loss: 0.004795, epsilon: 0.050175, episode:  209\n",
            "frames: 259000, reward: -7.300000, loss: 0.002984, epsilon: 0.050169, episode:  209\n",
            "frames: 260000, reward: -6.300000, loss: 0.003762, epsilon: 0.050164, episode:  210\n",
            "frames: 261000, reward: -6.300000, loss: 0.003628, epsilon: 0.050158, episode:  210\n",
            "frames: 262000, reward: -6.300000, loss: 0.004337, epsilon: 0.050153, episode:  210\n",
            "frames: 263000, reward: -5.800000, loss: 0.003557, epsilon: 0.050148, episode:  211\n",
            "frames: 264000, reward: -5.800000, loss: 0.002643, epsilon: 0.050143, episode:  211\n",
            "frames: 265000, reward: -6.100000, loss: 0.005569, epsilon: 0.050139, episode:  212\n",
            "frames: 266000, reward: -6.100000, loss: 0.002414, epsilon: 0.050134, episode:  212\n",
            "frames: 267000, reward: -6.100000, loss: 0.005418, epsilon: 0.050130, episode:  212\n",
            "frames: 268000, reward: -6.100000, loss: 0.004369, epsilon: 0.050125, episode:  212\n",
            "frames: 269000, reward: -5.700000, loss: 0.003659, epsilon: 0.050121, episode:  213\n",
            "frames: 270000, reward: -5.700000, loss: 0.003184, epsilon: 0.050117, episode:  213\n",
            "frames: 271000, reward: -5.700000, loss: 0.000817, epsilon: 0.050113, episode:  213\n",
            "frames: 272000, reward: -4.800000, loss: 0.003467, epsilon: 0.050110, episode:  214\n",
            "frames: 273000, reward: -4.800000, loss: 0.001988, epsilon: 0.050106, episode:  214\n",
            "frames: 274000, reward: -4.800000, loss: 0.003749, epsilon: 0.050103, episode:  214\n",
            "frames: 275000, reward: -5.100000, loss: 0.005868, epsilon: 0.050099, episode:  215\n",
            "frames: 276000, reward: -5.100000, loss: 0.003104, epsilon: 0.050096, episode:  215\n",
            "frames: 277000, reward: -5.100000, loss: 0.003853, epsilon: 0.050093, episode:  215\n",
            "frames: 278000, reward: -5.600000, loss: 0.003671, epsilon: 0.050090, episode:  216\n",
            "frames: 279000, reward: -5.600000, loss: 0.001301, epsilon: 0.050087, episode:  216\n",
            "frames: 280000, reward: -5.600000, loss: 0.005302, epsilon: 0.050084, episode:  216\n",
            "frames: 281000, reward: -5.200000, loss: 0.002917, epsilon: 0.050081, episode:  217\n",
            "frames: 282000, reward: -5.200000, loss: 0.005416, epsilon: 0.050079, episode:  217\n",
            "frames: 283000, reward: -5.200000, loss: 0.004463, epsilon: 0.050076, episode:  217\n",
            "frames: 284000, reward: -4.500000, loss: 0.002836, epsilon: 0.050074, episode:  218\n",
            "frames: 285000, reward: -4.500000, loss: 0.001366, epsilon: 0.050071, episode:  218\n",
            "frames: 286000, reward: -5.500000, loss: 0.000862, epsilon: 0.050069, episode:  219\n",
            "frames: 287000, reward: -5.500000, loss: 0.002080, epsilon: 0.050067, episode:  219\n",
            "frames: 288000, reward: -5.500000, loss: 0.001365, epsilon: 0.050064, episode:  219\n",
            "frames: 289000, reward: -6.500000, loss: 0.009068, epsilon: 0.050062, episode:  220\n",
            "frames: 290000, reward: -6.500000, loss: 0.001349, epsilon: 0.050060, episode:  220\n",
            "frames: 291000, reward: -6.500000, loss: 0.001571, epsilon: 0.050058, episode:  220\n",
            "frames: 292000, reward: -6.600000, loss: 0.004484, epsilon: 0.050056, episode:  221\n",
            "frames: 293000, reward: -6.600000, loss: 0.006863, epsilon: 0.050054, episode:  221\n",
            "frames: 294000, reward: -6.000000, loss: 0.001669, epsilon: 0.050053, episode:  222\n",
            "frames: 295000, reward: -6.000000, loss: 0.001724, epsilon: 0.050051, episode:  222\n",
            "frames: 296000, reward: -6.000000, loss: 0.002757, epsilon: 0.050049, episode:  222\n",
            "frames: 297000, reward: -6.000000, loss: 0.002607, epsilon: 0.050048, episode:  222\n",
            "frames: 298000, reward: -6.400000, loss: 0.003578, epsilon: 0.050046, episode:  223\n",
            "frames: 299000, reward: -6.400000, loss: 0.002179, epsilon: 0.050045, episode:  223\n",
            "frames: 300000, reward: -6.600000, loss: 0.003373, epsilon: 0.050043, episode:  224\n",
            "frames: 301000, reward: -6.600000, loss: 0.002452, epsilon: 0.050042, episode:  224\n",
            "frames: 302000, reward: -6.600000, loss: 0.006314, epsilon: 0.050040, episode:  224\n",
            "frames: 303000, reward: -7.200000, loss: 0.011753, epsilon: 0.050039, episode:  225\n",
            "frames: 304000, reward: -7.200000, loss: 0.002251, epsilon: 0.050038, episode:  225\n",
            "frames: 305000, reward: -6.800000, loss: 0.001915, epsilon: 0.050037, episode:  226\n",
            "frames: 306000, reward: -6.800000, loss: 0.003333, epsilon: 0.050035, episode:  226\n",
            "frames: 307000, reward: -6.800000, loss: 0.000913, epsilon: 0.050034, episode:  226\n",
            "frames: 308000, reward: -6.000000, loss: 0.003066, epsilon: 0.050033, episode:  227\n",
            "frames: 309000, reward: -6.000000, loss: 0.002517, epsilon: 0.050032, episode:  227\n",
            "frames: 310000, reward: -6.000000, loss: 0.003118, epsilon: 0.050031, episode:  227\n",
            "frames: 311000, reward: -6.800000, loss: 0.005894, epsilon: 0.050030, episode:  228\n",
            "frames: 312000, reward: -6.800000, loss: 0.001758, epsilon: 0.050029, episode:  228\n",
            "frames: 313000, reward: -6.500000, loss: 0.003747, epsilon: 0.050028, episode:  229\n",
            "frames: 314000, reward: -6.500000, loss: 0.002315, epsilon: 0.050027, episode:  229\n",
            "frames: 315000, reward: -6.800000, loss: 0.002033, epsilon: 0.050026, episode:  230\n",
            "frames: 316000, reward: -6.800000, loss: 0.001715, epsilon: 0.050025, episode:  230\n",
            "frames: 317000, reward: -6.800000, loss: 0.006244, epsilon: 0.050024, episode:  230\n",
            "frames: 318000, reward: -7.000000, loss: 0.003483, epsilon: 0.050024, episode:  231\n",
            "frames: 319000, reward: -7.000000, loss: 0.003474, epsilon: 0.050023, episode:  231\n",
            "frames: 320000, reward: -7.000000, loss: 0.002016, epsilon: 0.050022, episode:  231\n",
            "frames: 321000, reward: -7.200000, loss: 0.004072, epsilon: 0.050021, episode:  232\n",
            "frames: 322000, reward: -7.200000, loss: 0.002272, epsilon: 0.050021, episode:  232\n",
            "frames: 323000, reward: -7.200000, loss: 0.001136, epsilon: 0.050020, episode:  232\n",
            "frames: 324000, reward: -7.500000, loss: 0.005892, epsilon: 0.050019, episode:  233\n",
            "frames: 325000, reward: -7.500000, loss: 0.001842, epsilon: 0.050019, episode:  233\n",
            "frames: 326000, reward: -7.500000, loss: 0.001024, epsilon: 0.050018, episode:  233\n",
            "frames: 327000, reward: -6.900000, loss: 0.004756, epsilon: 0.050018, episode:  234\n",
            "frames: 328000, reward: -6.900000, loss: 0.000827, epsilon: 0.050017, episode:  234\n",
            "frames: 329000, reward: -6.900000, loss: 0.001017, epsilon: 0.050016, episode:  234\n",
            "frames: 330000, reward: -6.900000, loss: 0.002479, epsilon: 0.050016, episode:  234\n",
            "frames: 331000, reward: -6.100000, loss: 0.002584, epsilon: 0.050015, episode:  235\n",
            "frames: 332000, reward: -6.100000, loss: 0.002311, epsilon: 0.050015, episode:  235\n",
            "frames: 333000, reward: -6.200000, loss: 0.001654, epsilon: 0.050014, episode:  236\n",
            "frames: 334000, reward: -6.200000, loss: 0.001953, epsilon: 0.050014, episode:  236\n",
            "frames: 335000, reward: -6.200000, loss: 0.001894, epsilon: 0.050013, episode:  236\n",
            "frames: 336000, reward: -6.200000, loss: 0.002949, epsilon: 0.050013, episode:  236\n",
            "frames: 337000, reward: -6.500000, loss: 0.001820, epsilon: 0.050013, episode:  237\n",
            "frames: 338000, reward: -6.500000, loss: 0.004518, epsilon: 0.050012, episode:  237\n",
            "frames: 339000, reward: -6.500000, loss: 0.005865, epsilon: 0.050012, episode:  237\n",
            "frames: 340000, reward: -5.300000, loss: 0.002147, epsilon: 0.050011, episode:  238\n",
            "frames: 341000, reward: -5.300000, loss: 0.001207, epsilon: 0.050011, episode:  238\n",
            "frames: 342000, reward: -5.300000, loss: 0.002786, epsilon: 0.050011, episode:  238\n",
            "frames: 343000, reward: -5.300000, loss: 0.002049, epsilon: 0.050010, episode:  238\n",
            "frames: 344000, reward: -4.100000, loss: 0.006388, epsilon: 0.050010, episode:  239\n",
            "frames: 345000, reward: -4.100000, loss: 0.003259, epsilon: 0.050010, episode:  239\n",
            "frames: 346000, reward: -4.100000, loss: 0.003506, epsilon: 0.050009, episode:  239\n",
            "frames: 347000, reward: -3.100000, loss: 0.017712, epsilon: 0.050009, episode:  240\n",
            "frames: 348000, reward: -3.100000, loss: 0.002695, epsilon: 0.050009, episode:  240\n",
            "frames: 349000, reward: -3.100000, loss: 0.000620, epsilon: 0.050008, episode:  240\n",
            "frames: 350000, reward: -2.000000, loss: 0.010471, epsilon: 0.050008, episode:  241\n",
            "frames: 351000, reward: -2.000000, loss: 0.003211, epsilon: 0.050008, episode:  241\n",
            "frames: 352000, reward: -2.000000, loss: 0.008608, epsilon: 0.050008, episode:  241\n",
            "frames: 353000, reward: -2.000000, loss: 0.004375, epsilon: 0.050007, episode:  242\n",
            "frames: 354000, reward: -2.000000, loss: 0.000917, epsilon: 0.050007, episode:  242\n",
            "frames: 355000, reward: -2.000000, loss: 0.000895, epsilon: 0.050007, episode:  242\n",
            "frames: 356000, reward: -2.000000, loss: 0.004759, epsilon: 0.050007, episode:  243\n",
            "frames: 357000, reward: -2.000000, loss: 0.002813, epsilon: 0.050006, episode:  243\n",
            "frames: 358000, reward: -1.100000, loss: 0.002092, epsilon: 0.050006, episode:  244\n",
            "frames: 359000, reward: -1.100000, loss: 0.001774, epsilon: 0.050006, episode:  244\n",
            "frames: 360000, reward: -1.100000, loss: 0.002771, epsilon: 0.050006, episode:  244\n",
            "frames: 361000, reward: -1.500000, loss: 0.008895, epsilon: 0.050006, episode:  245\n",
            "frames: 362000, reward: -1.500000, loss: 0.004236, epsilon: 0.050005, episode:  245\n",
            "frames: 363000, reward: -1.500000, loss: 0.000864, epsilon: 0.050005, episode:  245\n",
            "frames: 364000, reward: -0.200000, loss: 0.004033, epsilon: 0.050005, episode:  246\n",
            "frames: 365000, reward: -0.200000, loss: 0.002834, epsilon: 0.050005, episode:  246\n",
            "frames: 366000, reward: -0.200000, loss: 0.003524, epsilon: 0.050005, episode:  246\n",
            "frames: 367000, reward: -0.900000, loss: 0.001061, epsilon: 0.050005, episode:  247\n",
            "frames: 368000, reward: -0.900000, loss: 0.010908, epsilon: 0.050004, episode:  247\n",
            "frames: 369000, reward: -0.900000, loss: 0.002429, epsilon: 0.050004, episode:  247\n",
            "frames: 370000, reward: -1.800000, loss: 0.003857, epsilon: 0.050004, episode:  248\n",
            "frames: 371000, reward: -1.800000, loss: 0.002149, epsilon: 0.050004, episode:  248\n",
            "frames: 372000, reward: -2.800000, loss: 0.001087, epsilon: 0.050004, episode:  249\n",
            "frames: 373000, reward: -2.800000, loss: 0.003702, epsilon: 0.050004, episode:  249\n",
            "frames: 374000, reward: -2.800000, loss: 0.001567, epsilon: 0.050004, episode:  249\n",
            "frames: 375000, reward: -3.300000, loss: 0.006477, epsilon: 0.050004, episode:  250\n",
            "frames: 376000, reward: -3.300000, loss: 0.003438, epsilon: 0.050003, episode:  250\n",
            "frames: 377000, reward: -3.300000, loss: 0.004777, epsilon: 0.050003, episode:  250\n",
            "frames: 378000, reward: -4.500000, loss: 0.001211, epsilon: 0.050003, episode:  251\n",
            "frames: 379000, reward: -4.500000, loss: 0.000876, epsilon: 0.050003, episode:  251\n",
            "frames: 380000, reward: -4.500000, loss: 0.002182, epsilon: 0.050003, episode:  251\n",
            "frames: 381000, reward: -3.600000, loss: 0.002409, epsilon: 0.050003, episode:  252\n",
            "frames: 382000, reward: -3.600000, loss: 0.002115, epsilon: 0.050003, episode:  252\n",
            "frames: 383000, reward: -3.600000, loss: 0.002714, epsilon: 0.050003, episode:  252\n",
            "frames: 384000, reward: -3.300000, loss: 0.002267, epsilon: 0.050003, episode:  253\n",
            "frames: 385000, reward: -3.300000, loss: 0.002066, epsilon: 0.050003, episode:  253\n",
            "frames: 386000, reward: -3.300000, loss: 0.001320, epsilon: 0.050002, episode:  253\n",
            "frames: 387000, reward: -5.300000, loss: 0.001627, epsilon: 0.050002, episode:  254\n",
            "frames: 388000, reward: -5.300000, loss: 0.002544, epsilon: 0.050002, episode:  254\n",
            "frames: 389000, reward: -6.000000, loss: 0.002575, epsilon: 0.050002, episode:  255\n",
            "frames: 390000, reward: -6.000000, loss: 0.002020, epsilon: 0.050002, episode:  255\n",
            "frames: 391000, reward: -6.000000, loss: 0.002465, epsilon: 0.050002, episode:  255\n",
            "frames: 392000, reward: -6.000000, loss: 0.001396, epsilon: 0.050002, episode:  255\n",
            "frames: 393000, reward: -6.100000, loss: 0.006706, epsilon: 0.050002, episode:  256\n",
            "frames: 394000, reward: -6.100000, loss: 0.002267, epsilon: 0.050002, episode:  256\n",
            "frames: 395000, reward: -6.100000, loss: 0.007390, epsilon: 0.050002, episode:  256\n",
            "frames: 396000, reward: -5.000000, loss: 0.006430, epsilon: 0.050002, episode:  257\n",
            "frames: 397000, reward: -5.000000, loss: 0.000588, epsilon: 0.050002, episode:  257\n",
            "frames: 398000, reward: -5.000000, loss: 0.002499, epsilon: 0.050002, episode:  257\n",
            "frames: 399000, reward: -3.800000, loss: 0.004022, epsilon: 0.050002, episode:  258\n",
            "frames: 400000, reward: -3.800000, loss: 0.002659, epsilon: 0.050002, episode:  258\n",
            "frames: 401000, reward: -3.800000, loss: 0.003965, epsilon: 0.050001, episode:  258\n",
            "frames: 402000, reward: -3.800000, loss: 0.006485, epsilon: 0.050001, episode:  258\n",
            "frames: 403000, reward: -2.800000, loss: 0.005727, epsilon: 0.050001, episode:  259\n",
            "frames: 404000, reward: -2.800000, loss: 0.001367, epsilon: 0.050001, episode:  259\n",
            "frames: 405000, reward: -2.800000, loss: 0.003542, epsilon: 0.050001, episode:  259\n",
            "frames: 406000, reward: -2.600000, loss: 0.005606, epsilon: 0.050001, episode:  260\n",
            "frames: 407000, reward: -2.600000, loss: 0.003517, epsilon: 0.050001, episode:  260\n",
            "frames: 408000, reward: -2.600000, loss: 0.001989, epsilon: 0.050001, episode:  260\n",
            "frames: 409000, reward: -2.600000, loss: 0.001741, epsilon: 0.050001, episode:  260\n",
            "frames: 410000, reward: -2.100000, loss: 0.002372, epsilon: 0.050001, episode:  261\n",
            "frames: 411000, reward: -2.100000, loss: 0.003717, epsilon: 0.050001, episode:  261\n",
            "frames: 412000, reward: -2.100000, loss: 0.001273, epsilon: 0.050001, episode:  261\n",
            "frames: 413000, reward: -1.800000, loss: 0.001427, epsilon: 0.050001, episode:  262\n",
            "frames: 414000, reward: -1.800000, loss: 0.001150, epsilon: 0.050001, episode:  262\n",
            "frames: 415000, reward: -1.800000, loss: 0.002743, epsilon: 0.050001, episode:  262\n",
            "frames: 416000, reward: -1.800000, loss: 0.002112, epsilon: 0.050001, episode:  262\n",
            "frames: 417000, reward: -2.000000, loss: 0.002459, epsilon: 0.050001, episode:  263\n",
            "frames: 418000, reward: -2.000000, loss: 0.001482, epsilon: 0.050001, episode:  263\n",
            "frames: 419000, reward: -2.000000, loss: 0.001221, epsilon: 0.050001, episode:  263\n",
            "frames: 420000, reward: -1.100000, loss: 0.000877, epsilon: 0.050001, episode:  264\n",
            "frames: 421000, reward: -1.100000, loss: 0.009803, epsilon: 0.050001, episode:  264\n",
            "frames: 422000, reward: -1.100000, loss: 0.006502, epsilon: 0.050001, episode:  264\n",
            "frames: 423000, reward: -1.100000, loss: 0.002293, epsilon: 0.050001, episode:  264\n",
            "frames: 424000, reward: 0.100000, loss: 0.003840, epsilon: 0.050001, episode:  265\n",
            "frames: 425000, reward: 0.100000, loss: 0.004197, epsilon: 0.050001, episode:  265\n",
            "frames: 426000, reward: 0.100000, loss: 0.005642, epsilon: 0.050001, episode:  265\n",
            "frames: 427000, reward: 0.100000, loss: 0.001478, epsilon: 0.050001, episode:  265\n",
            "frames: 428000, reward: -0.500000, loss: 0.001556, epsilon: 0.050001, episode:  266\n",
            "frames: 429000, reward: -0.500000, loss: 0.002794, epsilon: 0.050001, episode:  266\n",
            "frames: 430000, reward: -0.500000, loss: 0.000707, epsilon: 0.050001, episode:  266\n",
            "frames: 431000, reward: 0.100000, loss: 0.002186, epsilon: 0.050001, episode:  267\n",
            "frames: 432000, reward: 0.100000, loss: 0.009370, epsilon: 0.050001, episode:  267\n",
            "frames: 433000, reward: 0.100000, loss: 0.002998, epsilon: 0.050001, episode:  267\n",
            "frames: 434000, reward: 0.300000, loss: 0.003181, epsilon: 0.050000, episode:  268\n",
            "frames: 435000, reward: 0.300000, loss: 0.001241, epsilon: 0.050000, episode:  268\n",
            "frames: 436000, reward: 0.300000, loss: 0.001258, epsilon: 0.050000, episode:  268\n",
            "frames: 437000, reward: 0.300000, loss: 0.001097, epsilon: 0.050000, episode:  268\n",
            "frames: 438000, reward: 0.400000, loss: 0.001138, epsilon: 0.050000, episode:  269\n",
            "frames: 439000, reward: 0.400000, loss: 0.002086, epsilon: 0.050000, episode:  269\n",
            "frames: 440000, reward: 0.400000, loss: 0.001618, epsilon: 0.050000, episode:  269\n",
            "frames: 441000, reward: -0.200000, loss: 0.009129, epsilon: 0.050000, episode:  270\n",
            "frames: 442000, reward: -0.200000, loss: 0.001534, epsilon: 0.050000, episode:  270\n",
            "frames: 443000, reward: -0.200000, loss: 0.001250, epsilon: 0.050000, episode:  270\n",
            "frames: 444000, reward: -0.200000, loss: 0.001731, epsilon: 0.050000, episode:  270\n",
            "frames: 445000, reward: 0.400000, loss: 0.001729, epsilon: 0.050000, episode:  271\n",
            "frames: 446000, reward: 0.400000, loss: 0.001084, epsilon: 0.050000, episode:  271\n",
            "frames: 447000, reward: 0.400000, loss: 0.002355, epsilon: 0.050000, episode:  271\n",
            "frames: 448000, reward: 0.400000, loss: 0.004279, epsilon: 0.050000, episode:  272\n",
            "frames: 449000, reward: 0.400000, loss: 0.001926, epsilon: 0.050000, episode:  272\n",
            "frames: 450000, reward: 0.400000, loss: 0.001222, epsilon: 0.050000, episode:  272\n",
            "frames: 451000, reward: 0.400000, loss: 0.001908, epsilon: 0.050000, episode:  272\n",
            "frames: 452000, reward: 1.000000, loss: 0.002447, epsilon: 0.050000, episode:  273\n",
            "frames: 453000, reward: 1.000000, loss: 0.003166, epsilon: 0.050000, episode:  273\n",
            "frames: 454000, reward: 1.000000, loss: 0.001291, epsilon: 0.050000, episode:  273\n",
            "frames: 455000, reward: 1.000000, loss: 0.002340, epsilon: 0.050000, episode:  273\n",
            "frames: 456000, reward: 0.800000, loss: 0.002074, epsilon: 0.050000, episode:  274\n",
            "frames: 457000, reward: 0.800000, loss: 0.003258, epsilon: 0.050000, episode:  274\n",
            "frames: 458000, reward: 0.800000, loss: 0.005388, epsilon: 0.050000, episode:  274\n",
            "frames: 459000, reward: 0.800000, loss: 0.001226, epsilon: 0.050000, episode:  274\n",
            "frames: 460000, reward: 0.700000, loss: 0.002436, epsilon: 0.050000, episode:  275\n",
            "frames: 461000, reward: 0.700000, loss: 0.001911, epsilon: 0.050000, episode:  275\n",
            "frames: 462000, reward: 0.700000, loss: 0.001755, epsilon: 0.050000, episode:  275\n",
            "frames: 463000, reward: 0.200000, loss: 0.004045, epsilon: 0.050000, episode:  276\n",
            "frames: 464000, reward: 0.200000, loss: 0.000745, epsilon: 0.050000, episode:  276\n",
            "frames: 465000, reward: 0.200000, loss: 0.003402, epsilon: 0.050000, episode:  276\n",
            "frames: 466000, reward: 0.200000, loss: 0.005510, epsilon: 0.050000, episode:  276\n",
            "frames: 467000, reward: -0.900000, loss: 0.001680, epsilon: 0.050000, episode:  277\n",
            "frames: 468000, reward: -0.900000, loss: 0.001931, epsilon: 0.050000, episode:  277\n",
            "frames: 469000, reward: -0.900000, loss: 0.002102, epsilon: 0.050000, episode:  277\n",
            "frames: 470000, reward: -0.900000, loss: 0.003117, epsilon: 0.050000, episode:  277\n",
            "frames: 471000, reward: -1.500000, loss: 0.001400, epsilon: 0.050000, episode:  278\n",
            "frames: 472000, reward: -1.500000, loss: 0.001664, epsilon: 0.050000, episode:  278\n",
            "frames: 473000, reward: -1.500000, loss: 0.002021, epsilon: 0.050000, episode:  278\n",
            "frames: 474000, reward: -1.000000, loss: 0.002159, epsilon: 0.050000, episode:  279\n",
            "frames: 475000, reward: -1.000000, loss: 0.001128, epsilon: 0.050000, episode:  279\n",
            "frames: 476000, reward: -1.000000, loss: 0.001751, epsilon: 0.050000, episode:  279\n",
            "frames: 477000, reward: -1.000000, loss: 0.003021, epsilon: 0.050000, episode:  279\n",
            "frames: 478000, reward: 0.400000, loss: 0.004616, epsilon: 0.050000, episode:  280\n",
            "frames: 479000, reward: 0.400000, loss: 0.002201, epsilon: 0.050000, episode:  280\n",
            "frames: 480000, reward: 0.400000, loss: 0.001727, epsilon: 0.050000, episode:  280\n",
            "frames: 481000, reward: 0.400000, loss: 0.001267, epsilon: 0.050000, episode:  280\n",
            "frames: 482000, reward: 0.100000, loss: 0.002044, epsilon: 0.050000, episode:  281\n",
            "frames: 483000, reward: 0.100000, loss: 0.005741, epsilon: 0.050000, episode:  281\n",
            "frames: 484000, reward: 0.100000, loss: 0.003228, epsilon: 0.050000, episode:  281\n",
            "frames: 485000, reward: 0.100000, loss: 0.003227, epsilon: 0.050000, episode:  281\n",
            "frames: 486000, reward: 0.300000, loss: 0.002281, epsilon: 0.050000, episode:  282\n",
            "frames: 487000, reward: 0.300000, loss: 0.001976, epsilon: 0.050000, episode:  282\n",
            "frames: 488000, reward: 0.300000, loss: 0.001367, epsilon: 0.050000, episode:  282\n",
            "frames: 489000, reward: 1.800000, loss: 0.002612, epsilon: 0.050000, episode:  283\n",
            "frames: 490000, reward: 1.800000, loss: 0.006609, epsilon: 0.050000, episode:  283\n",
            "frames: 491000, reward: 1.800000, loss: 0.002640, epsilon: 0.050000, episode:  283\n",
            "frames: 492000, reward: 2.400000, loss: 0.001344, epsilon: 0.050000, episode:  284\n",
            "frames: 493000, reward: 2.400000, loss: 0.002511, epsilon: 0.050000, episode:  284\n",
            "frames: 494000, reward: 2.400000, loss: 0.000836, epsilon: 0.050000, episode:  284\n",
            "frames: 495000, reward: 3.200000, loss: 0.001817, epsilon: 0.050000, episode:  285\n",
            "frames: 496000, reward: 3.200000, loss: 0.004362, epsilon: 0.050000, episode:  285\n",
            "frames: 497000, reward: 3.200000, loss: 0.002461, epsilon: 0.050000, episode:  285\n",
            "frames: 498000, reward: 3.200000, loss: 0.001237, epsilon: 0.050000, episode:  285\n",
            "frames: 499000, reward: 3.700000, loss: 0.000821, epsilon: 0.050000, episode:  286\n",
            "frames: 500000, reward: 3.700000, loss: 0.003179, epsilon: 0.050000, episode:  286\n",
            "frames: 501000, reward: 3.700000, loss: 0.001444, epsilon: 0.050000, episode:  286\n",
            "frames: 502000, reward: 3.700000, loss: 0.001076, epsilon: 0.050000, episode:  286\n",
            "frames: 503000, reward: 4.500000, loss: 0.004133, epsilon: 0.050000, episode:  287\n",
            "frames: 504000, reward: 4.500000, loss: 0.001234, epsilon: 0.050000, episode:  287\n",
            "frames: 505000, reward: 4.500000, loss: 0.001266, epsilon: 0.050000, episode:  287\n",
            "frames: 506000, reward: 5.400000, loss: 0.001082, epsilon: 0.050000, episode:  288\n",
            "frames: 507000, reward: 5.400000, loss: 0.003592, epsilon: 0.050000, episode:  288\n",
            "frames: 508000, reward: 5.400000, loss: 0.003529, epsilon: 0.050000, episode:  288\n",
            "frames: 509000, reward: 4.400000, loss: 0.002982, epsilon: 0.050000, episode:  289\n",
            "frames: 510000, reward: 4.400000, loss: 0.001772, epsilon: 0.050000, episode:  289\n",
            "frames: 511000, reward: 4.400000, loss: 0.000685, epsilon: 0.050000, episode:  289\n",
            "frames: 512000, reward: 4.400000, loss: 0.001459, epsilon: 0.050000, episode:  289\n",
            "frames: 513000, reward: 4.100000, loss: 0.002412, epsilon: 0.050000, episode:  290\n",
            "frames: 514000, reward: 4.100000, loss: 0.001587, epsilon: 0.050000, episode:  290\n",
            "frames: 515000, reward: 4.100000, loss: 0.001359, epsilon: 0.050000, episode:  290\n",
            "frames: 516000, reward: 5.200000, loss: 0.001270, epsilon: 0.050000, episode:  291\n",
            "frames: 517000, reward: 5.200000, loss: 0.000818, epsilon: 0.050000, episode:  291\n",
            "frames: 518000, reward: 5.200000, loss: 0.001192, epsilon: 0.050000, episode:  291\n",
            "frames: 519000, reward: 5.200000, loss: 0.002147, epsilon: 0.050000, episode:  291\n",
            "frames: 520000, reward: 5.300000, loss: 0.001040, epsilon: 0.050000, episode:  292\n",
            "frames: 521000, reward: 5.300000, loss: 0.002257, epsilon: 0.050000, episode:  292\n",
            "frames: 522000, reward: 5.300000, loss: 0.002086, epsilon: 0.050000, episode:  292\n",
            "frames: 523000, reward: 5.000000, loss: 0.001169, epsilon: 0.050000, episode:  293\n",
            "frames: 524000, reward: 5.000000, loss: 0.001412, epsilon: 0.050000, episode:  293\n",
            "frames: 525000, reward: 5.000000, loss: 0.000818, epsilon: 0.050000, episode:  293\n",
            "frames: 526000, reward: 5.700000, loss: 0.002043, epsilon: 0.050000, episode:  294\n",
            "frames: 527000, reward: 5.700000, loss: 0.001318, epsilon: 0.050000, episode:  294\n",
            "frames: 528000, reward: 5.700000, loss: 0.001881, epsilon: 0.050000, episode:  294\n",
            "frames: 529000, reward: 5.700000, loss: 0.001115, epsilon: 0.050000, episode:  294\n",
            "frames: 530000, reward: 5.700000, loss: 0.014060, epsilon: 0.050000, episode:  295\n",
            "frames: 531000, reward: 5.700000, loss: 0.002736, epsilon: 0.050000, episode:  295\n",
            "frames: 532000, reward: 5.700000, loss: 0.001305, epsilon: 0.050000, episode:  295\n",
            "frames: 533000, reward: 6.800000, loss: 0.001214, epsilon: 0.050000, episode:  296\n",
            "frames: 534000, reward: 6.800000, loss: 0.000806, epsilon: 0.050000, episode:  296\n",
            "frames: 535000, reward: 6.800000, loss: 0.002075, epsilon: 0.050000, episode:  296\n",
            "frames: 536000, reward: 7.300000, loss: 0.001567, epsilon: 0.050000, episode:  297\n",
            "frames: 537000, reward: 7.300000, loss: 0.002152, epsilon: 0.050000, episode:  297\n",
            "frames: 538000, reward: 7.900000, loss: 0.001243, epsilon: 0.050000, episode:  298\n",
            "frames: 539000, reward: 7.900000, loss: 0.001653, epsilon: 0.050000, episode:  298\n",
            "frames: 540000, reward: 7.900000, loss: 0.000645, epsilon: 0.050000, episode:  298\n",
            "frames: 541000, reward: 7.900000, loss: 0.001864, epsilon: 0.050000, episode:  298\n",
            "frames: 542000, reward: 8.900000, loss: 0.001338, epsilon: 0.050000, episode:  299\n",
            "frames: 543000, reward: 8.900000, loss: 0.001656, epsilon: 0.050000, episode:  299\n",
            "frames: 544000, reward: 8.900000, loss: 0.000986, epsilon: 0.050000, episode:  299\n",
            "frames: 545000, reward: 9.100000, loss: 0.000639, epsilon: 0.050000, episode:  300\n",
            "frames: 546000, reward: 9.100000, loss: 0.015798, epsilon: 0.050000, episode:  300\n",
            "frames: 547000, reward: 9.100000, loss: 0.001770, epsilon: 0.050000, episode:  300\n",
            "frames: 548000, reward: 9.200000, loss: 0.007346, epsilon: 0.050000, episode:  301\n",
            "frames: 549000, reward: 9.200000, loss: 0.001291, epsilon: 0.050000, episode:  301\n",
            "frames: 550000, reward: 9.200000, loss: 0.001848, epsilon: 0.050000, episode:  301\n",
            "frames: 551000, reward: 9.200000, loss: 0.002171, epsilon: 0.050000, episode:  301\n",
            "frames: 552000, reward: 9.300000, loss: 0.005358, epsilon: 0.050000, episode:  302\n",
            "frames: 553000, reward: 9.300000, loss: 0.000623, epsilon: 0.050000, episode:  302\n",
            "frames: 554000, reward: 9.300000, loss: 0.000850, epsilon: 0.050000, episode:  302\n",
            "frames: 555000, reward: 9.100000, loss: 0.009423, epsilon: 0.050000, episode:  303\n",
            "frames: 556000, reward: 9.100000, loss: 0.001829, epsilon: 0.050000, episode:  303\n",
            "frames: 557000, reward: 9.100000, loss: 0.001785, epsilon: 0.050000, episode:  303\n",
            "frames: 558000, reward: 8.500000, loss: 0.006227, epsilon: 0.050000, episode:  304\n",
            "frames: 559000, reward: 8.500000, loss: 0.001861, epsilon: 0.050000, episode:  304\n",
            "frames: 560000, reward: 8.500000, loss: 0.001794, epsilon: 0.050000, episode:  304\n",
            "frames: 561000, reward: 8.800000, loss: 0.001012, epsilon: 0.050000, episode:  305\n",
            "frames: 562000, reward: 8.800000, loss: 0.001177, epsilon: 0.050000, episode:  305\n",
            "frames: 563000, reward: 8.800000, loss: 0.000906, epsilon: 0.050000, episode:  305\n",
            "frames: 564000, reward: 8.300000, loss: 0.001323, epsilon: 0.050000, episode:  306\n",
            "frames: 565000, reward: 8.300000, loss: 0.001287, epsilon: 0.050000, episode:  306\n",
            "frames: 566000, reward: 8.300000, loss: 0.000973, epsilon: 0.050000, episode:  306\n",
            "frames: 567000, reward: 8.600000, loss: 0.002934, epsilon: 0.050000, episode:  307\n",
            "frames: 568000, reward: 8.600000, loss: 0.001366, epsilon: 0.050000, episode:  307\n",
            "frames: 569000, reward: 8.600000, loss: 0.001957, epsilon: 0.050000, episode:  307\n",
            "frames: 570000, reward: 7.600000, loss: 0.001916, epsilon: 0.050000, episode:  308\n",
            "frames: 571000, reward: 7.600000, loss: 0.001859, epsilon: 0.050000, episode:  308\n",
            "frames: 572000, reward: 7.600000, loss: 0.003199, epsilon: 0.050000, episode:  308\n",
            "frames: 573000, reward: 7.600000, loss: 0.002494, epsilon: 0.050000, episode:  309\n",
            "frames: 574000, reward: 7.600000, loss: 0.000720, epsilon: 0.050000, episode:  309\n",
            "frames: 575000, reward: 7.600000, loss: 0.000851, epsilon: 0.050000, episode:  309\n",
            "frames: 576000, reward: 8.100000, loss: 0.001180, epsilon: 0.050000, episode:  310\n",
            "frames: 577000, reward: 8.100000, loss: 0.000546, epsilon: 0.050000, episode:  310\n",
            "frames: 578000, reward: 8.100000, loss: 0.003908, epsilon: 0.050000, episode:  310\n",
            "frames: 579000, reward: 8.200000, loss: 0.001495, epsilon: 0.050000, episode:  311\n",
            "frames: 580000, reward: 8.200000, loss: 0.001961, epsilon: 0.050000, episode:  311\n",
            "frames: 581000, reward: 8.200000, loss: 0.001231, epsilon: 0.050000, episode:  311\n",
            "frames: 582000, reward: 8.200000, loss: 0.001324, epsilon: 0.050000, episode:  311\n",
            "frames: 583000, reward: 7.700000, loss: 0.001671, epsilon: 0.050000, episode:  312\n",
            "frames: 584000, reward: 7.700000, loss: 0.001059, epsilon: 0.050000, episode:  312\n",
            "frames: 585000, reward: 7.700000, loss: 0.002479, epsilon: 0.050000, episode:  312\n",
            "frames: 586000, reward: 7.300000, loss: 0.001699, epsilon: 0.050000, episode:  313\n",
            "frames: 587000, reward: 7.300000, loss: 0.001990, epsilon: 0.050000, episode:  313\n",
            "frames: 588000, reward: 7.300000, loss: 0.002013, epsilon: 0.050000, episode:  313\n",
            "frames: 589000, reward: 8.000000, loss: 0.002681, epsilon: 0.050000, episode:  314\n",
            "frames: 590000, reward: 8.000000, loss: 0.001132, epsilon: 0.050000, episode:  314\n",
            "frames: 591000, reward: 8.400000, loss: 0.001770, epsilon: 0.050000, episode:  315\n",
            "frames: 592000, reward: 8.400000, loss: 0.001356, epsilon: 0.050000, episode:  315\n",
            "frames: 593000, reward: 8.400000, loss: 0.001734, epsilon: 0.050000, episode:  315\n",
            "frames: 594000, reward: 8.400000, loss: 0.002741, epsilon: 0.050000, episode:  315\n",
            "frames: 595000, reward: 8.700000, loss: 0.008048, epsilon: 0.050000, episode:  316\n",
            "frames: 596000, reward: 8.700000, loss: 0.001286, epsilon: 0.050000, episode:  316\n",
            "frames: 597000, reward: 8.700000, loss: 0.001275, epsilon: 0.050000, episode:  316\n",
            "frames: 598000, reward: 8.700000, loss: 0.008307, epsilon: 0.050000, episode:  316\n",
            "frames: 599000, reward: 7.500000, loss: 0.001660, epsilon: 0.050000, episode:  317\n",
            "frames: 600000, reward: 7.500000, loss: 0.002709, epsilon: 0.050000, episode:  317\n",
            "frames: 601000, reward: 7.500000, loss: 0.001544, epsilon: 0.050000, episode:  317\n",
            "frames: 602000, reward: 7.900000, loss: 0.000984, epsilon: 0.050000, episode:  318\n",
            "frames: 603000, reward: 7.900000, loss: 0.001146, epsilon: 0.050000, episode:  318\n",
            "frames: 604000, reward: 7.900000, loss: 0.001487, epsilon: 0.050000, episode:  318\n",
            "frames: 605000, reward: 7.600000, loss: 0.001131, epsilon: 0.050000, episode:  319\n",
            "frames: 606000, reward: 7.600000, loss: 0.001046, epsilon: 0.050000, episode:  319\n",
            "frames: 607000, reward: 7.700000, loss: 0.002916, epsilon: 0.050000, episode:  320\n",
            "frames: 608000, reward: 7.700000, loss: 0.000895, epsilon: 0.050000, episode:  320\n",
            "frames: 609000, reward: 7.700000, loss: 0.000833, epsilon: 0.050000, episode:  320\n",
            "frames: 610000, reward: 7.800000, loss: 0.000496, epsilon: 0.050000, episode:  321\n",
            "frames: 611000, reward: 7.800000, loss: 0.004027, epsilon: 0.050000, episode:  321\n",
            "frames: 612000, reward: 7.800000, loss: 0.003368, epsilon: 0.050000, episode:  321\n",
            "frames: 613000, reward: 8.900000, loss: 0.001466, epsilon: 0.050000, episode:  322\n",
            "frames: 614000, reward: 8.900000, loss: 0.002535, epsilon: 0.050000, episode:  322\n",
            "frames: 615000, reward: 8.900000, loss: 0.001188, epsilon: 0.050000, episode:  322\n",
            "frames: 616000, reward: 9.500000, loss: 0.001544, epsilon: 0.050000, episode:  323\n",
            "frames: 617000, reward: 9.500000, loss: 0.002430, epsilon: 0.050000, episode:  323\n",
            "frames: 618000, reward: 8.600000, loss: 0.000869, epsilon: 0.050000, episode:  324\n",
            "frames: 619000, reward: 8.600000, loss: 0.001767, epsilon: 0.050000, episode:  324\n",
            "frames: 620000, reward: 8.600000, loss: 0.003203, epsilon: 0.050000, episode:  324\n",
            "frames: 621000, reward: 8.900000, loss: 0.000931, epsilon: 0.050000, episode:  325\n",
            "frames: 622000, reward: 8.900000, loss: 0.001196, epsilon: 0.050000, episode:  325\n",
            "frames: 623000, reward: 10.000000, loss: 0.001093, epsilon: 0.050000, episode:  326\n",
            "frames: 624000, reward: 10.000000, loss: 0.001482, epsilon: 0.050000, episode:  326\n",
            "frames: 625000, reward: 10.000000, loss: 0.004118, epsilon: 0.050000, episode:  326\n",
            "frames: 626000, reward: 10.500000, loss: 0.002152, epsilon: 0.050000, episode:  327\n",
            "frames: 627000, reward: 10.500000, loss: 0.000737, epsilon: 0.050000, episode:  327\n",
            "frames: 628000, reward: 10.500000, loss: 0.002223, epsilon: 0.050000, episode:  327\n",
            "frames: 629000, reward: 9.900000, loss: 0.000890, epsilon: 0.050000, episode:  328\n",
            "frames: 630000, reward: 9.900000, loss: 0.002274, epsilon: 0.050000, episode:  328\n",
            "frames: 631000, reward: 11.100000, loss: 0.001697, epsilon: 0.050000, episode:  329\n",
            "frames: 632000, reward: 11.100000, loss: 0.001779, epsilon: 0.050000, episode:  329\n",
            "frames: 633000, reward: 11.100000, loss: 0.001332, epsilon: 0.050000, episode:  329\n",
            "frames: 634000, reward: 11.300000, loss: 0.003015, epsilon: 0.050000, episode:  330\n",
            "frames: 635000, reward: 11.300000, loss: 0.002389, epsilon: 0.050000, episode:  330\n",
            "frames: 636000, reward: 11.700000, loss: 0.001695, epsilon: 0.050000, episode:  331\n",
            "frames: 637000, reward: 11.700000, loss: 0.001151, epsilon: 0.050000, episode:  331\n",
            "frames: 638000, reward: 11.700000, loss: 0.003372, epsilon: 0.050000, episode:  331\n",
            "frames: 639000, reward: 11.700000, loss: 0.001212, epsilon: 0.050000, episode:  332\n",
            "frames: 640000, reward: 11.700000, loss: 0.004315, epsilon: 0.050000, episode:  332\n",
            "frames: 641000, reward: 11.600000, loss: 0.001579, epsilon: 0.050000, episode:  333\n",
            "frames: 642000, reward: 11.600000, loss: 0.002608, epsilon: 0.050000, episode:  333\n",
            "frames: 643000, reward: 11.600000, loss: 0.000551, epsilon: 0.050000, episode:  333\n",
            "frames: 644000, reward: 12.800000, loss: 0.001189, epsilon: 0.050000, episode:  334\n",
            "frames: 645000, reward: 12.800000, loss: 0.001901, epsilon: 0.050000, episode:  334\n",
            "frames: 646000, reward: 12.900000, loss: 0.000787, epsilon: 0.050000, episode:  335\n",
            "frames: 647000, reward: 12.900000, loss: 0.002178, epsilon: 0.050000, episode:  335\n",
            "frames: 648000, reward: 12.400000, loss: 0.000878, epsilon: 0.050000, episode:  336\n",
            "frames: 649000, reward: 12.400000, loss: 0.000694, epsilon: 0.050000, episode:  336\n",
            "frames: 650000, reward: 13.500000, loss: 0.002385, epsilon: 0.050000, episode:  337\n",
            "frames: 651000, reward: 13.500000, loss: 0.000749, epsilon: 0.050000, episode:  337\n",
            "frames: 652000, reward: 13.500000, loss: 0.002909, epsilon: 0.050000, episode:  337\n",
            "frames: 653000, reward: 14.300000, loss: 0.003486, epsilon: 0.050000, episode:  338\n",
            "frames: 654000, reward: 14.300000, loss: 0.000765, epsilon: 0.050000, episode:  338\n",
            "frames: 655000, reward: 14.000000, loss: 0.001768, epsilon: 0.050000, episode:  339\n",
            "frames: 656000, reward: 14.000000, loss: 0.018747, epsilon: 0.050000, episode:  339\n",
            "frames: 657000, reward: 14.300000, loss: 0.014674, epsilon: 0.050000, episode:  340\n",
            "frames: 658000, reward: 14.300000, loss: 0.001100, epsilon: 0.050000, episode:  340\n",
            "frames: 659000, reward: 14.300000, loss: 0.010101, epsilon: 0.050000, episode:  340\n",
            "frames: 660000, reward: 14.100000, loss: 0.003834, epsilon: 0.050000, episode:  341\n",
            "frames: 661000, reward: 14.100000, loss: 0.003442, epsilon: 0.050000, episode:  341\n",
            "frames: 662000, reward: 14.000000, loss: 0.001873, epsilon: 0.050000, episode:  342\n",
            "frames: 663000, reward: 14.000000, loss: 0.000541, epsilon: 0.050000, episode:  342\n",
            "frames: 664000, reward: 14.000000, loss: 0.000810, epsilon: 0.050000, episode:  342\n",
            "frames: 665000, reward: 14.300000, loss: 0.001324, epsilon: 0.050000, episode:  343\n",
            "frames: 666000, reward: 14.300000, loss: 0.001220, epsilon: 0.050000, episode:  343\n",
            "frames: 667000, reward: 13.800000, loss: 0.001059, epsilon: 0.050000, episode:  344\n",
            "frames: 668000, reward: 13.800000, loss: 0.001206, epsilon: 0.050000, episode:  344\n",
            "frames: 669000, reward: 13.800000, loss: 0.001030, epsilon: 0.050000, episode:  344\n",
            "frames: 670000, reward: 13.200000, loss: 0.001180, epsilon: 0.050000, episode:  345\n",
            "frames: 671000, reward: 13.200000, loss: 0.000586, epsilon: 0.050000, episode:  345\n",
            "frames: 672000, reward: 13.500000, loss: 0.002017, epsilon: 0.050000, episode:  346\n",
            "frames: 673000, reward: 13.500000, loss: 0.001011, epsilon: 0.050000, episode:  346\n",
            "frames: 674000, reward: 13.300000, loss: 0.000871, epsilon: 0.050000, episode:  347\n",
            "frames: 675000, reward: 13.300000, loss: 0.001149, epsilon: 0.050000, episode:  347\n",
            "frames: 676000, reward: 13.600000, loss: 0.001041, epsilon: 0.050000, episode:  348\n",
            "frames: 677000, reward: 13.600000, loss: 0.003241, epsilon: 0.050000, episode:  348\n",
            "frames: 678000, reward: 13.600000, loss: 0.000646, epsilon: 0.050000, episode:  348\n",
            "frames: 679000, reward: 13.300000, loss: 0.001242, epsilon: 0.050000, episode:  349\n",
            "frames: 680000, reward: 13.300000, loss: 0.001199, epsilon: 0.050000, episode:  349\n",
            "frames: 681000, reward: 13.300000, loss: 0.000807, epsilon: 0.050000, episode:  349\n",
            "frames: 682000, reward: 12.900000, loss: 0.000918, epsilon: 0.050000, episode:  350\n",
            "frames: 683000, reward: 12.900000, loss: 0.001744, epsilon: 0.050000, episode:  350\n",
            "frames: 684000, reward: 12.300000, loss: 0.001754, epsilon: 0.050000, episode:  351\n",
            "frames: 685000, reward: 12.300000, loss: 0.000854, epsilon: 0.050000, episode:  351\n",
            "frames: 686000, reward: 12.300000, loss: 0.000745, epsilon: 0.050000, episode:  351\n",
            "frames: 687000, reward: 12.200000, loss: 0.004227, epsilon: 0.050000, episode:  352\n",
            "frames: 688000, reward: 12.200000, loss: 0.000878, epsilon: 0.050000, episode:  352\n",
            "frames: 689000, reward: 12.200000, loss: 0.000611, epsilon: 0.050000, episode:  352\n",
            "frames: 690000, reward: 11.600000, loss: 0.001643, epsilon: 0.050000, episode:  353\n",
            "frames: 691000, reward: 11.600000, loss: 0.001360, epsilon: 0.050000, episode:  353\n",
            "frames: 692000, reward: 12.000000, loss: 0.001421, epsilon: 0.050000, episode:  354\n",
            "frames: 693000, reward: 12.000000, loss: 0.002121, epsilon: 0.050000, episode:  354\n",
            "frames: 694000, reward: 12.500000, loss: 0.001040, epsilon: 0.050000, episode:  355\n",
            "frames: 695000, reward: 12.500000, loss: 0.001833, epsilon: 0.050000, episode:  355\n",
            "frames: 696000, reward: 12.500000, loss: 0.010069, epsilon: 0.050000, episode:  355\n",
            "frames: 697000, reward: 12.200000, loss: 0.003439, epsilon: 0.050000, episode:  356\n",
            "frames: 698000, reward: 12.200000, loss: 0.001603, epsilon: 0.050000, episode:  356\n",
            "frames: 699000, reward: 12.300000, loss: 0.001816, epsilon: 0.050000, episode:  357\n",
            "frames: 700000, reward: 12.300000, loss: 0.002519, epsilon: 0.050000, episode:  357\n",
            "frames: 701000, reward: 12.200000, loss: 0.001589, epsilon: 0.050000, episode:  358\n",
            "frames: 702000, reward: 12.200000, loss: 0.000827, epsilon: 0.050000, episode:  358\n",
            "frames: 703000, reward: 12.800000, loss: 0.000730, epsilon: 0.050000, episode:  359\n",
            "frames: 704000, reward: 12.800000, loss: 0.000977, epsilon: 0.050000, episode:  359\n",
            "frames: 705000, reward: 12.800000, loss: 0.003047, epsilon: 0.050000, episode:  359\n",
            "frames: 706000, reward: 13.200000, loss: 0.000538, epsilon: 0.050000, episode:  360\n",
            "frames: 707000, reward: 13.200000, loss: 0.000796, epsilon: 0.050000, episode:  360\n",
            "frames: 708000, reward: 14.200000, loss: 0.001140, epsilon: 0.050000, episode:  361\n",
            "frames: 709000, reward: 14.200000, loss: 0.001537, epsilon: 0.050000, episode:  361\n",
            "frames: 710000, reward: 12.200000, loss: 0.000653, epsilon: 0.050000, episode:  362\n",
            "frames: 711000, reward: 12.200000, loss: 0.000750, epsilon: 0.050000, episode:  362\n",
            "frames: 712000, reward: 13.100000, loss: 0.001376, epsilon: 0.050000, episode:  363\n",
            "frames: 713000, reward: 13.100000, loss: 0.001061, epsilon: 0.050000, episode:  363\n",
            "frames: 714000, reward: 13.100000, loss: 0.007689, epsilon: 0.050000, episode:  363\n",
            "frames: 715000, reward: 12.700000, loss: 0.002235, epsilon: 0.050000, episode:  364\n",
            "frames: 716000, reward: 12.700000, loss: 0.000648, epsilon: 0.050000, episode:  364\n",
            "frames: 717000, reward: 12.500000, loss: 0.000266, epsilon: 0.050000, episode:  365\n",
            "frames: 718000, reward: 12.500000, loss: 0.001000, epsilon: 0.050000, episode:  365\n",
            "frames: 719000, reward: 12.900000, loss: 0.001463, epsilon: 0.050000, episode:  366\n",
            "frames: 720000, reward: 12.900000, loss: 0.003625, epsilon: 0.050000, episode:  366\n",
            "frames: 721000, reward: 12.900000, loss: 0.001465, epsilon: 0.050000, episode:  366\n",
            "frames: 722000, reward: 12.500000, loss: 0.000862, epsilon: 0.050000, episode:  367\n",
            "frames: 723000, reward: 12.500000, loss: 0.002071, epsilon: 0.050000, episode:  367\n",
            "frames: 724000, reward: 12.600000, loss: 0.001564, epsilon: 0.050000, episode:  368\n",
            "frames: 725000, reward: 12.600000, loss: 0.001226, epsilon: 0.050000, episode:  368\n",
            "frames: 726000, reward: 12.600000, loss: 0.001111, epsilon: 0.050000, episode:  368\n",
            "frames: 727000, reward: 12.400000, loss: 0.001799, epsilon: 0.050000, episode:  369\n",
            "frames: 728000, reward: 12.400000, loss: 0.000946, epsilon: 0.050000, episode:  369\n",
            "frames: 729000, reward: 12.300000, loss: 0.001706, epsilon: 0.050000, episode:  370\n",
            "frames: 730000, reward: 12.300000, loss: 0.000816, epsilon: 0.050000, episode:  370\n",
            "frames: 731000, reward: 11.900000, loss: 0.008049, epsilon: 0.050000, episode:  371\n",
            "frames: 732000, reward: 11.900000, loss: 0.001069, epsilon: 0.050000, episode:  371\n",
            "frames: 733000, reward: 14.600000, loss: 0.000918, epsilon: 0.050000, episode:  372\n",
            "frames: 734000, reward: 14.600000, loss: 0.000694, epsilon: 0.050000, episode:  372\n",
            "frames: 735000, reward: 14.300000, loss: 0.002396, epsilon: 0.050000, episode:  373\n",
            "frames: 736000, reward: 14.300000, loss: 0.000668, epsilon: 0.050000, episode:  373\n",
            "frames: 737000, reward: 14.300000, loss: 0.001446, epsilon: 0.050000, episode:  373\n",
            "frames: 738000, reward: 14.500000, loss: 0.000910, epsilon: 0.050000, episode:  374\n",
            "frames: 739000, reward: 14.500000, loss: 0.001360, epsilon: 0.050000, episode:  374\n",
            "frames: 740000, reward: 14.800000, loss: 0.003875, epsilon: 0.050000, episode:  375\n",
            "frames: 741000, reward: 14.800000, loss: 0.000860, epsilon: 0.050000, episode:  375\n",
            "frames: 742000, reward: 14.600000, loss: 0.001900, epsilon: 0.050000, episode:  376\n",
            "frames: 743000, reward: 15.100000, loss: 0.006455, epsilon: 0.050000, episode:  377\n",
            "frames: 744000, reward: 15.100000, loss: 0.001464, epsilon: 0.050000, episode:  377\n",
            "frames: 745000, reward: 15.100000, loss: 0.000563, epsilon: 0.050000, episode:  377\n",
            "frames: 746000, reward: 14.900000, loss: 0.000728, epsilon: 0.050000, episode:  378\n",
            "frames: 747000, reward: 14.900000, loss: 0.000975, epsilon: 0.050000, episode:  378\n",
            "frames: 748000, reward: 14.600000, loss: 0.001341, epsilon: 0.050000, episode:  379\n",
            "frames: 749000, reward: 14.600000, loss: 0.001547, epsilon: 0.050000, episode:  379\n",
            "frames: 750000, reward: 15.100000, loss: 0.000975, epsilon: 0.050000, episode:  380\n",
            "frames: 751000, reward: 15.100000, loss: 0.000858, epsilon: 0.050000, episode:  380\n",
            "frames: 752000, reward: 15.100000, loss: 0.001054, epsilon: 0.050000, episode:  380\n",
            "frames: 753000, reward: 15.100000, loss: 0.001300, epsilon: 0.050000, episode:  381\n",
            "frames: 754000, reward: 15.100000, loss: 0.000786, epsilon: 0.050000, episode:  381\n",
            "frames: 755000, reward: 14.400000, loss: 0.002056, epsilon: 0.050000, episode:  382\n",
            "frames: 756000, reward: 14.400000, loss: 0.000555, epsilon: 0.050000, episode:  382\n",
            "frames: 757000, reward: 14.600000, loss: 0.001114, epsilon: 0.050000, episode:  383\n",
            "frames: 758000, reward: 14.600000, loss: 0.000676, epsilon: 0.050000, episode:  383\n",
            "frames: 759000, reward: 14.600000, loss: 0.001635, epsilon: 0.050000, episode:  384\n",
            "frames: 760000, reward: 14.600000, loss: 0.000524, epsilon: 0.050000, episode:  384\n",
            "frames: 761000, reward: 14.900000, loss: 0.001077, epsilon: 0.050000, episode:  385\n",
            "frames: 762000, reward: 14.900000, loss: 0.000487, epsilon: 0.050000, episode:  385\n",
            "frames: 763000, reward: 15.000000, loss: 0.005408, epsilon: 0.050000, episode:  386\n",
            "frames: 764000, reward: 15.000000, loss: 0.000805, epsilon: 0.050000, episode:  386\n",
            "frames: 765000, reward: 14.800000, loss: 0.003092, epsilon: 0.050000, episode:  387\n",
            "frames: 766000, reward: 14.800000, loss: 0.000456, epsilon: 0.050000, episode:  387\n",
            "frames: 767000, reward: 14.900000, loss: 0.001649, epsilon: 0.050000, episode:  388\n",
            "frames: 768000, reward: 14.900000, loss: 0.001078, epsilon: 0.050000, episode:  388\n",
            "frames: 769000, reward: 15.200000, loss: 0.004697, epsilon: 0.050000, episode:  389\n",
            "frames: 770000, reward: 15.200000, loss: 0.001665, epsilon: 0.050000, episode:  389\n",
            "frames: 771000, reward: 15.200000, loss: 0.001305, epsilon: 0.050000, episode:  389\n",
            "frames: 772000, reward: 14.900000, loss: 0.000943, epsilon: 0.050000, episode:  390\n",
            "frames: 773000, reward: 14.900000, loss: 0.000570, epsilon: 0.050000, episode:  390\n",
            "frames: 774000, reward: 14.900000, loss: 0.002184, epsilon: 0.050000, episode:  391\n",
            "frames: 775000, reward: 14.900000, loss: 0.000394, epsilon: 0.050000, episode:  391\n",
            "frames: 776000, reward: 15.400000, loss: 0.001204, epsilon: 0.050000, episode:  392\n",
            "frames: 777000, reward: 15.400000, loss: 0.000851, epsilon: 0.050000, episode:  392\n",
            "frames: 778000, reward: 15.900000, loss: 0.001441, epsilon: 0.050000, episode:  393\n",
            "frames: 779000, reward: 15.900000, loss: 0.000775, epsilon: 0.050000, episode:  393\n",
            "frames: 780000, reward: 16.300000, loss: 0.000791, epsilon: 0.050000, episode:  394\n",
            "frames: 781000, reward: 16.300000, loss: 0.001182, epsilon: 0.050000, episode:  394\n",
            "frames: 782000, reward: 15.300000, loss: 0.002023, epsilon: 0.050000, episode:  395\n",
            "frames: 783000, reward: 15.300000, loss: 0.000651, epsilon: 0.050000, episode:  395\n",
            "frames: 784000, reward: 15.300000, loss: 0.000494, epsilon: 0.050000, episode:  395\n",
            "frames: 785000, reward: 14.700000, loss: 0.000272, epsilon: 0.050000, episode:  396\n",
            "frames: 786000, reward: 14.700000, loss: 0.000454, epsilon: 0.050000, episode:  396\n",
            "frames: 787000, reward: 15.100000, loss: 0.000953, epsilon: 0.050000, episode:  397\n",
            "frames: 788000, reward: 15.100000, loss: 0.002173, epsilon: 0.050000, episode:  397\n",
            "frames: 789000, reward: 15.600000, loss: 0.002826, epsilon: 0.050000, episode:  398\n",
            "frames: 790000, reward: 15.600000, loss: 0.002211, epsilon: 0.050000, episode:  398\n",
            "frames: 791000, reward: 15.900000, loss: 0.000578, epsilon: 0.050000, episode:  399\n",
            "frames: 792000, reward: 15.900000, loss: 0.001076, epsilon: 0.050000, episode:  399\n",
            "frames: 793000, reward: 15.800000, loss: 0.001163, epsilon: 0.050000, episode:  400\n",
            "frames: 794000, reward: 15.800000, loss: 0.001069, epsilon: 0.050000, episode:  400\n",
            "frames: 795000, reward: 15.900000, loss: 0.000424, epsilon: 0.050000, episode:  401\n",
            "frames: 796000, reward: 15.900000, loss: 0.001092, epsilon: 0.050000, episode:  401\n",
            "frames: 797000, reward: 16.100000, loss: 0.000554, epsilon: 0.050000, episode:  402\n",
            "frames: 798000, reward: 16.100000, loss: 0.006561, epsilon: 0.050000, episode:  402\n",
            "frames: 799000, reward: 15.500000, loss: 0.000567, epsilon: 0.050000, episode:  403\n",
            "frames: 800000, reward: 15.500000, loss: 0.000360, epsilon: 0.050000, episode:  403\n",
            "frames: 801000, reward: 15.500000, loss: 0.000867, epsilon: 0.050000, episode:  404\n",
            "frames: 802000, reward: 15.500000, loss: 0.001075, epsilon: 0.050000, episode:  404\n",
            "frames: 803000, reward: 16.500000, loss: 0.000626, epsilon: 0.050000, episode:  405\n",
            "frames: 804000, reward: 16.500000, loss: 0.000744, epsilon: 0.050000, episode:  405\n",
            "frames: 805000, reward: 17.000000, loss: 0.001423, epsilon: 0.050000, episode:  406\n",
            "frames: 806000, reward: 17.000000, loss: 0.000631, epsilon: 0.050000, episode:  406\n",
            "frames: 807000, reward: 16.900000, loss: 0.000610, epsilon: 0.050000, episode:  407\n",
            "frames: 808000, reward: 16.900000, loss: 0.000705, epsilon: 0.050000, episode:  407\n",
            "frames: 809000, reward: 16.400000, loss: 0.000978, epsilon: 0.050000, episode:  408\n",
            "frames: 810000, reward: 16.400000, loss: 0.000380, epsilon: 0.050000, episode:  408\n",
            "frames: 811000, reward: 16.400000, loss: 0.001807, epsilon: 0.050000, episode:  409\n",
            "frames: 812000, reward: 16.400000, loss: 0.002698, epsilon: 0.050000, episode:  409\n",
            "frames: 813000, reward: 16.500000, loss: 0.001085, epsilon: 0.050000, episode:  410\n",
            "frames: 814000, reward: 16.500000, loss: 0.000386, epsilon: 0.050000, episode:  410\n",
            "frames: 815000, reward: 16.800000, loss: 0.001090, epsilon: 0.050000, episode:  411\n",
            "frames: 816000, reward: 16.800000, loss: 0.000452, epsilon: 0.050000, episode:  411\n",
            "frames: 817000, reward: 16.800000, loss: 0.000536, epsilon: 0.050000, episode:  412\n",
            "frames: 818000, reward: 16.800000, loss: 0.001297, epsilon: 0.050000, episode:  412\n",
            "frames: 819000, reward: 17.200000, loss: 0.000220, epsilon: 0.050000, episode:  413\n",
            "frames: 820000, reward: 17.200000, loss: 0.000559, epsilon: 0.050000, episode:  413\n",
            "frames: 821000, reward: 17.300000, loss: 0.001238, epsilon: 0.050000, episode:  414\n",
            "frames: 822000, reward: 17.300000, loss: 0.000708, epsilon: 0.050000, episode:  414\n",
            "frames: 823000, reward: 17.300000, loss: 0.000483, epsilon: 0.050000, episode:  415\n",
            "frames: 824000, reward: 17.300000, loss: 0.000473, epsilon: 0.050000, episode:  415\n",
            "frames: 825000, reward: 17.500000, loss: 0.001087, epsilon: 0.050000, episode:  416\n",
            "frames: 826000, reward: 17.500000, loss: 0.000786, epsilon: 0.050000, episode:  416\n",
            "frames: 827000, reward: 17.400000, loss: 0.000592, epsilon: 0.050000, episode:  417\n",
            "frames: 828000, reward: 17.400000, loss: 0.001353, epsilon: 0.050000, episode:  417\n",
            "frames: 829000, reward: 17.800000, loss: 0.000612, epsilon: 0.050000, episode:  418\n",
            "frames: 830000, reward: 18.000000, loss: 0.000719, epsilon: 0.050000, episode:  419\n",
            "frames: 831000, reward: 18.000000, loss: 0.001990, epsilon: 0.050000, episode:  419\n",
            "frames: 832000, reward: 18.000000, loss: 0.000457, epsilon: 0.050000, episode:  419\n",
            "frames: 833000, reward: 18.200000, loss: 0.000621, epsilon: 0.050000, episode:  420\n",
            "frames: 834000, reward: 18.200000, loss: 0.000568, epsilon: 0.050000, episode:  420\n",
            "frames: 835000, reward: 18.000000, loss: 0.000478, epsilon: 0.050000, episode:  421\n",
            "frames: 836000, reward: 18.000000, loss: 0.000359, epsilon: 0.050000, episode:  421\n",
            "frames: 837000, reward: 17.300000, loss: 0.000410, epsilon: 0.050000, episode:  422\n",
            "frames: 838000, reward: 17.300000, loss: 0.000945, epsilon: 0.050000, episode:  422\n",
            "frames: 839000, reward: 17.000000, loss: 0.000806, epsilon: 0.050000, episode:  423\n",
            "frames: 840000, reward: 17.000000, loss: 0.004243, epsilon: 0.050000, episode:  423\n",
            "frames: 841000, reward: 16.800000, loss: 0.000342, epsilon: 0.050000, episode:  424\n",
            "frames: 842000, reward: 16.800000, loss: 0.001129, epsilon: 0.050000, episode:  424\n",
            "frames: 843000, reward: 16.700000, loss: 0.002673, epsilon: 0.050000, episode:  425\n",
            "frames: 844000, reward: 16.700000, loss: 0.000299, epsilon: 0.050000, episode:  425\n",
            "frames: 845000, reward: 16.700000, loss: 0.000553, epsilon: 0.050000, episode:  425\n",
            "frames: 846000, reward: 16.200000, loss: 0.001072, epsilon: 0.050000, episode:  426\n",
            "frames: 847000, reward: 16.200000, loss: 0.000531, epsilon: 0.050000, episode:  426\n",
            "frames: 848000, reward: 16.000000, loss: 0.000529, epsilon: 0.050000, episode:  427\n",
            "frames: 849000, reward: 16.000000, loss: 0.000762, epsilon: 0.050000, episode:  427\n",
            "frames: 850000, reward: 15.700000, loss: 0.000339, epsilon: 0.050000, episode:  428\n",
            "frames: 851000, reward: 15.700000, loss: 0.000771, epsilon: 0.050000, episode:  428\n",
            "frames: 852000, reward: 15.300000, loss: 0.000795, epsilon: 0.050000, episode:  429\n",
            "frames: 853000, reward: 15.300000, loss: 0.000410, epsilon: 0.050000, episode:  429\n",
            "frames: 854000, reward: 15.100000, loss: 0.000323, epsilon: 0.050000, episode:  430\n",
            "frames: 855000, reward: 15.100000, loss: 0.000332, epsilon: 0.050000, episode:  430\n",
            "frames: 856000, reward: 15.100000, loss: 0.000298, epsilon: 0.050000, episode:  430\n",
            "frames: 857000, reward: 15.100000, loss: 0.000288, epsilon: 0.050000, episode:  431\n",
            "frames: 858000, reward: 15.700000, loss: 0.000364, epsilon: 0.050000, episode:  432\n",
            "frames: 859000, reward: 15.700000, loss: 0.000384, epsilon: 0.050000, episode:  432\n",
            "frames: 860000, reward: 15.700000, loss: 0.000402, epsilon: 0.050000, episode:  432\n",
            "frames: 861000, reward: 16.000000, loss: 0.002327, epsilon: 0.050000, episode:  433\n",
            "frames: 862000, reward: 16.200000, loss: 0.000489, epsilon: 0.050000, episode:  434\n",
            "frames: 863000, reward: 16.200000, loss: 0.001068, epsilon: 0.050000, episode:  434\n",
            "frames: 864000, reward: 16.200000, loss: 0.000304, epsilon: 0.050000, episode:  435\n",
            "frames: 865000, reward: 16.200000, loss: 0.000517, epsilon: 0.050000, episode:  435\n",
            "frames: 866000, reward: 16.700000, loss: 0.000578, epsilon: 0.050000, episode:  436\n",
            "frames: 867000, reward: 16.700000, loss: 0.000495, epsilon: 0.050000, episode:  436\n",
            "frames: 868000, reward: 17.000000, loss: 0.000455, epsilon: 0.050000, episode:  437\n",
            "frames: 869000, reward: 17.000000, loss: 0.000565, epsilon: 0.050000, episode:  437\n",
            "frames: 870000, reward: 17.200000, loss: 0.000682, epsilon: 0.050000, episode:  438\n",
            "frames: 871000, reward: 17.200000, loss: 0.000446, epsilon: 0.050000, episode:  438\n",
            "frames: 872000, reward: 17.400000, loss: 0.000359, epsilon: 0.050000, episode:  439\n",
            "frames: 873000, reward: 17.400000, loss: 0.000609, epsilon: 0.050000, episode:  439\n",
            "frames: 874000, reward: 17.500000, loss: 0.000743, epsilon: 0.050000, episode:  440\n",
            "frames: 875000, reward: 17.500000, loss: 0.001798, epsilon: 0.050000, episode:  440\n",
            "frames: 876000, reward: 17.500000, loss: 0.000346, epsilon: 0.050000, episode:  441\n",
            "frames: 877000, reward: 17.500000, loss: 0.000617, epsilon: 0.050000, episode:  441\n",
            "frames: 878000, reward: 17.400000, loss: 0.000310, epsilon: 0.050000, episode:  442\n",
            "frames: 879000, reward: 17.400000, loss: 0.000693, epsilon: 0.050000, episode:  442\n",
            "frames: 880000, reward: 17.400000, loss: 0.001077, epsilon: 0.050000, episode:  443\n",
            "frames: 881000, reward: 17.400000, loss: 0.000376, epsilon: 0.050000, episode:  443\n",
            "frames: 882000, reward: 17.500000, loss: 0.001211, epsilon: 0.050000, episode:  444\n",
            "frames: 883000, reward: 17.500000, loss: 0.000485, epsilon: 0.050000, episode:  444\n",
            "frames: 884000, reward: 17.500000, loss: 0.001605, epsilon: 0.050000, episode:  445\n",
            "frames: 885000, reward: 17.500000, loss: 0.002931, epsilon: 0.050000, episode:  445\n",
            "frames: 886000, reward: 17.600000, loss: 0.000412, epsilon: 0.050000, episode:  446\n",
            "frames: 887000, reward: 17.600000, loss: 0.000514, epsilon: 0.050000, episode:  446\n",
            "frames: 888000, reward: 17.500000, loss: 0.000645, epsilon: 0.050000, episode:  447\n",
            "frames: 889000, reward: 17.500000, loss: 0.000320, epsilon: 0.050000, episode:  447\n",
            "frames: 890000, reward: 17.500000, loss: 0.000760, epsilon: 0.050000, episode:  448\n",
            "frames: 891000, reward: 17.500000, loss: 0.000491, epsilon: 0.050000, episode:  448\n",
            "frames: 892000, reward: 17.700000, loss: 0.000973, epsilon: 0.050000, episode:  449\n",
            "frames: 893000, reward: 17.700000, loss: 0.000399, epsilon: 0.050000, episode:  449\n",
            "frames: 894000, reward: 17.500000, loss: 0.000669, epsilon: 0.050000, episode:  450\n",
            "frames: 895000, reward: 17.500000, loss: 0.001719, epsilon: 0.050000, episode:  450\n",
            "frames: 896000, reward: 17.700000, loss: 0.000822, epsilon: 0.050000, episode:  451\n",
            "frames: 897000, reward: 17.700000, loss: 0.001136, epsilon: 0.050000, episode:  451\n",
            "frames: 898000, reward: 17.400000, loss: 0.000226, epsilon: 0.050000, episode:  452\n",
            "frames: 899000, reward: 17.400000, loss: 0.000393, epsilon: 0.050000, episode:  452\n",
            "frames: 900000, reward: 17.200000, loss: 0.000372, epsilon: 0.050000, episode:  453\n",
            "frames: 901000, reward: 17.200000, loss: 0.000706, epsilon: 0.050000, episode:  453\n",
            "frames: 902000, reward: 17.000000, loss: 0.000566, epsilon: 0.050000, episode:  454\n",
            "frames: 903000, reward: 17.000000, loss: 0.000329, epsilon: 0.050000, episode:  454\n",
            "frames: 904000, reward: 17.200000, loss: 0.000228, epsilon: 0.050000, episode:  455\n",
            "frames: 905000, reward: 17.200000, loss: 0.000284, epsilon: 0.050000, episode:  455\n",
            "frames: 906000, reward: 17.400000, loss: 0.000298, epsilon: 0.050000, episode:  456\n",
            "frames: 907000, reward: 17.400000, loss: 0.000315, epsilon: 0.050000, episode:  456\n",
            "frames: 908000, reward: 17.400000, loss: 0.000394, epsilon: 0.050000, episode:  457\n",
            "frames: 909000, reward: 17.400000, loss: 0.000296, epsilon: 0.050000, episode:  457\n",
            "frames: 910000, reward: 17.600000, loss: 0.000745, epsilon: 0.050000, episode:  458\n",
            "frames: 911000, reward: 17.600000, loss: 0.000234, epsilon: 0.050000, episode:  458\n",
            "frames: 912000, reward: 17.100000, loss: 0.000579, epsilon: 0.050000, episode:  459\n",
            "frames: 913000, reward: 17.100000, loss: 0.000443, epsilon: 0.050000, episode:  459\n",
            "frames: 914000, reward: 17.400000, loss: 0.000521, epsilon: 0.050000, episode:  460\n",
            "frames: 915000, reward: 17.400000, loss: 0.000250, epsilon: 0.050000, episode:  460\n",
            "frames: 916000, reward: 17.500000, loss: 0.000700, epsilon: 0.050000, episode:  461\n",
            "frames: 917000, reward: 17.500000, loss: 0.000230, epsilon: 0.050000, episode:  461\n",
            "frames: 918000, reward: 17.900000, loss: 0.000350, epsilon: 0.050000, episode:  462\n",
            "frames: 919000, reward: 17.900000, loss: 0.000214, epsilon: 0.050000, episode:  462\n",
            "frames: 920000, reward: 18.300000, loss: 0.000927, epsilon: 0.050000, episode:  463\n",
            "frames: 921000, reward: 18.300000, loss: 0.000154, epsilon: 0.050000, episode:  463\n",
            "frames: 922000, reward: 18.200000, loss: 0.000338, epsilon: 0.050000, episode:  464\n",
            "frames: 923000, reward: 18.200000, loss: 0.000746, epsilon: 0.050000, episode:  464\n",
            "frames: 924000, reward: 17.700000, loss: 0.000200, epsilon: 0.050000, episode:  465\n",
            "frames: 925000, reward: 17.700000, loss: 0.001705, epsilon: 0.050000, episode:  466\n",
            "frames: 926000, reward: 17.700000, loss: 0.001488, epsilon: 0.050000, episode:  466\n",
            "frames: 927000, reward: 17.700000, loss: 0.000654, epsilon: 0.050000, episode:  467\n",
            "frames: 928000, reward: 17.700000, loss: 0.000388, epsilon: 0.050000, episode:  467\n",
            "frames: 929000, reward: 17.700000, loss: 0.000330, epsilon: 0.050000, episode:  467\n",
            "frames: 930000, reward: 17.200000, loss: 0.000507, epsilon: 0.050000, episode:  468\n",
            "frames: 931000, reward: 17.700000, loss: 0.000423, epsilon: 0.050000, episode:  469\n",
            "frames: 932000, reward: 17.700000, loss: 0.003935, epsilon: 0.050000, episode:  469\n",
            "frames: 933000, reward: 17.500000, loss: 0.000348, epsilon: 0.050000, episode:  470\n",
            "frames: 934000, reward: 17.500000, loss: 0.000223, epsilon: 0.050000, episode:  470\n",
            "frames: 935000, reward: 17.400000, loss: 0.000317, epsilon: 0.050000, episode:  471\n",
            "frames: 936000, reward: 17.400000, loss: 0.000887, epsilon: 0.050000, episode:  471\n",
            "frames: 937000, reward: 17.600000, loss: 0.000587, epsilon: 0.050000, episode:  472\n",
            "frames: 938000, reward: 17.600000, loss: 0.000421, epsilon: 0.050000, episode:  472\n",
            "frames: 939000, reward: 17.600000, loss: 0.000382, epsilon: 0.050000, episode:  473\n",
            "frames: 940000, reward: 17.600000, loss: 0.001768, epsilon: 0.050000, episode:  473\n",
            "frames: 941000, reward: 17.800000, loss: 0.000285, epsilon: 0.050000, episode:  474\n",
            "frames: 942000, reward: 17.800000, loss: 0.000852, epsilon: 0.050000, episode:  474\n",
            "frames: 943000, reward: 17.300000, loss: 0.000237, epsilon: 0.050000, episode:  475\n",
            "frames: 944000, reward: 17.300000, loss: 0.000471, epsilon: 0.050000, episode:  475\n",
            "frames: 945000, reward: 17.200000, loss: 0.002197, epsilon: 0.050000, episode:  476\n",
            "frames: 946000, reward: 17.200000, loss: 0.000691, epsilon: 0.050000, episode:  476\n",
            "frames: 947000, reward: 17.100000, loss: 0.000518, epsilon: 0.050000, episode:  477\n",
            "frames: 948000, reward: 17.100000, loss: 0.001289, epsilon: 0.050000, episode:  477\n",
            "frames: 949000, reward: 17.400000, loss: 0.000270, epsilon: 0.050000, episode:  478\n",
            "frames: 950000, reward: 17.400000, loss: 0.001284, epsilon: 0.050000, episode:  478\n",
            "frames: 951000, reward: 17.400000, loss: 0.000402, epsilon: 0.050000, episode:  478\n",
            "frames: 952000, reward: 16.600000, loss: 0.000887, epsilon: 0.050000, episode:  479\n",
            "frames: 953000, reward: 16.600000, loss: 0.000391, epsilon: 0.050000, episode:  479\n",
            "frames: 954000, reward: 16.800000, loss: 0.000778, epsilon: 0.050000, episode:  480\n",
            "frames: 955000, reward: 16.800000, loss: 0.001606, epsilon: 0.050000, episode:  480\n",
            "frames: 956000, reward: 16.700000, loss: 0.006315, epsilon: 0.050000, episode:  481\n",
            "frames: 957000, reward: 16.700000, loss: 0.000325, epsilon: 0.050000, episode:  481\n",
            "frames: 958000, reward: 16.400000, loss: 0.000436, epsilon: 0.050000, episode:  482\n",
            "frames: 959000, reward: 16.400000, loss: 0.000184, epsilon: 0.050000, episode:  482\n",
            "frames: 960000, reward: 16.200000, loss: 0.000241, epsilon: 0.050000, episode:  483\n",
            "frames: 961000, reward: 16.200000, loss: 0.000276, epsilon: 0.050000, episode:  483\n",
            "frames: 962000, reward: 16.200000, loss: 0.000345, epsilon: 0.050000, episode:  484\n",
            "frames: 963000, reward: 16.200000, loss: 0.000199, epsilon: 0.050000, episode:  484\n",
            "frames: 964000, reward: 16.800000, loss: 0.000806, epsilon: 0.050000, episode:  485\n",
            "frames: 965000, reward: 16.800000, loss: 0.000280, epsilon: 0.050000, episode:  485\n",
            "frames: 966000, reward: 16.400000, loss: 0.001117, epsilon: 0.050000, episode:  486\n",
            "frames: 967000, reward: 16.400000, loss: 0.000466, epsilon: 0.050000, episode:  486\n",
            "frames: 968000, reward: 16.400000, loss: 0.001194, epsilon: 0.050000, episode:  487\n",
            "frames: 969000, reward: 16.400000, loss: 0.000425, epsilon: 0.050000, episode:  487\n",
            "frames: 970000, reward: 16.400000, loss: 0.001438, epsilon: 0.050000, episode:  488\n",
            "frames: 971000, reward: 16.400000, loss: 0.000292, epsilon: 0.050000, episode:  488\n",
            "frames: 972000, reward: 17.100000, loss: 0.001630, epsilon: 0.050000, episode:  489\n",
            "frames: 973000, reward: 17.100000, loss: 0.000247, epsilon: 0.050000, episode:  489\n",
            "frames: 974000, reward: 16.900000, loss: 0.000440, epsilon: 0.050000, episode:  490\n",
            "frames: 975000, reward: 16.900000, loss: 0.000488, epsilon: 0.050000, episode:  490\n",
            "frames: 976000, reward: 16.900000, loss: 0.000528, epsilon: 0.050000, episode:  490\n",
            "frames: 977000, reward: 16.700000, loss: 0.001330, epsilon: 0.050000, episode:  491\n",
            "frames: 978000, reward: 16.700000, loss: 0.002959, epsilon: 0.050000, episode:  491\n",
            "frames: 979000, reward: 16.600000, loss: 0.000376, epsilon: 0.050000, episode:  492\n",
            "frames: 980000, reward: 16.600000, loss: 0.001471, epsilon: 0.050000, episode:  492\n",
            "frames: 981000, reward: 16.600000, loss: 0.000704, epsilon: 0.050000, episode:  493\n",
            "frames: 982000, reward: 16.800000, loss: 0.001033, epsilon: 0.050000, episode:  494\n",
            "frames: 983000, reward: 16.800000, loss: 0.000419, epsilon: 0.050000, episode:  494\n",
            "frames: 984000, reward: 16.800000, loss: 0.000814, epsilon: 0.050000, episode:  494\n",
            "frames: 985000, reward: 16.900000, loss: 0.000527, epsilon: 0.050000, episode:  495\n",
            "frames: 986000, reward: 17.100000, loss: 0.001049, epsilon: 0.050000, episode:  496\n",
            "frames: 987000, reward: 17.100000, loss: 0.000908, epsilon: 0.050000, episode:  496\n",
            "frames: 988000, reward: 17.100000, loss: 0.000253, epsilon: 0.050000, episode:  496\n",
            "frames: 989000, reward: 17.200000, loss: 0.000190, epsilon: 0.050000, episode:  497\n",
            "frames: 990000, reward: 17.400000, loss: 0.000519, epsilon: 0.050000, episode:  498\n",
            "frames: 991000, reward: 17.400000, loss: 0.000625, epsilon: 0.050000, episode:  498\n",
            "frames: 992000, reward: 17.200000, loss: 0.000627, epsilon: 0.050000, episode:  499\n",
            "frames: 993000, reward: 17.200000, loss: 0.000566, epsilon: 0.050000, episode:  499\n",
            "frames: 994000, reward: 17.200000, loss: 0.000221, epsilon: 0.050000, episode:  499\n",
            "frames: 995000, reward: 16.800000, loss: 0.000253, epsilon: 0.050000, episode:  500\n",
            "frames: 996000, reward: 16.800000, loss: 0.000342, epsilon: 0.050000, episode:  500\n",
            "frames: 997000, reward: 15.400000, loss: 0.000643, epsilon: 0.050000, episode:  501\n",
            "frames: 998000, reward: 15.400000, loss: 0.001196, epsilon: 0.050000, episode:  501\n",
            "frames: 999000, reward: 15.400000, loss: 0.000968, epsilon: 0.050000, episode:  501\n",
            "frames: 1000000, reward: 15.300000, loss: 0.000249, epsilon: 0.050000, episode:  502\n",
            "frames: 1001000, reward: 15.300000, loss: 0.000278, epsilon: 0.050000, episode:  502\n",
            "frames: 1002000, reward: 15.200000, loss: 0.000622, epsilon: 0.050000, episode:  503\n",
            "frames: 1003000, reward: 15.000000, loss: 0.000393, epsilon: 0.050000, episode:  504\n",
            "frames: 1004000, reward: 15.000000, loss: 0.000234, epsilon: 0.050000, episode:  504\n",
            "frames: 1005000, reward: 15.300000, loss: 0.002890, epsilon: 0.050000, episode:  505\n",
            "frames: 1006000, reward: 15.300000, loss: 0.005563, epsilon: 0.050000, episode:  505\n",
            "frames: 1007000, reward: 15.300000, loss: 0.000246, epsilon: 0.050000, episode:  506\n",
            "frames: 1008000, reward: 15.300000, loss: 0.000461, epsilon: 0.050000, episode:  506\n",
            "frames: 1009000, reward: 15.400000, loss: 0.000439, epsilon: 0.050000, episode:  507\n",
            "frames: 1010000, reward: 15.400000, loss: 0.006872, epsilon: 0.050000, episode:  507\n",
            "frames: 1011000, reward: 14.900000, loss: 0.000622, epsilon: 0.050000, episode:  508\n",
            "frames: 1012000, reward: 14.900000, loss: 0.000723, epsilon: 0.050000, episode:  508\n",
            "frames: 1013000, reward: 15.200000, loss: 0.000529, epsilon: 0.050000, episode:  509\n",
            "frames: 1014000, reward: 15.200000, loss: 0.000218, epsilon: 0.050000, episode:  509\n",
            "frames: 1015000, reward: 15.200000, loss: 0.000194, epsilon: 0.050000, episode:  509\n",
            "frames: 1016000, reward: 15.300000, loss: 0.002115, epsilon: 0.050000, episode:  510\n",
            "frames: 1017000, reward: 17.000000, loss: 0.000190, epsilon: 0.050000, episode:  511\n",
            "frames: 1018000, reward: 17.000000, loss: 0.000546, epsilon: 0.050000, episode:  511\n",
            "frames: 1019000, reward: 17.500000, loss: 0.000681, epsilon: 0.050000, episode:  512\n",
            "frames: 1020000, reward: 17.500000, loss: 0.000194, epsilon: 0.050000, episode:  512\n",
            "frames: 1021000, reward: 17.600000, loss: 0.000517, epsilon: 0.050000, episode:  513\n",
            "frames: 1022000, reward: 17.600000, loss: 0.000277, epsilon: 0.050000, episode:  513\n",
            "frames: 1023000, reward: 17.600000, loss: 0.000250, epsilon: 0.050000, episode:  513\n",
            "frames: 1024000, reward: 17.500000, loss: 0.003988, epsilon: 0.050000, episode:  514\n",
            "frames: 1025000, reward: 17.500000, loss: 0.000535, epsilon: 0.050000, episode:  514\n",
            "frames: 1026000, reward: 17.100000, loss: 0.001361, epsilon: 0.050000, episode:  515\n",
            "frames: 1027000, reward: 17.100000, loss: 0.000619, epsilon: 0.050000, episode:  515\n",
            "frames: 1028000, reward: 17.400000, loss: 0.000619, epsilon: 0.050000, episode:  516\n",
            "frames: 1029000, reward: 17.100000, loss: 0.000437, epsilon: 0.050000, episode:  517\n",
            "frames: 1030000, reward: 17.100000, loss: 0.000681, epsilon: 0.050000, episode:  517\n",
            "frames: 1031000, reward: 17.800000, loss: 0.000329, epsilon: 0.050000, episode:  518\n",
            "frames: 1032000, reward: 17.800000, loss: 0.000390, epsilon: 0.050000, episode:  518\n",
            "frames: 1033000, reward: 17.800000, loss: 0.000530, epsilon: 0.050000, episode:  518\n",
            "frames: 1034000, reward: 17.400000, loss: 0.001793, epsilon: 0.050000, episode:  519\n",
            "frames: 1035000, reward: 17.400000, loss: 0.000503, epsilon: 0.050000, episode:  519\n",
            "frames: 1036000, reward: 18.000000, loss: 0.001068, epsilon: 0.050000, episode:  520\n",
            "frames: 1037000, reward: 18.000000, loss: 0.000302, epsilon: 0.050000, episode:  520\n",
            "frames: 1038000, reward: 17.800000, loss: 0.000299, epsilon: 0.050000, episode:  521\n",
            "frames: 1039000, reward: 17.800000, loss: 0.000621, epsilon: 0.050000, episode:  521\n",
            "frames: 1040000, reward: 17.600000, loss: 0.000844, epsilon: 0.050000, episode:  522\n",
            "frames: 1041000, reward: 17.600000, loss: 0.000651, epsilon: 0.050000, episode:  522\n",
            "frames: 1042000, reward: 17.300000, loss: 0.000262, epsilon: 0.050000, episode:  523\n",
            "frames: 1043000, reward: 17.300000, loss: 0.001172, epsilon: 0.050000, episode:  523\n",
            "frames: 1044000, reward: 17.200000, loss: 0.000581, epsilon: 0.050000, episode:  524\n",
            "frames: 1045000, reward: 17.600000, loss: 0.001158, epsilon: 0.050000, episode:  525\n",
            "frames: 1046000, reward: 17.600000, loss: 0.000226, epsilon: 0.050000, episode:  525\n",
            "frames: 1047000, reward: 17.300000, loss: 0.000830, epsilon: 0.050000, episode:  526\n",
            "frames: 1048000, reward: 17.300000, loss: 0.001051, epsilon: 0.050000, episode:  526\n",
            "frames: 1049000, reward: 17.400000, loss: 0.000760, epsilon: 0.050000, episode:  527\n",
            "frames: 1050000, reward: 17.400000, loss: 0.000402, epsilon: 0.050000, episode:  527\n",
            "frames: 1051000, reward: 17.300000, loss: 0.002109, epsilon: 0.050000, episode:  528\n",
            "frames: 1052000, reward: 17.300000, loss: 0.000318, epsilon: 0.050000, episode:  528\n",
            "frames: 1053000, reward: 17.700000, loss: 0.000248, epsilon: 0.050000, episode:  529\n",
            "frames: 1054000, reward: 17.700000, loss: 0.000349, epsilon: 0.050000, episode:  529\n",
            "frames: 1055000, reward: 17.800000, loss: 0.000878, epsilon: 0.050000, episode:  530\n",
            "frames: 1056000, reward: 17.800000, loss: 0.000452, epsilon: 0.050000, episode:  530\n",
            "frames: 1057000, reward: 17.900000, loss: 0.001321, epsilon: 0.050000, episode:  531\n",
            "frames: 1058000, reward: 17.900000, loss: 0.000339, epsilon: 0.050000, episode:  531\n",
            "frames: 1059000, reward: 17.900000, loss: 0.000374, epsilon: 0.050000, episode:  532\n",
            "frames: 1060000, reward: 17.900000, loss: 0.002231, epsilon: 0.050000, episode:  532\n",
            "frames: 1061000, reward: 18.100000, loss: 0.000705, epsilon: 0.050000, episode:  533\n",
            "frames: 1062000, reward: 18.100000, loss: 0.000173, epsilon: 0.050000, episode:  533\n",
            "frames: 1063000, reward: 18.400000, loss: 0.000263, epsilon: 0.050000, episode:  534\n",
            "frames: 1064000, reward: 18.300000, loss: 0.000273, epsilon: 0.050000, episode:  535\n",
            "frames: 1065000, reward: 18.300000, loss: 0.000175, epsilon: 0.050000, episode:  535\n",
            "frames: 1066000, reward: 18.200000, loss: 0.000778, epsilon: 0.050000, episode:  536\n",
            "frames: 1067000, reward: 18.200000, loss: 0.000251, epsilon: 0.050000, episode:  536\n",
            "frames: 1068000, reward: 18.600000, loss: 0.000618, epsilon: 0.050000, episode:  537\n",
            "frames: 1069000, reward: 18.600000, loss: 0.002298, epsilon: 0.050000, episode:  537\n",
            "frames: 1070000, reward: 18.300000, loss: 0.000188, epsilon: 0.050000, episode:  538\n",
            "frames: 1071000, reward: 18.300000, loss: 0.000314, epsilon: 0.050000, episode:  538\n",
            "frames: 1072000, reward: 18.000000, loss: 0.000279, epsilon: 0.050000, episode:  539\n",
            "frames: 1073000, reward: 18.000000, loss: 0.000472, epsilon: 0.050000, episode:  539\n",
            "frames: 1074000, reward: 18.000000, loss: 0.000476, epsilon: 0.050000, episode:  540\n",
            "frames: 1075000, reward: 18.000000, loss: 0.000318, epsilon: 0.050000, episode:  540\n",
            "frames: 1076000, reward: 18.000000, loss: 0.000529, epsilon: 0.050000, episode:  541\n",
            "frames: 1077000, reward: 18.000000, loss: 0.001014, epsilon: 0.050000, episode:  541\n",
            "frames: 1078000, reward: 18.000000, loss: 0.000253, epsilon: 0.050000, episode:  542\n",
            "frames: 1079000, reward: 18.000000, loss: 0.001245, epsilon: 0.050000, episode:  542\n",
            "frames: 1080000, reward: 18.100000, loss: 0.000198, epsilon: 0.050000, episode:  543\n",
            "frames: 1081000, reward: 18.100000, loss: 0.004415, epsilon: 0.050000, episode:  543\n",
            "frames: 1082000, reward: 18.200000, loss: 0.000506, epsilon: 0.050000, episode:  544\n",
            "frames: 1083000, reward: 18.200000, loss: 0.000369, epsilon: 0.050000, episode:  544\n",
            "frames: 1084000, reward: 18.100000, loss: 0.000234, epsilon: 0.050000, episode:  545\n",
            "frames: 1085000, reward: 18.100000, loss: 0.000569, epsilon: 0.050000, episode:  545\n",
            "frames: 1086000, reward: 18.100000, loss: 0.000372, epsilon: 0.050000, episode:  546\n",
            "frames: 1087000, reward: 18.100000, loss: 0.000277, epsilon: 0.050000, episode:  546\n",
            "frames: 1088000, reward: 18.100000, loss: 0.000510, epsilon: 0.050000, episode:  546\n",
            "frames: 1089000, reward: 17.300000, loss: 0.000606, epsilon: 0.050000, episode:  547\n",
            "frames: 1090000, reward: 17.300000, loss: 0.000383, epsilon: 0.050000, episode:  547\n",
            "frames: 1091000, reward: 16.700000, loss: 0.000403, epsilon: 0.050000, episode:  548\n",
            "frames: 1092000, reward: 16.700000, loss: 0.000613, epsilon: 0.050000, episode:  548\n",
            "frames: 1093000, reward: 16.800000, loss: 0.000321, epsilon: 0.050000, episode:  549\n",
            "frames: 1094000, reward: 16.800000, loss: 0.000238, epsilon: 0.050000, episode:  549\n",
            "frames: 1095000, reward: 16.700000, loss: 0.000298, epsilon: 0.050000, episode:  550\n",
            "frames: 1096000, reward: 16.700000, loss: 0.000331, epsilon: 0.050000, episode:  550\n",
            "frames: 1097000, reward: 16.700000, loss: 0.005390, epsilon: 0.050000, episode:  551\n",
            "frames: 1098000, reward: 16.700000, loss: 0.001023, epsilon: 0.050000, episode:  551\n",
            "frames: 1099000, reward: 16.600000, loss: 0.000415, epsilon: 0.050000, episode:  552\n",
            "frames: 1100000, reward: 16.600000, loss: 0.000503, epsilon: 0.050000, episode:  552\n",
            "frames: 1101000, reward: 16.600000, loss: 0.000740, epsilon: 0.050000, episode:  553\n",
            "frames: 1102000, reward: 16.600000, loss: 0.000292, epsilon: 0.050000, episode:  553\n",
            "frames: 1103000, reward: 16.300000, loss: 0.000261, epsilon: 0.050000, episode:  554\n",
            "frames: 1104000, reward: 16.300000, loss: 0.000318, epsilon: 0.050000, episode:  554\n",
            "frames: 1105000, reward: 16.600000, loss: 0.000265, epsilon: 0.050000, episode:  555\n",
            "frames: 1106000, reward: 16.900000, loss: 0.000628, epsilon: 0.050000, episode:  556\n",
            "frames: 1107000, reward: 16.900000, loss: 0.000542, epsilon: 0.050000, episode:  556\n",
            "frames: 1108000, reward: 17.700000, loss: 0.000476, epsilon: 0.050000, episode:  557\n",
            "frames: 1109000, reward: 17.700000, loss: 0.000153, epsilon: 0.050000, episode:  557\n",
            "frames: 1110000, reward: 18.600000, loss: 0.000274, epsilon: 0.050000, episode:  558\n",
            "frames: 1111000, reward: 18.600000, loss: 0.000573, epsilon: 0.050000, episode:  558\n",
            "frames: 1112000, reward: 18.900000, loss: 0.000205, epsilon: 0.050000, episode:  559\n",
            "frames: 1113000, reward: 18.900000, loss: 0.000411, epsilon: 0.050000, episode:  559\n",
            "frames: 1114000, reward: 18.800000, loss: 0.000474, epsilon: 0.050000, episode:  560\n",
            "frames: 1115000, reward: 18.800000, loss: 0.004480, epsilon: 0.050000, episode:  560\n",
            "frames: 1116000, reward: 18.900000, loss: 0.000380, epsilon: 0.050000, episode:  561\n",
            "frames: 1117000, reward: 18.900000, loss: 0.000232, epsilon: 0.050000, episode:  561\n",
            "frames: 1118000, reward: 19.100000, loss: 0.001598, epsilon: 0.050000, episode:  562\n",
            "frames: 1119000, reward: 19.200000, loss: 0.000260, epsilon: 0.050000, episode:  563\n",
            "frames: 1120000, reward: 19.200000, loss: 0.000347, epsilon: 0.050000, episode:  563\n",
            "frames: 1121000, reward: 19.500000, loss: 0.000370, epsilon: 0.050000, episode:  564\n",
            "frames: 1122000, reward: 19.500000, loss: 0.002895, epsilon: 0.050000, episode:  564\n",
            "frames: 1123000, reward: 19.300000, loss: 0.000317, epsilon: 0.050000, episode:  565\n",
            "frames: 1124000, reward: 19.300000, loss: 0.000775, epsilon: 0.050000, episode:  565\n",
            "frames: 1125000, reward: 19.400000, loss: 0.000179, epsilon: 0.050000, episode:  566\n",
            "frames: 1126000, reward: 19.400000, loss: 0.000295, epsilon: 0.050000, episode:  566\n",
            "frames: 1127000, reward: 19.300000, loss: 0.000371, epsilon: 0.050000, episode:  567\n",
            "frames: 1128000, reward: 19.300000, loss: 0.000428, epsilon: 0.050000, episode:  568\n",
            "frames: 1129000, reward: 19.300000, loss: 0.000235, epsilon: 0.050000, episode:  568\n",
            "frames: 1130000, reward: 19.300000, loss: 0.000310, epsilon: 0.050000, episode:  568\n",
            "frames: 1131000, reward: 18.400000, loss: 0.000383, epsilon: 0.050000, episode:  569\n",
            "frames: 1132000, reward: 18.400000, loss: 0.000321, epsilon: 0.050000, episode:  569\n",
            "frames: 1133000, reward: 18.100000, loss: 0.000223, epsilon: 0.050000, episode:  570\n",
            "frames: 1134000, reward: 18.100000, loss: 0.000808, epsilon: 0.050000, episode:  570\n",
            "frames: 1135000, reward: 18.400000, loss: 0.000190, epsilon: 0.050000, episode:  571\n",
            "frames: 1136000, reward: 18.400000, loss: 0.000185, epsilon: 0.050000, episode:  571\n",
            "frames: 1137000, reward: 18.300000, loss: 0.000392, epsilon: 0.050000, episode:  572\n",
            "frames: 1138000, reward: 18.300000, loss: 0.000326, epsilon: 0.050000, episode:  572\n",
            "frames: 1139000, reward: 18.100000, loss: 0.000265, epsilon: 0.050000, episode:  573\n",
            "frames: 1140000, reward: 17.800000, loss: 0.000844, epsilon: 0.050000, episode:  574\n",
            "frames: 1141000, reward: 17.800000, loss: 0.000314, epsilon: 0.050000, episode:  574\n",
            "frames: 1142000, reward: 17.800000, loss: 0.000233, epsilon: 0.050000, episode:  574\n",
            "frames: 1143000, reward: 17.400000, loss: 0.000515, epsilon: 0.050000, episode:  575\n",
            "frames: 1144000, reward: 17.400000, loss: 0.000875, epsilon: 0.050000, episode:  576\n",
            "frames: 1145000, reward: 17.400000, loss: 0.001133, epsilon: 0.050000, episode:  576\n",
            "frames: 1146000, reward: 17.400000, loss: 0.000136, epsilon: 0.050000, episode:  577\n",
            "frames: 1147000, reward: 17.400000, loss: 0.000162, epsilon: 0.050000, episode:  577\n",
            "frames: 1148000, reward: 17.100000, loss: 0.000200, epsilon: 0.050000, episode:  578\n",
            "frames: 1149000, reward: 17.100000, loss: 0.000349, epsilon: 0.050000, episode:  578\n",
            "frames: 1150000, reward: 17.900000, loss: 0.000110, epsilon: 0.050000, episode:  579\n",
            "frames: 1151000, reward: 17.900000, loss: 0.000263, epsilon: 0.050000, episode:  579\n",
            "frames: 1152000, reward: 18.300000, loss: 0.000375, epsilon: 0.050000, episode:  580\n",
            "frames: 1153000, reward: 18.300000, loss: 0.000192, epsilon: 0.050000, episode:  580\n",
            "frames: 1154000, reward: 18.300000, loss: 0.000194, epsilon: 0.050000, episode:  581\n",
            "frames: 1155000, reward: 18.300000, loss: 0.000325, epsilon: 0.050000, episode:  581\n",
            "frames: 1156000, reward: 18.500000, loss: 0.000743, epsilon: 0.050000, episode:  582\n",
            "frames: 1157000, reward: 18.700000, loss: 0.000521, epsilon: 0.050000, episode:  583\n",
            "frames: 1158000, reward: 18.700000, loss: 0.000295, epsilon: 0.050000, episode:  583\n",
            "frames: 1159000, reward: 19.000000, loss: 0.000470, epsilon: 0.050000, episode:  584\n",
            "frames: 1160000, reward: 19.000000, loss: 0.000311, epsilon: 0.050000, episode:  584\n",
            "frames: 1161000, reward: 19.200000, loss: 0.000882, epsilon: 0.050000, episode:  585\n",
            "frames: 1162000, reward: 19.200000, loss: 0.000349, epsilon: 0.050000, episode:  585\n",
            "frames: 1163000, reward: 19.000000, loss: 0.002575, epsilon: 0.050000, episode:  586\n",
            "frames: 1164000, reward: 19.000000, loss: 0.000439, epsilon: 0.050000, episode:  586\n",
            "frames: 1165000, reward: 18.900000, loss: 0.000811, epsilon: 0.050000, episode:  587\n",
            "frames: 1166000, reward: 18.900000, loss: 0.000116, epsilon: 0.050000, episode:  587\n",
            "frames: 1167000, reward: 19.200000, loss: 0.000393, epsilon: 0.050000, episode:  588\n",
            "frames: 1168000, reward: 19.200000, loss: 0.000308, epsilon: 0.050000, episode:  588\n",
            "frames: 1169000, reward: 19.200000, loss: 0.002622, epsilon: 0.050000, episode:  588\n",
            "frames: 1170000, reward: 18.600000, loss: 0.000577, epsilon: 0.050000, episode:  589\n",
            "frames: 1171000, reward: 18.600000, loss: 0.000282, epsilon: 0.050000, episode:  589\n",
            "frames: 1172000, reward: 18.300000, loss: 0.000653, epsilon: 0.050000, episode:  590\n",
            "frames: 1173000, reward: 18.300000, loss: 0.000854, epsilon: 0.050000, episode:  590\n",
            "frames: 1174000, reward: 18.000000, loss: 0.000268, epsilon: 0.050000, episode:  591\n",
            "frames: 1175000, reward: 18.000000, loss: 0.000324, epsilon: 0.050000, episode:  591\n",
            "frames: 1176000, reward: 17.300000, loss: 0.000380, epsilon: 0.050000, episode:  592\n",
            "frames: 1177000, reward: 17.300000, loss: 0.000330, epsilon: 0.050000, episode:  592\n",
            "frames: 1178000, reward: 17.000000, loss: 0.001005, epsilon: 0.050000, episode:  593\n",
            "frames: 1179000, reward: 17.000000, loss: 0.000277, epsilon: 0.050000, episode:  593\n",
            "frames: 1180000, reward: 16.900000, loss: 0.000314, epsilon: 0.050000, episode:  594\n",
            "frames: 1181000, reward: 16.900000, loss: 0.000233, epsilon: 0.050000, episode:  594\n",
            "frames: 1182000, reward: 16.700000, loss: 0.000177, epsilon: 0.050000, episode:  595\n",
            "frames: 1183000, reward: 16.700000, loss: 0.000334, epsilon: 0.050000, episode:  595\n",
            "frames: 1184000, reward: 16.700000, loss: 0.000352, epsilon: 0.050000, episode:  596\n",
            "frames: 1185000, reward: 16.700000, loss: 0.004508, epsilon: 0.050000, episode:  596\n",
            "frames: 1186000, reward: 16.900000, loss: 0.000848, epsilon: 0.050000, episode:  597\n",
            "frames: 1187000, reward: 16.900000, loss: 0.000780, epsilon: 0.050000, episode:  597\n",
            "frames: 1188000, reward: 16.500000, loss: 0.000252, epsilon: 0.050000, episode:  598\n",
            "frames: 1189000, reward: 16.500000, loss: 0.000203, epsilon: 0.050000, episode:  598\n",
            "frames: 1190000, reward: 16.500000, loss: 0.000232, epsilon: 0.050000, episode:  599\n",
            "frames: 1191000, reward: 16.500000, loss: 0.000450, epsilon: 0.050000, episode:  599\n",
            "frames: 1192000, reward: 16.500000, loss: 0.000244, epsilon: 0.050000, episode:  600\n",
            "frames: 1193000, reward: 16.500000, loss: 0.000929, epsilon: 0.050000, episode:  600\n",
            "frames: 1194000, reward: 16.600000, loss: 0.000218, epsilon: 0.050000, episode:  601\n",
            "frames: 1195000, reward: 16.600000, loss: 0.000446, epsilon: 0.050000, episode:  601\n",
            "frames: 1196000, reward: 17.300000, loss: 0.001334, epsilon: 0.050000, episode:  602\n",
            "frames: 1197000, reward: 17.300000, loss: 0.001031, epsilon: 0.050000, episode:  602\n",
            "frames: 1198000, reward: 17.500000, loss: 0.004797, epsilon: 0.050000, episode:  603\n",
            "frames: 1199000, reward: 17.500000, loss: 0.000548, epsilon: 0.050000, episode:  603\n",
            "frames: 1200000, reward: 17.300000, loss: 0.000118, epsilon: 0.050000, episode:  604\n",
            "frames: 1201000, reward: 17.300000, loss: 0.001266, epsilon: 0.050000, episode:  604\n",
            "frames: 1202000, reward: 17.900000, loss: 0.003434, epsilon: 0.050000, episode:  605\n",
            "frames: 1203000, reward: 17.900000, loss: 0.000234, epsilon: 0.050000, episode:  605\n",
            "frames: 1204000, reward: 17.800000, loss: 0.000489, epsilon: 0.050000, episode:  606\n",
            "frames: 1205000, reward: 17.800000, loss: 0.000440, epsilon: 0.050000, episode:  607\n",
            "frames: 1206000, reward: 17.800000, loss: 0.000341, epsilon: 0.050000, episode:  607\n",
            "frames: 1207000, reward: 18.200000, loss: 0.000561, epsilon: 0.050000, episode:  608\n",
            "frames: 1208000, reward: 18.200000, loss: 0.000192, epsilon: 0.050000, episode:  608\n",
            "frames: 1209000, reward: 18.800000, loss: 0.000374, epsilon: 0.050000, episode:  609\n",
            "frames: 1210000, reward: 18.800000, loss: 0.000425, epsilon: 0.050000, episode:  609\n",
            "frames: 1211000, reward: 18.500000, loss: 0.003990, epsilon: 0.050000, episode:  610\n",
            "frames: 1212000, reward: 18.500000, loss: 0.000687, epsilon: 0.050000, episode:  610\n",
            "frames: 1213000, reward: 18.400000, loss: 0.001841, epsilon: 0.050000, episode:  611\n",
            "frames: 1214000, reward: 18.400000, loss: 0.000272, epsilon: 0.050000, episode:  611\n",
            "frames: 1215000, reward: 17.600000, loss: 0.000440, epsilon: 0.050000, episode:  612\n",
            "frames: 1216000, reward: 17.600000, loss: 0.001669, epsilon: 0.050000, episode:  612\n",
            "frames: 1217000, reward: 17.600000, loss: 0.000624, epsilon: 0.050000, episode:  613\n",
            "frames: 1218000, reward: 17.600000, loss: 0.000372, epsilon: 0.050000, episode:  613\n",
            "frames: 1219000, reward: 17.800000, loss: 0.000197, epsilon: 0.050000, episode:  614\n",
            "frames: 1220000, reward: 17.800000, loss: 0.000356, epsilon: 0.050000, episode:  614\n",
            "frames: 1221000, reward: 17.200000, loss: 0.000640, epsilon: 0.050000, episode:  615\n",
            "frames: 1222000, reward: 17.200000, loss: 0.000654, epsilon: 0.050000, episode:  615\n",
            "frames: 1223000, reward: 17.300000, loss: 0.000257, epsilon: 0.050000, episode:  616\n",
            "frames: 1224000, reward: 17.300000, loss: 0.000264, epsilon: 0.050000, episode:  616\n",
            "frames: 1225000, reward: 17.200000, loss: 0.000169, epsilon: 0.050000, episode:  617\n",
            "frames: 1226000, reward: 17.200000, loss: 0.000449, epsilon: 0.050000, episode:  617\n",
            "frames: 1227000, reward: 16.900000, loss: 0.000477, epsilon: 0.050000, episode:  618\n",
            "frames: 1228000, reward: 16.900000, loss: 0.000465, epsilon: 0.050000, episode:  618\n",
            "frames: 1229000, reward: 16.400000, loss: 0.000624, epsilon: 0.050000, episode:  619\n",
            "frames: 1230000, reward: 16.400000, loss: 0.000919, epsilon: 0.050000, episode:  619\n",
            "frames: 1231000, reward: 16.800000, loss: 0.000256, epsilon: 0.050000, episode:  620\n",
            "frames: 1232000, reward: 17.000000, loss: 0.000310, epsilon: 0.050000, episode:  621\n",
            "frames: 1233000, reward: 17.000000, loss: 0.000355, epsilon: 0.050000, episode:  621\n",
            "frames: 1234000, reward: 17.000000, loss: 0.000243, epsilon: 0.050000, episode:  621\n",
            "frames: 1235000, reward: 17.200000, loss: 0.000251, epsilon: 0.050000, episode:  622\n"
          ]
        }
      ],
      "source": [
        "# if __name__ == '__main__':\n",
        "\n",
        "# Training DQN in PongNoFrameskip-v4\n",
        "env = gym.make('PongNoFrameskip-v4')\n",
        "env = AtariPreprocessing(env,\n",
        "                         scale_obs=False,\n",
        "                         terminal_on_life_loss=True,\n",
        "                         )\n",
        "env = FrameStack(env, num_stack=4)\n",
        "\n",
        "gamma = 0.99\n",
        "epsilon_max = 1\n",
        "epsilon_min = 0.05\n",
        "eps_decay = 30000\n",
        "frames = 2000000\n",
        "USE_CUDA = False\n",
        "learning_rate = 2e-4\n",
        "max_buff = 100000\n",
        "update_tar_interval = 1000\n",
        "batch_size = 32\n",
        "print_interval = 1000\n",
        "log_interval = 1000\n",
        "learning_start = 10000\n",
        "win_reward = 18     # Pong-v4\n",
        "win_break = True\n",
        "\n",
        "action_space = env.action_space\n",
        "action_dim = env.action_space.n\n",
        "state_dim = env.observation_space.shape[1]\n",
        "state_channel = env.observation_space.shape[0]\n",
        "agent = DQNAgent(in_channels = state_channel, \n",
        "                 action_space = action_space, \n",
        "                 USE_CUDA = USE_CUDA, \n",
        "                 lr = learning_rate,\n",
        "                 memory_size = max_buff)\n",
        "\n",
        "frame, _ = env.reset()\n",
        "\n",
        "episode_reward = 0\n",
        "all_rewards = []\n",
        "losses = []\n",
        "episode_num = 0\n",
        "is_win = False\n",
        "# tensorboard\n",
        "summary_writer = SummaryWriter(log_dir = \"DQN_stackframe\", comment= \"good_makeatari\")\n",
        "\n",
        "# e-greedy decay\n",
        "epsilon_by_frame = lambda frame_idx: epsilon_min + (epsilon_max - epsilon_min) * math.exp(\n",
        "            -1. * frame_idx / eps_decay)\n",
        "# plt.plot([epsilon_by_frame(i) for i in range(10000)])\n",
        "\n",
        "for i in range(frames):\n",
        "    epsilon = epsilon_by_frame(i)\n",
        "    state_tensor = agent.observe(frame)\n",
        "    action = agent.act(state_tensor, epsilon)\n",
        "\n",
        "    next_frame, reward, terminated, truncated, _ = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    \n",
        "    episode_reward += reward\n",
        "    agent.memory_buffer.push(frame, action, reward, next_frame, done)\n",
        "    frame = next_frame\n",
        "\n",
        "    loss = 0\n",
        "    if agent.memory_buffer.size() >= learning_start:\n",
        "        loss = agent.learn_from_experience(batch_size)\n",
        "        losses.append(loss)\n",
        "\n",
        "    if i % print_interval == 0:\n",
        "        print(\"frames: %5d, reward: %5f, loss: %4f, epsilon: %5f, episode: %4d\" % (i, np.mean(all_rewards[-10:]), loss, epsilon, episode_num))\n",
        "        summary_writer.add_scalar(\"Temporal Difference Loss\", loss, i)\n",
        "        summary_writer.add_scalar(\"Mean Reward\", np.mean(all_rewards[-10:]), i)\n",
        "        summary_writer.add_scalar(\"Epsilon\", epsilon, i)\n",
        "\n",
        "    if i % update_tar_interval == 0:\n",
        "        agent.DQN_target.load_state_dict(agent.DQN.state_dict())\n",
        "\n",
        "    if done:\n",
        "\n",
        "        frame, _ = env.reset()\n",
        "\n",
        "        all_rewards.append(episode_reward)\n",
        "        episode_reward = 0\n",
        "        episode_num += 1\n",
        "        avg_reward = float(np.mean(all_rewards[-100:]))\n",
        "\n",
        "summary_writer.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "下面我们使用matplotlib库画出游戏得分和loss曲线。\n",
        "\n",
        "从左边的图我们可以看到，DQN智能体在玩了200把游戏后开始快速学习，大概在300把游戏之后学习成功（达到20+分）。\n",
        "\n",
        "从右边的图我们可以看到，在表现达到最优之后，Loss还是在不断减小。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_ekyfJGaNroU",
        "outputId": "bbb8cf5a-a90b-4da1-e35d-6b5c224b911b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_training(frame_idx, rewards, losses):\n",
        "    clear_output(True)\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(131)\n",
        "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
        "    plt.plot(rewards)\n",
        "    plt.subplot(132)\n",
        "    plt.title('loss')\n",
        "    plt.plot(losses)\n",
        "    plt.show()\n",
        "\n",
        "plot_training(i, all_rewards, losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeaTvisTCI1K"
      },
      "source": [
        "## 总结\n",
        "\n",
        "感想就是，总结强化学习需要的元素相对容易，真正实现的时候很麻烦，尤其是当模型学不会的时候，你会怀疑是模型的问题还是代码有bug，不要犹豫，是代码有bug。\n",
        "\n",
        "训练模型收敛大概需要2百万步，差不多要24小时+，比较慢，但是很欣慰的是Pong在atari game中是最容易实现的游戏，没有bug的话可以在10小时以内收敛，很良心。\n",
        "\n",
        "DQN算法非常经典，值得学习，建议大家都自己实现一遍。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
