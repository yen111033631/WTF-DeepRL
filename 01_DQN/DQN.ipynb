{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WTF 深度强化学习教程 1. Deep Q-Network\n",
        "\n",
        "WTF 深度强化学习教程，帮助新人快速入门 Deep RL，算法使用pytorch 2.0版本实现。\n",
        "\n",
        "**推特**：[@WTFAcademy_](https://twitter.com/WTFAcademy_) ｜ [@0xAA_Science](https://twitter.com/0xAA_Science)\n",
        "\n",
        "**WTF Academy 社群：** [官网 wtf.academy](https://wtf.academy/) | [WTF Solidity 教程](https://github.com/AmazingAng/WTFSolidity) | [discord](https://discord.wtf.academy/) | [微信群申请](https://docs.google.com/forms/d/e/1FAIpQLSe4KGT8Sh6sJ7hedQRuIYirOoZK_85miz3dw7vA1-YjodgJ-A/viewform?usp=sf_link)\n",
        "\n",
        "所有代码和教程开源在 github: [github.com/AmazingAng/WTF-DeepRL](https://github.com/WTFAcademy/WTF-DeepRL)\n",
        "\n",
        "---\n",
        "\n",
        "这一讲，我们将尝试利用pytorch实现深度强化学习的开山之作 Deep Q-Network，DQN，推荐你先阅读 [DQN 论文](https://arxiv.org/abs/1312.5602)。\n",
        "\n",
        "## 0. 先修课程\n",
        "\n",
        "在开始之前，你需要先完成先修课程：\n",
        "\n",
        "1. 强化学习理论：推荐 Sutton 和 Barto 写的[强化学习圣经](http://incompleteideas.net/book/RLbook2020.pdf)。\n",
        "\n",
        "    ![](./img/1-1.png)\n",
        "\n",
        "2. 机器学习：你可以在网上找到很多机器学习的公开课，比如coursera上Andrew Ng的课程。\n",
        "\n",
        "3. python编程：网上你可以找到很多的python入门公开课，我推荐哈佛大学的CS50 python版。\n",
        "\n",
        "## 1. 深度强化学习中的元素\n",
        "\n",
        "强化学习研究的是智能体（Agent）和环境（Environment）交互中如何学习最优策略，以获得最大收益（Cumulative rewards）。Agent需要能够观察环境(observe)的到所处的状态，评判（value）状态下每个动作的价值，选出最优的动作（act）来和环境交互，同时通过从经验中学习不断改善自己的策略（learn from experience）。因此，observe，value，act和learn是强化学习Agent必不可少的元素。\n",
        "\n",
        "![](./img/1-2.png)\n",
        "\n",
        "如果我们给Agent写一个类，大体会长这样的：\n",
        "\n",
        "```python\n",
        "class Agent: \n",
        "\n",
        "    def __init__(self):\n",
        "        ...\n",
        "\n",
        "    def observe(self, observation):\n",
        "        ...\n",
        "        return state\n",
        "\n",
        "    def value(self, state,):\n",
        "        ...\n",
        "        return value_of_actions\n",
        "    \n",
        "    def act(value_of_actions):\n",
        "        ...\n",
        "        return selected_action\n",
        "    \n",
        "    def learn_from_experience(self, batch_size):\n",
        "        ...\n",
        "```\n",
        "\n",
        "这个教程中，我们会使用经典的Atari游戏来训练强化学习算法，下面我们探讨一下这几个函数在Atari环境中起到什么作用：\n",
        "\n",
        "- `observe`: 在Atari中，环境每一步给出的observation（84x84x1的array）可以直接作为state。那么observe()函数只需要把numpy array转换为torch tensor，方便模型后续使用就好了。在更复杂的partial observable环境，我们需要利用observation来推断所处的state，这时observe()函数会由更多功能。\n",
        "- `value`: 在DQN中，`value`函数主要是给出当前state下每个action的Q value，帮助智能体选择最优策略。\n",
        "- `act`: 在DQN中，根据`value`函数给出的Q值，采用epsilon greedy policy选出action。\n",
        "- `learn_from_experience`: 根据收集的经验计算TD Loss（temporal-difference loss），再通过梯度下降算法更新深度神经网络的参数，改善策略。其中TD Loss由Bellman Equation给出：\n",
        "\n",
        "    $$Loss_{TD}=R_t+\\gamma Q(s_{t+1},a_{t+1})−Q(s_t,a_t)$$\n",
        "\n",
        "下面，我们开始完成DQN算法。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 引入包\n",
        "你需要安装相应的包，然后在 jupyter notebook 中导入他们，如果你使用的是Google Colab Research，则需要安装`gym[atari]`和`autorom[accept-rom-license]`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yy1WnM9NroP",
        "outputId": "c6789b55-af8d-443e-ae3f-ad61d485f163"
      },
      "outputs": [],
      "source": [
        "# 在 Google Colab Rsearch 中需要安装的库\n",
        "# !pip install gym[atari]\n",
        "# !pip install autorom[accept-rom-license]\n",
        "\n",
        "import gym, random, pickle, os.path, math, glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "import pdb\n",
        "\n",
        "from gym.wrappers import AtariPreprocessing, LazyFrames, FrameStack\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Atari游戏中的Pong\n",
        "\n",
        "Pong是Atari中一个仿真打乒乓球的游戏：玩家和电脑每人拿一个板子，接对方弹来的球，没接住的话，对方得一分，先得到21分的获胜。\n",
        "\n",
        "我们使用 DQN 论文中的设定，在丢失声明时会结束游戏，并且4帧画面会合并为1个输入，加快学习。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "TaTmabj6NroQ",
        "outputId": "f8ad7d9e-07b3-4ae7-9dd6-5ee3d63c15d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
            "[Powered by Stella]\n",
            "/home/neaf2080/.pyenv/versions/3.8.18/envs/RL_gym/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcaeb1f6790>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGgCAYAAADsNrNZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh1UlEQVR4nO3df3BU1f3/8VeSTTbRkA2JsktqAtHSBkUqBg0r1LaYNkMZCiW16mBFYaTaQIVMtaY1tH4Ug7QVxPKjOjTqKFLzGUVxRhyNNQ5jwo9YrFQNWFOTCrvUttkN0Wwge75/9NP9ugaETTacbHw+Zs4M99xz7745Lnl5cu/eTTLGGAEAcJol2y4AAPD5RAABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwYtABat26dxo4dq/T0dJWUlGjXrl2D9VIAgASUNBjPgvvDH/6g6667Ths3blRJSYnWrFmjuro6tbS0aNSoUZ95bDgc1sGDBzVixAglJSXFuzQAwCAzxqizs1N5eXlKTv6MdY4ZBJdeeqmpqKiIbPf29pq8vDxTU1Nz0mPb29uNJBqNRqMleGtvb//Mn/cOxVlPT4+am5tVVVUV6UtOTlZpaakaGxv7jA+FQgqFQpFt838Lsmn6thxKHVAtSZPGR233njmw8yWCXmdKn74PJ6SdltfOefton77Uj46dltfG58fx3uP/PP/0vMdHtvAePxXHjoX0WtMqjRgx4jPHxT2APvzwQ/X29srtdkf1u91uvfPOO33G19TU6M477zxOYalyJA0wgFKc0duO0/MmtSnJ0fcfZ4rz9Py9Hal9X9vh4B8n4ov3eOI42WWUuAdQrKqqqlRZWRnZDgaDys/PV3jaRIUd6RYrS0zhlL7/wbvG9J6W187+a9/f9aZ2nZaXxufI8d7jR8aenve4q5X3eDzFPYDOOusspaSkyO/3R/X7/X55PJ4+451Op5xOZ59+AMDwFvfbsNPS0lRcXKz6+vpIXzgcVn19vbxeb7xfDgCQoAblV3CVlZWaP3++Jk+erEsvvVRr1qxRV1eXbrjhhsF4OQBAAhqUALrqqqv0j3/8Q8uXL5fP59NFF12k7du397kxAQDw+TVoNyEsXrxYixcvHqzT4wSOd0voeXUDP2/rrL7X6cLpZuAnBk6D8/6356Rj/jaz701PvRnhwSgH/4dnwQEArCCAAABWEEAAACusfxAV8RVO6fv/FIHCgX9K3KRwvQdAfLECAgBYQQABAKwggAAAVhBAAAAruAlhmOl19v1/in9N4sN0AIYeVkAAACsIIACAFQQQAMAKrgFBX3g5PudJ6+CriQGcOlZAAAArCCAAgBUEEADACq4BARj2unNP/kBek8wDd083VkAAACsIIACAFQQQAMAKAggAYAU3IUAfTI/Peb7wct+3U/o/e+JzcmAAPvjGqYziJoTTjRUQAMAKAggAYAUBBACwgmtAw0xKqO+Xz+X86fT8Z3Z0HT0tr4PPt+O+x/fyHk9ErIAAAFYQQAAAKwggAIAVBBAAwIohexNC6+w0JWec/Am2OBV9L9oOhn9dlHKc3uP1AfHGe3woCX8clnacfBwrIACAFQQQAMCKmAPo1Vdf1axZs5SXl6ekpCRt3bo1ar8xRsuXL9fo0aOVkZGh0tJSHThwIF71AgCGiZivAXV1dekrX/mKFixYoLlz5/bZv2rVKq1du1aPPPKICgsLVV1drbKyMr311ltKT08/5df58+xaZY1ggQYAiSbYGdbIW08+LuYAmjFjhmbMmHHcfcYYrVmzRnfccYdmz54tSXr00Ufldru1detWXX311bG+HABgmIrrEqO1tVU+n0+lpaWRPpfLpZKSEjU2Nh73mFAopGAwGNUAAMNfXAPI5/NJktxud1S/2+2O7Pu0mpoauVyuSMvPz49nSQCAIcr6RZaqqioFAoFIa29vt10SAOA0iGsAeTweSZLf74/q9/v9kX2f5nQ6lZWVFdUAAMNfXAOosLBQHo9H9fX1kb5gMKidO3fK6/XG86UAAAku5rvgjhw5onfffTey3draqr179yonJ0cFBQVaunSp7r77bo0bNy5yG3ZeXp7mzJkTz7oBAAku5gDas2ePvvGNb0S2KysrJUnz58/Xww8/rNtuu01dXV1atGiROjo6NG3aNG3fvj2mzwABAIa/JGOMsV3EJwWDQblcLv17/7l8EBUAElCwM6yRX3pPgUDgM6/r8xMeAGAFAQQAsIIAAgBYMWS/kO6b+2bJcabTdhkAgBgd6wpJuv+k41gBAQCsIIAAAFYQQAAAKwggAIAVQ/YmhDPuy5LDwdMTACDRHDvWfUrjWAEBAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYEVMA1dTU6JJLLtGIESM0atQozZkzRy0tLVFjuru7VVFRodzcXGVmZqq8vFx+vz+uRQMAEl9MAdTQ0KCKigo1NTXpxRdf1NGjR/Wtb31LXV1dkTHLli3Ttm3bVFdXp4aGBh08eFBz586Ne+EAgMSWZIwx/T34H//4h0aNGqWGhgZdfvnlCgQCOvvss7V582Z973vfkyS98847Gj9+vBobGzVlypSTnjMYDMrlcunyadVyONL7WxoAwJJjx7r16o67FAgElJWVdcJxA7oGFAgEJEk5OTmSpObmZh09elSlpaWRMUVFRSooKFBjY+NxzxEKhRQMBqMaAGD463cAhcNhLV26VFOnTtWECRMkST6fT2lpacrOzo4a63a75fP5jnuempoauVyuSMvPz+9vSQCABNLvAKqoqNC+ffu0ZcuWARVQVVWlQCAQae3t7QM6HwAgMTj6c9DixYv13HPP6dVXX9U555wT6fd4POrp6VFHR0fUKsjv98vj8Rz3XE6nU06nsz9lAAASWEwrIGOMFi9erKefflovv/yyCgsLo/YXFxcrNTVV9fX1kb6Wlha1tbXJ6/XGp2IAwLAQ0wqooqJCmzdv1jPPPKMRI0ZEruu4XC5lZGTI5XJp4cKFqqysVE5OjrKysrRkyRJ5vd5TugMOAPD5EVMAbdiwQZL09a9/Paq/trZW119/vSRp9erVSk5OVnl5uUKhkMrKyrR+/fq4FAsAGD5iCqBT+chQenq61q1bp3Xr1vW7KADA8Mez4AAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVjhsFwAA6OvDCRlR24Gi3qjtzL+l9DnGvefjQa0p3lgBAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALAipgDasGGDJk6cqKysLGVlZcnr9er555+P7O/u7lZFRYVyc3OVmZmp8vJy+f3+uBcNAEh8MQXQOeeco5UrV6q5uVl79uzR9OnTNXv2bP3lL3+RJC1btkzbtm1TXV2dGhoadPDgQc2dO3dQCgcAJLaYnoQwa9asqO0VK1Zow4YNampq0jnnnKNNmzZp8+bNmj59uiSptrZW48ePV1NTk6ZMmRK/qgEACa/f14B6e3u1ZcsWdXV1yev1qrm5WUePHlVpaWlkTFFRkQoKCtTY2HjC84RCIQWDwagGABj+Yg6gN998U5mZmXI6nbrpppv09NNP6/zzz5fP51NaWpqys7Ojxrvdbvl8vhOer6amRi6XK9Ly8/Nj/ksAABJPzAH05S9/WXv37tXOnTt18803a/78+Xrrrbf6XUBVVZUCgUCktbe39/tcAIDEEfPTsNPS0vTFL35RklRcXKzdu3fr/vvv11VXXaWenh51dHRErYL8fr88Hs8Jz+d0OuV0OmOvHACQ0Ab8OaBwOKxQKKTi4mKlpqaqvr4+sq+lpUVtbW3yer0DfRkAwDAT0wqoqqpKM2bMUEFBgTo7O7V582a98soreuGFF+RyubRw4UJVVlYqJydHWVlZWrJkibxeL3fAAQD6iCmADh8+rOuuu06HDh2Sy+XSxIkT9cILL+ib3/ymJGn16tVKTk5WeXm5QqGQysrKtH79+kEpHACQ2GIKoE2bNn3m/vT0dK1bt07r1q0bUFEAgOGPZ8EBAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYEfPDSAEAgy/zUG/Udkp39HrBGYzen4hYAQEArCCAAABWEEAAACu4BgQAQ1D6P3s+tW2pkEHECggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArBhQAK1cuVJJSUlaunRppK+7u1sVFRXKzc1VZmamysvL5ff7B1onAGCY6XcA7d69W7/73e80ceLEqP5ly5Zp27ZtqqurU0NDgw4ePKi5c+cOuFAAwPDSrwA6cuSI5s2bp4ceekgjR46M9AcCAW3atEn33Xefpk+fruLiYtXW1uq1115TU1NT3IoGACS+fgVQRUWFZs6cqdLS0qj+5uZmHT16NKq/qKhIBQUFamxsPO65QqGQgsFgVAMADH+OWA/YsmWLXn/9de3evbvPPp/Pp7S0NGVnZ0f1u91u+Xy+456vpqZGd955Z6xlAAASXEwroPb2dt1yyy16/PHHlZ6eHpcCqqqqFAgEIq29vT0u5wUADG0xBVBzc7MOHz6siy++WA6HQw6HQw0NDVq7dq0cDofcbrd6enrU0dERdZzf75fH4znuOZ1Op7KysqIaAGD4i+lXcFdccYXefPPNqL4bbrhBRUVF+ulPf6r8/Hylpqaqvr5e5eXlkqSWlha1tbXJ6/XGr2oAQMKLKYBGjBihCRMmRPWdeeaZys3NjfQvXLhQlZWVysnJUVZWlpYsWSKv16spU6bEr2oAQMKL+SaEk1m9erWSk5NVXl6uUCiksrIyrV+/Pt4vAwBIcEnGGGO7iE8KBoNyuVy6fFq1HI743OgAADh9jh3r1qs77lIgEPjM6/o8Cw4AYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYEVMAfTLX/5SSUlJUa2oqCiyv7u7WxUVFcrNzVVmZqbKy8vl9/vjXjQAIPHFvAK64IILdOjQoUjbsWNHZN+yZcu0bds21dXVqaGhQQcPHtTcuXPjWjAAYHhwxHyAwyGPx9OnPxAIaNOmTdq8ebOmT58uSaqtrdX48ePV1NSkKVOmDLxaAMCwEfMK6MCBA8rLy9O5556refPmqa2tTZLU3Nyso0ePqrS0NDK2qKhIBQUFamxsPOH5QqGQgsFgVAMADH8xBVBJSYkefvhhbd++XRs2bFBra6u++tWvqrOzUz6fT2lpacrOzo46xu12y+fznfCcNTU1crlckZafn9+vvwgAILHE9Cu4GTNmRP48ceJElZSUaMyYMXryySeVkZHRrwKqqqpUWVkZ2Q4Gg4QQAHwODOg27OzsbH3pS1/Su+++K4/Ho56eHnV0dESN8fv9x71m9F9Op1NZWVlRDQAw/A0ogI4cOaK//vWvGj16tIqLi5Wamqr6+vrI/paWFrW1tcnr9Q64UADA8BLTr+B+8pOfaNasWRozZowOHjyoX/ziF0pJSdE111wjl8ulhQsXqrKyUjk5OcrKytKSJUvk9Xq5Aw4A0EdMAfT3v/9d11xzjf75z3/q7LPP1rRp09TU1KSzzz5bkrR69WolJyervLxcoVBIZWVlWr9+/aAUDgBIbEnGGGO7iE8KBoNyuVy6fFq1HI502+UAAGJ07Fi3Xt1xlwKBwGde1+dZcAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAK2IOoA8++EDXXnutcnNzlZGRoQsvvFB79uyJ7DfGaPny5Ro9erQyMjJUWlqqAwcOxLVoAEDiiymA/v3vf2vq1KlKTU3V888/r7feeku/+c1vNHLkyMiYVatWae3atdq4caN27typM888U2VlZeru7o578QCAxOWIZfC9996r/Px81dbWRvoKCwsjfzbGaM2aNbrjjjs0e/ZsSdKjjz4qt9utrVu36uqrr45T2QCARBfTCujZZ5/V5MmTdeWVV2rUqFGaNGmSHnroocj+1tZW+Xw+lZaWRvpcLpdKSkrU2Nh43HOGQiEFg8GoBgAY/mIKoPfee08bNmzQuHHj9MILL+jmm2/Wj3/8Yz3yyCOSJJ/PJ0lyu91Rx7nd7si+T6upqZHL5Yq0/Pz8/vw9AAAJJqYACofDuvjii3XPPfdo0qRJWrRokW688UZt3Lix3wVUVVUpEAhEWnt7e7/PBQBIHDEF0OjRo3X++edH9Y0fP15tbW2SJI/HI0ny+/1RY/x+f2TfpzmdTmVlZUU1AMDwF1MATZ06VS0tLVF9+/fv15gxYyT954YEj8ej+vr6yP5gMKidO3fK6/XGoVwAwHAR011wy5Yt02WXXaZ77rlH3//+97Vr1y49+OCDevDBByVJSUlJWrp0qe6++26NGzdOhYWFqq6uVl5enubMmTMY9QMAElRMAXTJJZfo6aefVlVVlf7nf/5HhYWFWrNmjebNmxcZc9ttt6mrq0uLFi1SR0eHpk2bpu3btys9PT3uxQMAEleSMcbYLuKTgsGgXC6XLp9WLYeD0AKARHPsWLde3XGXAoHAZ17X51lwAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBY4bBdwFD34QUZffo+yjNR2yNao/ePfLd7MEsCgGGBFRAAwAoCCABgRUwBNHbsWCUlJfVpFRUVkqTu7m5VVFQoNzdXmZmZKi8vl9/vH5TCAQCJLaYA2r17tw4dOhRpL774oiTpyiuvlCQtW7ZM27ZtU11dnRoaGnTw4EHNnTs3/lWfRsfO7NuOZoejWm9GUlQDAJxcTDchnH322VHbK1eu1Hnnnaevfe1rCgQC2rRpkzZv3qzp06dLkmprazV+/Hg1NTVpypQp8asaAJDw+n0NqKenR4899pgWLFigpKQkNTc36+jRoyotLY2MKSoqUkFBgRobG094nlAopGAwGNUAAMNfvwNo69at6ujo0PXXXy9J8vl8SktLU3Z2dtQ4t9stn893wvPU1NTI5XJFWn5+fn9LAgAkkH4H0KZNmzRjxgzl5eUNqICqqioFAoFIa29vH9D5AACJoV8fRH3//ff10ksv6amnnor0eTwe9fT0qKOjI2oV5Pf75fF4Tngup9Mpp9PZnzIAAAmsXyug2tpajRo1SjNnzoz0FRcXKzU1VfX19ZG+lpYWtbW1yev1DrxSAMCwEvMKKBwOq7a2VvPnz5fD8f8Pd7lcWrhwoSorK5WTk6OsrCwtWbJEXq+XO+AAAH3EHEAvvfSS2tratGDBgj77Vq9ereTkZJWXlysUCqmsrEzr16+PS6EAgOEl5gD61re+JWPMcfelp6dr3bp1Wrdu3YALAwAMbzwLDgBgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgRczfiPp5k/V+uE+f81/RuZ3x797TVQ4ADBusgAAAVhBAAAArCCAAgBVD9hpQ6+w0JWek2S5DkjnFvk8aCnUDgB3hj8PSjpOPYwUEALCCAAIAWEEAAQCsIIAAAFYkGWNOdkX9tAoGg3K5XPr3/nOVNYJ8BIBEE+wMa+SX3lMgEFBWVtYJx/ETHgBgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAK2IKoN7eXlVXV6uwsFAZGRk677zzdNddd+mTd3IbY7R8+XKNHj1aGRkZKi0t1YEDB+JeOAAgscUUQPfee682bNig3/72t3r77bd17733atWqVXrggQciY1atWqW1a9dq48aN2rlzp84880yVlZWpu7s77sUDABJXTE/Dfu211zR79mzNnDlTkjR27Fg98cQT2rVrl6T/rH7WrFmjO+64Q7Nnz5YkPfroo3K73dq6dauuvvrqOJcPAEhUMa2ALrvsMtXX12v//v2SpDfeeEM7duzQjBkzJEmtra3y+XwqLS2NHONyuVRSUqLGxsbjnjMUCikYDEY1AMDwF9MK6Pbbb1cwGFRRUZFSUlLU29urFStWaN68eZIkn88nSXK73VHHud3uyL5Pq6mp0Z133tmf2gEACSymFdCTTz6pxx9/XJs3b9brr7+uRx55RL/+9a/1yCOP9LuAqqoqBQKBSGtvb+/3uQAAiSOmFdCtt96q22+/PXIt58ILL9T777+vmpoazZ8/Xx6PR5Lk9/s1evToyHF+v18XXXTRcc/pdDrldDr7WT4AIFHFtAL66KOPlJwcfUhKSorC4bAkqbCwUB6PR/X19ZH9wWBQO3fulNfrjUO5AIDhIqYV0KxZs7RixQoVFBToggsu0J/+9Cfdd999WrBggSQpKSlJS5cu1d13361x48apsLBQ1dXVysvL05w5cwajfgBAgoopgB544AFVV1frRz/6kQ4fPqy8vDz98Ic/1PLlyyNjbrvtNnV1dWnRokXq6OjQtGnTtH37dqWnp8e9eABA4uIL6QAAccUX0gEAhjQCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAK2L6IOrp8N+PJQWPhC1XAgDoj//+/D7Zx0yHXAB1dnZKksZc/De7hQAABqSzs1Mul+uE+4fckxDC4bAOHjyoESNGqLOzU/n5+Wpvb//MT9Oif4LBIPM7iJjfwcX8Dq6BzK8xRp2dncrLy+vzAOtPGnIroOTkZJ1zzjmS/vNwU0nKysriDTaImN/BxfwOLuZ3cPV3fj9r5fNf3IQAALCCAAIAWDGkA8jpdOoXv/gF35g6SJjfwcX8Di7md3CdjvkdcjchAAA+H4b0CggAMHwRQAAAKwggAIAVBBAAwAoCCABgxZANoHXr1mns2LFKT09XSUmJdu3aZbukhFRTU6NLLrlEI0aM0KhRozRnzhy1tLREjenu7lZFRYVyc3OVmZmp8vJy+f1+SxUnrpUrVyopKUlLly6N9DG3A/fBBx/o2muvVW5urjIyMnThhRdqz549kf3GGC1fvlyjR49WRkaGSktLdeDAAYsVJ47e3l5VV1ersLBQGRkZOu+883TXXXdFPUR0UOfXDEFbtmwxaWlp5ve//735y1/+Ym688UaTnZ1t/H6/7dISTllZmamtrTX79u0ze/fuNd/+9rdNQUGBOXLkSGTMTTfdZPLz8019fb3Zs2ePmTJlirnsssssVp14du3aZcaOHWsmTpxobrnllkg/czsw//rXv8yYMWPM9ddfb3bu3Gnee+8988ILL5h33303MmblypXG5XKZrVu3mjfeeMN85zvfMYWFhebjjz+2WHliWLFihcnNzTXPPfecaW1tNXV1dSYzM9Pcf//9kTGDOb9DMoAuvfRSU1FREdnu7e01eXl5pqamxmJVw8Phw4eNJNPQ0GCMMaajo8Okpqaaurq6yJi3337bSDKNjY22ykwonZ2dZty4cebFF180X/va1yIBxNwO3E9/+lMzbdq0E+4Ph8PG4/GYX/3qV5G+jo4O43Q6zRNPPHE6SkxoM2fONAsWLIjqmzt3rpk3b54xZvDnd8j9Cq6np0fNzc0qLS2N9CUnJ6u0tFSNjY0WKxseAoGAJCknJ0eS1NzcrKNHj0bNd1FRkQoKCpjvU1RRUaGZM2dGzaHE3MbDs88+q8mTJ+vKK6/UqFGjNGnSJD300EOR/a2trfL5fFFz7HK5VFJSwhyfgssuu0z19fXav3+/JOmNN97Qjh07NGPGDEmDP79D7mnYH374oXp7e+V2u6P63W633nnnHUtVDQ/hcFhLly7V1KlTNWHCBEmSz+dTWlqasrOzo8a63W75fD4LVSaWLVu26PXXX9fu3bv77GNuB+69997Thg0bVFlZqZ/97GfavXu3fvzjHystLU3z58+PzOPxfl4wxyd3++23KxgMqqioSCkpKert7dWKFSs0b948SRr0+R1yAYTBU1FRoX379mnHjh22SxkW2tvbdcstt+jFF19Uenq67XKGpXA4rMmTJ+uee+6RJE2aNEn79u3Txo0bNX/+fMvVJb4nn3xSjz/+uDZv3qwLLrhAe/fu1dKlS5WXl3da5nfI/QrurLPOUkpKSp87hfx+vzwej6WqEt/ixYv13HPP6Y9//GPk+5YkyePxqKenRx0dHVHjme+Ta25u1uHDh3XxxRfL4XDI4XCooaFBa9eulcPhkNvtZm4HaPTo0Tr//POj+saPH6+2tjZJiswjPy/659Zbb9Xtt9+uq6++WhdeeKF+8IMfaNmyZaqpqZE0+PM75AIoLS1NxcXFqq+vj/SFw2HV19fL6/VarCwxGWO0ePFiPf3003r55ZdVWFgYtb+4uFipqalR893S0qK2tjbm+ySuuOIKvfnmm9q7d2+kTZ48WfPmzYv8mbkdmKlTp/b52MD+/fs1ZswYSVJhYaE8Hk/UHAeDQe3cuZM5PgUfffRRn28sTUlJUTgclnQa5nfAtzEMgi1bthin02kefvhh89Zbb5lFixaZ7Oxs4/P5bJeWcG6++WbjcrnMK6+8Yg4dOhRpH330UWTMTTfdZAoKCszLL79s9uzZY7xer/F6vRarTlyfvAvOGOZ2oHbt2mUcDodZsWKFOXDggHn88cfNGWecYR577LHImJUrV5rs7GzzzDPPmD//+c9m9uzZ3IZ9iubPn2++8IUvRG7Dfuqpp8xZZ51lbrvttsiYwZzfIRlAxhjzwAMPmIKCApOWlmYuvfRS09TUZLukhCTpuK22tjYy5uOPPzY/+tGPzMiRI80ZZ5xhvvvd75pDhw7ZKzqBfTqAmNuB27Ztm5kwYYJxOp2mqKjIPPjgg1H7w+Gwqa6uNm632zidTnPFFVeYlpYWS9UmlmAwaG655RZTUFBg0tPTzbnnnmt+/vOfm1AoFBkzmPPL9wEBAKwYcteAAACfDwQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYMX/A/bJhYjGb3qLAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create and wrap the environment\n",
        "env = gym.make('PongNoFrameskip-v4')\n",
        "env = AtariPreprocessing(env,\n",
        "                         scale_obs=False,\n",
        "                         terminal_on_life_loss=True,\n",
        "                         )\n",
        "env = FrameStack(env, num_stack=4)\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "# env.render()\n",
        "test = env.reset()\n",
        "for i in range(100):\n",
        "    test = env.step(env.action_space.sample())[0]\n",
        "\n",
        "plt.imshow(test.__array__()[0,...])\n",
        "\n",
        "# env.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Deep-Q Network\n",
        "\n",
        "对于复杂的问题，state维度非常大，我们很难基于tabular method来判断每一个(state, action)的价值。这种情况下，我们利用function approximation方法，构建一个深度神经网络(Deep-Q Network, DQN)，来估计(state, action)的价值。value()中Deep-Q Network模块就是一个神经网络，输入是atari game中的一帧图像，输出是每个action的价值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X_yXh2wANroR"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, in_channels=4, num_actions=5):\n",
        "        \"\"\"\n",
        "        Initialize a deep Q-learning network as described in\n",
        "        https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf\n",
        "        Arguments:\n",
        "            in_channels: number of channel of input.\n",
        "                i.e The number of most recent frames stacked together as describe in the paper\n",
        "            num_actions: number of action-value to output, one-to-one correspondence to action in game.\n",
        "        \"\"\"\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
        "        self.fc5 = nn.Linear(512, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.fc4(x.reshape(x.size(0), -1)))\n",
        "        return self.fc5(x)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Memory\n",
        "因为深度神经网络收敛很慢，需要非常多的样本，如果只根据环境交互来训练网络，将非常的没效率。因此DQN引入了一个memory buffer来进行memory replay，就是把之前和环境交互的经验存下来，在训练时重复利用。memory buffer主要实现两个函数：`push`函数将经验存入，`sample`函数将经验取出用于训练。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pFHzSKOqNroS"
      },
      "outputs": [],
      "source": [
        "class Memory_Buffer(object):\n",
        "    def __init__(self, memory_size=100000):\n",
        "        self.buffer = []\n",
        "        self.memory_size = memory_size\n",
        "        self.next_idx = 0\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        data = (state, action, reward, next_state, done)\n",
        "        if len(self.buffer) <= self.memory_size: # buffer not full\n",
        "            self.buffer.append(data)\n",
        "        else: # buffer is full\n",
        "            self.buffer[self.next_idx] = data\n",
        "        self.next_idx = (self.next_idx + 1) % self.memory_size\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            idx = random.randint(0, self.size() - 1)\n",
        "            data = self.buffer[idx]\n",
        "            state, action, reward, next_state, done= data\n",
        "            states.append(state)\n",
        "            actions.append(action)\n",
        "            rewards.append(reward)\n",
        "            next_states.append(next_state)\n",
        "            dones.append(done)\n",
        "\n",
        "        return np.concatenate(states), actions, rewards, np.concatenate(next_states), dones\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Agent\n",
        "\n",
        "下面，我们要写最复杂的部分，实现基于DQN的智能体。我们分别实现了下列函数：\n",
        "\n",
        "- `__init__`: 初始化DQN智能体的参数和网络。\n",
        "- `observe`: 将Atari环境每一步返回的observation（numpy矩阵）转为状态（pytorch tensor）。\n",
        "- `value`: 返回状态的Q值。\n",
        "- `act`: 给定状态，根据epsilon greedy算法给出当前动作。\n",
        "- `sample_from_buffer`: 学习相关，从memory buffer抽样经验。\n",
        "- `compute_td_loss`: 学习相关，利用从memory buffer抽样的经验计算TD Loss。\n",
        "- `learn_from_experience`: 学习相关，利用TD Loss进行梯度下降，优化网络。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2VnmExe-NroS"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, in_channels = 1, action_space = [], USE_CUDA = False, memory_size = 10000, epsilon  = 1, lr = 1e-4):\n",
        "        self.epsilon = epsilon\n",
        "        self.action_space = action_space\n",
        "        self.memory_buffer = Memory_Buffer(memory_size)\n",
        "        self.DQN = DQN(in_channels = in_channels, num_actions = action_space.n)\n",
        "        self.DQN_target = DQN(in_channels = in_channels, num_actions = action_space.n)\n",
        "        self.DQN_target.load_state_dict(self.DQN.state_dict())\n",
        "\n",
        "        self.USE_CUDA = USE_CUDA\n",
        "        if USE_CUDA:\n",
        "            self.DQN = self.DQN.cuda()\n",
        "            self.DQN_target = self.DQN_target.cuda()\n",
        "        self.optimizer = optim.RMSprop(self.DQN.parameters(),lr=lr, eps=0.001, alpha=0.95)\n",
        "\n",
        "    def observe(self, lazyframe):\n",
        "        # from Lazy frame to tensor\n",
        "        state =  torch.from_numpy(lazyframe.__array__()[None]/255).float()\n",
        "        if self.USE_CUDA:\n",
        "            state = state.cuda()\n",
        "        return state\n",
        "\n",
        "    def value(self, state):\n",
        "        q_values = self.DQN(state)\n",
        "        return q_values\n",
        "\n",
        "    def act(self, state, epsilon = None):\n",
        "        \"\"\"\n",
        "        sample actions with epsilon-greedy policy\n",
        "        recap: with p = epsilon pick random action, else pick action with highest Q(s,a)\n",
        "        \"\"\"\n",
        "        if epsilon is None: epsilon = self.epsilon\n",
        "\n",
        "        q_values = self.value(state).cpu().detach().numpy()\n",
        "        if random.random()<epsilon:\n",
        "            aciton = random.randrange(self.action_space.n)\n",
        "        else:\n",
        "            aciton = q_values.argmax(1)[0]\n",
        "        return aciton\n",
        "\n",
        "    def compute_td_loss(self, states, actions, rewards, next_states, is_done, gamma=0.99):\n",
        "        \"\"\" Compute td loss using torch operations only. Use the formula above. \"\"\"\n",
        "        actions = torch.tensor(actions).long()    # shape: [batch_size]\n",
        "        rewards = torch.tensor(rewards, dtype =torch.float)  # shape: [batch_size]\n",
        "        is_done = torch.tensor(is_done).bool()  # shape: [batch_size]\n",
        "\n",
        "        if self.USE_CUDA:\n",
        "            actions = actions.cuda()\n",
        "            rewards = rewards.cuda()\n",
        "            is_done = is_done.cuda()\n",
        "\n",
        "        # get q-values for all actions in current states\n",
        "        predicted_qvalues = self.DQN(states)\n",
        "\n",
        "        # select q-values for chosen actions\n",
        "        predicted_qvalues_for_actions = predicted_qvalues[\n",
        "          range(states.shape[0]), actions\n",
        "        ]\n",
        "\n",
        "        # compute q-values for all actions in next states\n",
        "        predicted_next_qvalues = self.DQN_target(next_states) # YOUR CODE\n",
        "\n",
        "        # compute V*(next_states) using predicted next q-values\n",
        "        next_state_values =  predicted_next_qvalues.max(-1)[0] # YOUR CODE\n",
        "\n",
        "        # compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
        "        target_qvalues_for_actions = rewards + gamma *next_state_values # YOUR CODE\n",
        "\n",
        "        # at the last state we shall use simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
        "        target_qvalues_for_actions = torch.where(\n",
        "            is_done, rewards, target_qvalues_for_actions)\n",
        "\n",
        "        # mean squared error loss to minimize\n",
        "        #loss = torch.mean((predicted_qvalues_for_actions -\n",
        "        #                   target_qvalues_for_actions.detach()) ** 2)\n",
        "        loss = F.smooth_l1_loss(predicted_qvalues_for_actions, target_qvalues_for_actions.detach())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def sample_from_buffer(self, batch_size):\n",
        "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
        "        for i in range(batch_size):\n",
        "            idx = random.randint(0, self.memory_buffer.size() - 1)\n",
        "            data = self.memory_buffer.buffer[idx]\n",
        "            frame, action, reward, next_frame, done= data\n",
        "            states.append(self.observe(frame))\n",
        "            actions.append(action)\n",
        "            rewards.append(reward)\n",
        "            next_states.append(self.observe(next_frame))\n",
        "            dones.append(done)\n",
        "        return torch.cat(states), actions, rewards, torch.cat(next_states), dones\n",
        "\n",
        "    def learn_from_experience(self, batch_size):\n",
        "        if self.memory_buffer.size() > batch_size:\n",
        "            states, actions, rewards, next_states, dones = self.sample_from_buffer(batch_size)\n",
        "            td_loss = self.compute_td_loss(states, actions, rewards, next_states, dones)\n",
        "            self.optimizer.zero_grad()\n",
        "            td_loss.backward()\n",
        "            for param in self.DQN.parameters():\n",
        "                param.grad.data.clamp_(-1, 1)\n",
        "\n",
        "            self.optimizer.step()\n",
        "            return(td_loss.item())\n",
        "        else:\n",
        "            return(0)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Traning\n",
        "\n",
        "接下来是最重要的训练部分，基本上就是定好初始参数，要训练的总帧数，然后让智能体与环境交互并学习。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsrAIr7TNroT",
        "outputId": "e1577d15-195e-4649-b798-e1d34c63adcd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/neaf2080/.pyenv/versions/3.8.18/envs/RL_gym/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "/home/neaf2080/.pyenv/versions/3.8.18/envs/RL_gym/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/home/neaf2080/.pyenv/versions/3.8.18/envs/RL_gym/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frames:     0, reward:   nan, loss: 0.000000, epsilon: 1.000000, episode:    0\n",
            "frames:  1000, reward: -21.000000, loss: 0.000000, epsilon: 0.968855, episode:    1\n",
            "frames:  2000, reward: -20.500000, loss: 0.000000, epsilon: 0.938732, episode:    2\n",
            "frames:  3000, reward: -20.666667, loss: 0.000000, epsilon: 0.909596, episode:    3\n",
            "frames:  4000, reward: -20.750000, loss: 0.000000, epsilon: 0.881415, episode:    4\n",
            "frames:  5000, reward: -20.800000, loss: 0.000000, epsilon: 0.854158, episode:    5\n",
            "frames:  6000, reward: -20.857143, loss: 0.000000, epsilon: 0.827794, episode:    7\n",
            "frames:  7000, reward: -20.875000, loss: 0.000000, epsilon: 0.802295, episode:    8\n",
            "frames:  8000, reward: -20.888889, loss: 0.000000, epsilon: 0.777632, episode:    9\n",
            "frames:  9000, reward: -20.900000, loss: 0.000000, epsilon: 0.753777, episode:   11\n",
            "frames: 10000, reward: -21.000000, loss: 0.014446, epsilon: 0.730705, episode:   12\n",
            "frames: 11000, reward: -20.900000, loss: 0.015243, epsilon: 0.708389, episode:   13\n",
            "frames: 12000, reward: -20.900000, loss: 0.014989, epsilon: 0.686804, episode:   14\n",
            "frames: 13000, reward: -20.900000, loss: 0.000392, epsilon: 0.665927, episode:   15\n",
            "frames: 14000, reward: -20.900000, loss: 0.000319, epsilon: 0.645735, episode:   17\n",
            "frames: 15000, reward: -20.900000, loss: 0.000192, epsilon: 0.626204, episode:   18\n",
            "frames: 16000, reward: -20.800000, loss: 0.000363, epsilon: 0.607314, episode:   19\n",
            "frames: 17000, reward: -20.600000, loss: 0.015014, epsilon: 0.589043, episode:   20\n",
            "frames: 18000, reward: -20.300000, loss: 0.015444, epsilon: 0.571371, episode:   21\n",
            "frames: 19000, reward: -20.300000, loss: 0.015364, epsilon: 0.554278, episode:   22\n",
            "frames: 20000, reward: -20.400000, loss: 0.030427, epsilon: 0.537746, episode:   23\n",
            "frames: 21000, reward: -20.300000, loss: 0.000296, epsilon: 0.521756, episode:   24\n",
            "frames: 22000, reward: -20.300000, loss: 0.000336, epsilon: 0.506290, episode:   25\n",
            "frames: 23000, reward: -20.200000, loss: 0.029777, epsilon: 0.491331, episode:   26\n",
            "frames: 24000, reward: -20.200000, loss: 0.015167, epsilon: 0.476863, episode:   28\n",
            "frames: 25000, reward: -20.300000, loss: 0.015131, epsilon: 0.462868, episode:   29\n",
            "frames: 26000, reward: -20.400000, loss: 0.000137, epsilon: 0.449333, episode:   30\n",
            "frames: 27000, reward: -20.500000, loss: 0.016082, epsilon: 0.436241, episode:   31\n",
            "frames: 28000, reward: -20.400000, loss: 0.014942, epsilon: 0.423579, episode:   32\n",
            "frames: 29000, reward: -20.400000, loss: 0.030498, epsilon: 0.411331, episode:   33\n",
            "frames: 30000, reward: -20.400000, loss: 0.015402, epsilon: 0.399485, episode:   34\n",
            "frames: 31000, reward: -20.300000, loss: 0.015078, epsilon: 0.388028, episode:   35\n",
            "frames: 32000, reward: -20.400000, loss: 0.044421, epsilon: 0.376946, episode:   37\n",
            "frames: 33000, reward: -20.200000, loss: 0.000148, epsilon: 0.366228, episode:   38\n",
            "frames: 34000, reward: -20.200000, loss: 0.000772, epsilon: 0.355860, episode:   39\n",
            "frames: 35000, reward: -20.300000, loss: 0.000065, epsilon: 0.345833, episode:   40\n",
            "frames: 36000, reward: -20.500000, loss: 0.029948, epsilon: 0.336135, episode:   41\n",
            "frames: 37000, reward: -20.500000, loss: 0.000525, epsilon: 0.326754, episode:   42\n",
            "frames: 38000, reward: -20.400000, loss: 0.015159, epsilon: 0.317681, episode:   43\n",
            "frames: 39000, reward: -20.500000, loss: 0.015226, epsilon: 0.308905, episode:   44\n",
            "frames: 40000, reward: -20.600000, loss: 0.015444, epsilon: 0.300417, episode:   45\n",
            "frames: 41000, reward: -20.300000, loss: 0.015278, epsilon: 0.292208, episode:   46\n",
            "frames: 42000, reward: -20.300000, loss: 0.014631, epsilon: 0.284267, episode:   47\n",
            "frames: 43000, reward: -20.300000, loss: 0.014629, epsilon: 0.276587, episode:   49\n",
            "frames: 44000, reward: -20.300000, loss: 0.015464, epsilon: 0.269159, episode:   50\n",
            "frames: 45000, reward: -20.300000, loss: 0.044490, epsilon: 0.261974, episode:   51\n",
            "frames: 46000, reward: -20.400000, loss: 0.030590, epsilon: 0.255024, episode:   52\n",
            "frames: 47000, reward: -20.500000, loss: 0.030654, epsilon: 0.248303, episode:   53\n",
            "frames: 48000, reward: -20.500000, loss: 0.000553, epsilon: 0.241802, episode:   54\n",
            "frames: 49000, reward: -20.300000, loss: 0.045919, epsilon: 0.235514, episode:   55\n",
            "frames: 50000, reward: -20.500000, loss: 0.000169, epsilon: 0.229432, episode:   57\n",
            "frames: 51000, reward: -20.500000, loss: 0.037632, epsilon: 0.223549, episode:   58\n",
            "frames: 52000, reward: -20.500000, loss: 0.029676, epsilon: 0.217860, episode:   59\n",
            "frames: 53000, reward: -20.400000, loss: 0.000557, epsilon: 0.212357, episode:   60\n",
            "frames: 54000, reward: -20.400000, loss: 0.000552, epsilon: 0.207034, episode:   61\n",
            "frames: 55000, reward: -20.400000, loss: 0.014590, epsilon: 0.201886, episode:   62\n",
            "frames: 56000, reward: -20.400000, loss: 0.000701, epsilon: 0.196906, episode:   64\n",
            "frames: 57000, reward: -20.500000, loss: 0.043667, epsilon: 0.192090, episode:   65\n",
            "frames: 58000, reward: -20.500000, loss: 0.014207, epsilon: 0.187432, episode:   65\n",
            "frames: 59000, reward: -20.500000, loss: 0.023112, epsilon: 0.182926, episode:   67\n",
            "frames: 60000, reward: -20.500000, loss: 0.008660, epsilon: 0.178569, episode:   67\n",
            "frames: 61000, reward: -20.600000, loss: 0.000634, epsilon: 0.174354, episode:   69\n",
            "frames: 62000, reward: -20.700000, loss: 0.002867, epsilon: 0.170277, episode:   70\n",
            "frames: 63000, reward: -20.600000, loss: 0.017393, epsilon: 0.166334, episode:   71\n",
            "frames: 64000, reward: -20.600000, loss: 0.014287, epsilon: 0.162520, episode:   72\n",
            "frames: 65000, reward: -20.500000, loss: 0.004916, epsilon: 0.158831, episode:   73\n",
            "frames: 66000, reward: -20.500000, loss: 0.017714, epsilon: 0.155263, episode:   74\n",
            "frames: 67000, reward: -20.600000, loss: 0.025801, epsilon: 0.151812, episode:   75\n",
            "frames: 68000, reward: -20.700000, loss: 0.019277, epsilon: 0.148474, episode:   77\n",
            "frames: 69000, reward: -20.800000, loss: 0.001846, epsilon: 0.145246, episode:   78\n",
            "frames: 70000, reward: -20.800000, loss: 0.002409, epsilon: 0.142123, episode:   79\n",
            "frames: 71000, reward: -20.700000, loss: 0.000883, epsilon: 0.139103, episode:   80\n",
            "frames: 72000, reward: -20.800000, loss: 0.015304, epsilon: 0.136182, episode:   81\n",
            "frames: 73000, reward: -20.800000, loss: 0.001006, epsilon: 0.133357, episode:   82\n",
            "frames: 74000, reward: -20.900000, loss: 0.000949, epsilon: 0.130624, episode:   84\n",
            "frames: 75000, reward: -20.900000, loss: 0.021027, epsilon: 0.127981, episode:   85\n",
            "frames: 76000, reward: -20.900000, loss: 0.001505, epsilon: 0.125424, episode:   86\n",
            "frames: 77000, reward: -20.900000, loss: 0.005888, epsilon: 0.122952, episode:   87\n",
            "frames: 78000, reward: -20.900000, loss: 0.001330, epsilon: 0.120560, episode:   88\n",
            "frames: 79000, reward: -21.000000, loss: 0.003772, epsilon: 0.118247, episode:   90\n",
            "frames: 80000, reward: -20.900000, loss: 0.001387, epsilon: 0.116009, episode:   91\n",
            "frames: 81000, reward: -20.800000, loss: 0.000760, epsilon: 0.113845, episode:   92\n",
            "frames: 82000, reward: -20.800000, loss: 0.003791, epsilon: 0.111752, episode:   93\n",
            "frames: 83000, reward: -20.800000, loss: 0.003329, epsilon: 0.109728, episode:   94\n",
            "frames: 84000, reward: -20.800000, loss: 0.004344, epsilon: 0.107770, episode:   95\n",
            "frames: 85000, reward: -20.800000, loss: 0.002250, epsilon: 0.105876, episode:   96\n",
            "frames: 86000, reward: -20.800000, loss: 0.003987, epsilon: 0.104044, episode:   97\n",
            "frames: 87000, reward: -20.700000, loss: 0.007546, epsilon: 0.102272, episode:   99\n",
            "frames: 88000, reward: -20.600000, loss: 0.001517, epsilon: 0.100558, episode:  100\n",
            "frames: 89000, reward: -20.700000, loss: 0.000440, epsilon: 0.098901, episode:  101\n",
            "frames: 90000, reward: -20.700000, loss: 0.001546, epsilon: 0.097298, episode:  102\n",
            "frames: 91000, reward: -20.700000, loss: 0.000964, epsilon: 0.095747, episode:  103\n",
            "frames: 92000, reward: -20.700000, loss: 0.002230, epsilon: 0.094247, episode:  104\n",
            "frames: 93000, reward: -20.700000, loss: 0.007702, epsilon: 0.092797, episode:  105\n",
            "frames: 94000, reward: -20.700000, loss: 0.001628, epsilon: 0.091394, episode:  106\n",
            "frames: 95000, reward: -20.700000, loss: 0.001100, epsilon: 0.090037, episode:  107\n",
            "frames: 96000, reward: -20.700000, loss: 0.002487, epsilon: 0.088724, episode:  108\n",
            "frames: 97000, reward: -20.800000, loss: 0.004031, epsilon: 0.087455, episode:  109\n",
            "frames: 98000, reward: -20.900000, loss: 0.000595, epsilon: 0.086227, episode:  110\n",
            "frames: 99000, reward: -20.900000, loss: 0.002143, epsilon: 0.085039, episode:  111\n",
            "frames: 100000, reward: -21.000000, loss: 0.002733, epsilon: 0.083890, episode:  112\n",
            "frames: 101000, reward: -20.900000, loss: 0.001922, epsilon: 0.082779, episode:  113\n",
            "frames: 102000, reward: -20.800000, loss: 0.002534, epsilon: 0.081705, episode:  114\n",
            "frames: 103000, reward: -20.700000, loss: 0.002779, epsilon: 0.080665, episode:  116\n",
            "frames: 104000, reward: -20.700000, loss: 0.001582, epsilon: 0.079660, episode:  117\n",
            "frames: 105000, reward: -20.700000, loss: 0.001390, epsilon: 0.078688, episode:  118\n",
            "frames: 106000, reward: -20.700000, loss: 0.004586, epsilon: 0.077747, episode:  119\n",
            "frames: 107000, reward: -20.700000, loss: 0.001680, epsilon: 0.076837, episode:  120\n",
            "frames: 108000, reward: -20.700000, loss: 0.004328, epsilon: 0.075958, episode:  121\n",
            "frames: 109000, reward: -20.700000, loss: 0.000424, epsilon: 0.075107, episode:  122\n",
            "frames: 110000, reward: -20.700000, loss: 0.001452, epsilon: 0.074283, episode:  123\n",
            "frames: 111000, reward: -20.800000, loss: 0.000832, epsilon: 0.073487, episode:  124\n",
            "frames: 112000, reward: -20.800000, loss: 0.001125, epsilon: 0.072717, episode:  125\n",
            "frames: 113000, reward: -20.800000, loss: 0.016597, epsilon: 0.071973, episode:  126\n",
            "frames: 114000, reward: -20.800000, loss: 0.003641, epsilon: 0.071252, episode:  127\n",
            "frames: 115000, reward: -20.600000, loss: 0.001065, epsilon: 0.070556, episode:  128\n",
            "frames: 116000, reward: -20.600000, loss: 0.000569, epsilon: 0.069882, episode:  129\n",
            "frames: 117000, reward: -20.600000, loss: 0.004438, epsilon: 0.069230, episode:  130\n",
            "frames: 118000, reward: -20.500000, loss: 0.001831, epsilon: 0.068599, episode:  131\n",
            "frames: 119000, reward: -20.400000, loss: 0.001693, epsilon: 0.067990, episode:  132\n",
            "frames: 120000, reward: -20.400000, loss: 0.001745, epsilon: 0.067400, episode:  132\n",
            "frames: 121000, reward: -20.500000, loss: 0.005059, epsilon: 0.066829, episode:  133\n",
            "frames: 122000, reward: -20.500000, loss: 0.001891, epsilon: 0.066278, episode:  134\n",
            "frames: 123000, reward: -20.500000, loss: 0.001497, epsilon: 0.065744, episode:  134\n",
            "frames: 124000, reward: -20.500000, loss: 0.002271, epsilon: 0.065228, episode:  135\n",
            "frames: 125000, reward: -20.500000, loss: 0.000977, epsilon: 0.064729, episode:  136\n",
            "frames: 126000, reward: -20.400000, loss: 0.004021, epsilon: 0.064246, episode:  137\n",
            "frames: 127000, reward: -20.600000, loss: 0.005053, epsilon: 0.063779, episode:  138\n",
            "frames: 128000, reward: -20.600000, loss: 0.001724, epsilon: 0.063327, episode:  138\n",
            "frames: 129000, reward: -20.500000, loss: 0.004201, epsilon: 0.062890, episode:  139\n",
            "frames: 130000, reward: -20.600000, loss: 0.001412, epsilon: 0.062468, episode:  141\n",
            "frames: 131000, reward: -20.600000, loss: 0.001720, epsilon: 0.062059, episode:  141\n",
            "frames: 132000, reward: -20.700000, loss: 0.001740, epsilon: 0.061663, episode:  142\n",
            "frames: 133000, reward: -20.700000, loss: 0.002385, epsilon: 0.061281, episode:  143\n",
            "frames: 134000, reward: -20.600000, loss: 0.001037, epsilon: 0.060911, episode:  144\n",
            "frames: 135000, reward: -20.600000, loss: 0.000666, epsilon: 0.060554, episode:  144\n",
            "frames: 136000, reward: -20.700000, loss: 0.002806, epsilon: 0.060208, episode:  145\n",
            "frames: 137000, reward: -20.700000, loss: 0.001199, epsilon: 0.059873, episode:  146\n",
            "frames: 138000, reward: -20.700000, loss: 0.000558, epsilon: 0.059549, episode:  146\n",
            "frames: 139000, reward: -20.800000, loss: 0.000531, epsilon: 0.059236, episode:  147\n",
            "frames: 140000, reward: -20.800000, loss: 0.001531, epsilon: 0.058933, episode:  149\n",
            "frames: 141000, reward: -20.800000, loss: 0.000950, epsilon: 0.058641, episode:  150\n",
            "frames: 142000, reward: -20.800000, loss: 0.005336, epsilon: 0.058357, episode:  151\n",
            "frames: 143000, reward: -20.700000, loss: 0.002567, epsilon: 0.058083, episode:  152\n",
            "frames: 144000, reward: -20.700000, loss: 0.003297, epsilon: 0.057818, episode:  152\n",
            "frames: 145000, reward: -20.100000, loss: 0.000803, epsilon: 0.057562, episode:  153\n",
            "frames: 146000, reward: -20.100000, loss: 0.001463, epsilon: 0.057314, episode:  154\n",
            "frames: 147000, reward: -19.900000, loss: 0.000480, epsilon: 0.057074, episode:  155\n",
            "frames: 148000, reward: -19.900000, loss: 0.003429, epsilon: 0.056842, episode:  155\n",
            "frames: 149000, reward: -19.800000, loss: 0.004422, epsilon: 0.056618, episode:  156\n",
            "frames: 150000, reward: -19.700000, loss: 0.001112, epsilon: 0.056401, episode:  157\n",
            "frames: 151000, reward: -19.800000, loss: 0.005529, epsilon: 0.056191, episode:  158\n",
            "frames: 152000, reward: -19.800000, loss: 0.002615, epsilon: 0.055988, episode:  158\n",
            "frames: 153000, reward: -19.600000, loss: 0.000802, epsilon: 0.055792, episode:  159\n",
            "frames: 154000, reward: -19.500000, loss: 0.002299, epsilon: 0.055602, episode:  160\n",
            "frames: 155000, reward: -19.500000, loss: 0.006031, epsilon: 0.055418, episode:  160\n",
            "frames: 156000, reward: -19.400000, loss: 0.002190, epsilon: 0.055241, episode:  161\n",
            "frames: 157000, reward: -19.500000, loss: 0.001058, epsilon: 0.055069, episode:  162\n",
            "frames: 158000, reward: -19.500000, loss: 0.002877, epsilon: 0.054903, episode:  162\n",
            "frames: 159000, reward: -19.900000, loss: 0.003785, epsilon: 0.054742, episode:  163\n",
            "frames: 160000, reward: -19.900000, loss: 0.001282, epsilon: 0.054587, episode:  163\n",
            "frames: 161000, reward: -20.000000, loss: 0.001399, epsilon: 0.054436, episode:  164\n",
            "frames: 162000, reward: -20.200000, loss: 0.001190, epsilon: 0.054291, episode:  165\n",
            "frames: 163000, reward: -20.200000, loss: 0.000788, epsilon: 0.054150, episode:  165\n",
            "frames: 164000, reward: -19.900000, loss: 0.002007, epsilon: 0.054014, episode:  166\n",
            "frames: 165000, reward: -19.900000, loss: 0.000894, epsilon: 0.053882, episode:  166\n",
            "frames: 166000, reward: -19.800000, loss: 0.007941, epsilon: 0.053755, episode:  167\n",
            "frames: 167000, reward: -19.800000, loss: 0.000858, epsilon: 0.053632, episode:  167\n",
            "frames: 168000, reward: -19.600000, loss: 0.000494, epsilon: 0.053513, episode:  168\n",
            "frames: 169000, reward: -19.600000, loss: 0.004711, epsilon: 0.053398, episode:  168\n",
            "frames: 170000, reward: -19.600000, loss: 0.003684, epsilon: 0.053286, episode:  169\n",
            "frames: 171000, reward: -19.700000, loss: 0.001135, epsilon: 0.053179, episode:  170\n",
            "frames: 172000, reward: -19.700000, loss: 0.000987, epsilon: 0.053074, episode:  170\n",
            "frames: 173000, reward: -19.700000, loss: 0.001493, epsilon: 0.052974, episode:  171\n",
            "frames: 174000, reward: -19.700000, loss: 0.001866, epsilon: 0.052876, episode:  171\n",
            "frames: 175000, reward: -19.700000, loss: 0.002371, epsilon: 0.052782, episode:  172\n",
            "frames: 176000, reward: -19.700000, loss: 0.003886, epsilon: 0.052691, episode:  172\n",
            "frames: 177000, reward: -19.600000, loss: 0.004079, epsilon: 0.052602, episode:  173\n",
            "frames: 178000, reward: -19.300000, loss: 0.007462, epsilon: 0.052517, episode:  174\n",
            "frames: 179000, reward: -19.300000, loss: 0.001430, epsilon: 0.052435, episode:  174\n",
            "frames: 180000, reward: -18.800000, loss: 0.002116, epsilon: 0.052355, episode:  175\n",
            "frames: 181000, reward: -18.800000, loss: 0.004071, epsilon: 0.052278, episode:  175\n",
            "frames: 182000, reward: -18.900000, loss: 0.002361, epsilon: 0.052203, episode:  176\n",
            "frames: 183000, reward: -18.800000, loss: 0.003965, epsilon: 0.052131, episode:  177\n",
            "frames: 184000, reward: -18.800000, loss: 0.002161, epsilon: 0.052061, episode:  177\n",
            "frames: 185000, reward: -18.200000, loss: 0.001705, epsilon: 0.051993, episode:  178\n",
            "frames: 186000, reward: -18.200000, loss: 0.001395, epsilon: 0.051928, episode:  178\n",
            "frames: 187000, reward: -18.100000, loss: 0.002830, epsilon: 0.051865, episode:  179\n",
            "frames: 188000, reward: -18.100000, loss: 0.003000, epsilon: 0.051804, episode:  179\n",
            "frames: 189000, reward: -17.200000, loss: 0.001523, epsilon: 0.051744, episode:  180\n",
            "frames: 190000, reward: -17.300000, loss: 0.001789, epsilon: 0.051687, episode:  181\n",
            "frames: 191000, reward: -17.300000, loss: 0.004735, epsilon: 0.051632, episode:  181\n",
            "frames: 192000, reward: -17.100000, loss: 0.000799, epsilon: 0.051578, episode:  182\n",
            "frames: 193000, reward: -17.100000, loss: 0.001736, epsilon: 0.051527, episode:  182\n",
            "frames: 194000, reward: -17.000000, loss: 0.005887, epsilon: 0.051477, episode:  183\n",
            "frames: 195000, reward: -16.500000, loss: 0.002641, epsilon: 0.051428, episode:  184\n",
            "frames: 196000, reward: -16.500000, loss: 0.003163, epsilon: 0.051381, episode:  184\n",
            "frames: 197000, reward: -16.000000, loss: 0.004811, epsilon: 0.051336, episode:  185\n",
            "frames: 198000, reward: -16.000000, loss: 0.002157, epsilon: 0.051292, episode:  185\n",
            "frames: 199000, reward: -15.600000, loss: 0.003474, epsilon: 0.051250, episode:  186\n",
            "frames: 200000, reward: -15.800000, loss: 0.002052, epsilon: 0.051209, episode:  187\n",
            "frames: 201000, reward: -15.800000, loss: 0.003246, epsilon: 0.051169, episode:  187\n",
            "frames: 202000, reward: -16.300000, loss: 0.002181, epsilon: 0.051131, episode:  188\n",
            "frames: 203000, reward: -16.600000, loss: 0.001805, epsilon: 0.051094, episode:  189\n",
            "frames: 204000, reward: -16.600000, loss: 0.002635, epsilon: 0.051058, episode:  189\n",
            "frames: 205000, reward: -16.800000, loss: 0.002282, epsilon: 0.051023, episode:  190\n",
            "frames: 206000, reward: -16.800000, loss: 0.003987, epsilon: 0.050990, episode:  190\n",
            "frames: 207000, reward: -15.600000, loss: 0.002858, epsilon: 0.050957, episode:  191\n",
            "frames: 208000, reward: -15.600000, loss: 0.002106, epsilon: 0.050926, episode:  191\n",
            "frames: 209000, reward: -14.600000, loss: 0.002081, epsilon: 0.050896, episode:  192\n",
            "frames: 210000, reward: -14.600000, loss: 0.002296, epsilon: 0.050866, episode:  192\n",
            "frames: 211000, reward: -14.200000, loss: 0.002152, epsilon: 0.050838, episode:  193\n",
            "frames: 212000, reward: -14.900000, loss: 0.001051, epsilon: 0.050810, episode:  194\n",
            "frames: 213000, reward: -15.900000, loss: 0.005206, epsilon: 0.050784, episode:  195\n",
            "frames: 214000, reward: -15.900000, loss: 0.001583, epsilon: 0.050758, episode:  195\n",
            "frames: 215000, reward: -16.600000, loss: 0.002595, epsilon: 0.050733, episode:  196\n",
            "frames: 216000, reward: -16.600000, loss: 0.000920, epsilon: 0.050709, episode:  196\n",
            "frames: 217000, reward: -15.500000, loss: 0.003543, epsilon: 0.050686, episode:  197\n",
            "frames: 218000, reward: -15.500000, loss: 0.002793, epsilon: 0.050664, episode:  197\n",
            "frames: 219000, reward: -14.500000, loss: 0.002208, epsilon: 0.050642, episode:  198\n",
            "frames: 220000, reward: -14.500000, loss: 0.001561, epsilon: 0.050621, episode:  198\n",
            "frames: 221000, reward: -13.800000, loss: 0.006375, epsilon: 0.050600, episode:  199\n",
            "frames: 222000, reward: -13.900000, loss: 0.003941, epsilon: 0.050581, episode:  200\n",
            "frames: 223000, reward: -13.900000, loss: 0.000881, epsilon: 0.050562, episode:  200\n",
            "frames: 224000, reward: -15.100000, loss: 0.005403, epsilon: 0.050543, episode:  201\n",
            "frames: 225000, reward: -15.100000, loss: 0.001285, epsilon: 0.050525, episode:  201\n",
            "frames: 226000, reward: -14.500000, loss: 0.005066, epsilon: 0.050508, episode:  202\n",
            "frames: 227000, reward: -14.500000, loss: 0.002999, epsilon: 0.050492, episode:  202\n",
            "frames: 228000, reward: -14.100000, loss: 0.002503, epsilon: 0.050475, episode:  203\n",
            "frames: 229000, reward: -14.100000, loss: 0.003697, epsilon: 0.050460, episode:  203\n",
            "frames: 230000, reward: -14.000000, loss: 0.001361, epsilon: 0.050445, episode:  204\n",
            "frames: 231000, reward: -14.000000, loss: 0.002501, epsilon: 0.050430, episode:  205\n",
            "frames: 232000, reward: -14.000000, loss: 0.002516, epsilon: 0.050416, episode:  205\n",
            "frames: 233000, reward: -14.000000, loss: 0.000851, epsilon: 0.050402, episode:  205\n",
            "frames: 234000, reward: -12.400000, loss: 0.002681, epsilon: 0.050389, episode:  206\n",
            "frames: 235000, reward: -12.400000, loss: 0.002739, epsilon: 0.050376, episode:  206\n",
            "frames: 236000, reward: -11.900000, loss: 0.002046, epsilon: 0.050364, episode:  207\n",
            "frames: 237000, reward: -11.900000, loss: 0.001312, epsilon: 0.050352, episode:  207\n",
            "frames: 238000, reward: -11.800000, loss: 0.001723, epsilon: 0.050341, episode:  208\n",
            "frames: 239000, reward: -12.200000, loss: 0.000912, epsilon: 0.050329, episode:  209\n",
            "frames: 240000, reward: -12.200000, loss: 0.000705, epsilon: 0.050319, episode:  209\n",
            "frames: 241000, reward: -12.200000, loss: 0.004202, epsilon: 0.050308, episode:  209\n",
            "frames: 242000, reward: -11.300000, loss: 0.000868, epsilon: 0.050298, episode:  210\n",
            "frames: 243000, reward: -11.300000, loss: 0.002577, epsilon: 0.050288, episode:  211\n",
            "frames: 244000, reward: -12.200000, loss: 0.001187, epsilon: 0.050279, episode:  212\n",
            "frames: 245000, reward: -12.200000, loss: 0.003997, epsilon: 0.050270, episode:  212\n",
            "frames: 246000, reward: -13.000000, loss: 0.002651, epsilon: 0.050261, episode:  213\n",
            "frames: 247000, reward: -13.000000, loss: 0.005038, epsilon: 0.050252, episode:  213\n",
            "frames: 248000, reward: -12.000000, loss: 0.000987, epsilon: 0.050244, episode:  214\n",
            "frames: 249000, reward: -11.900000, loss: 0.002696, epsilon: 0.050236, episode:  215\n",
            "frames: 250000, reward: -13.500000, loss: 0.001617, epsilon: 0.050228, episode:  216\n",
            "frames: 251000, reward: -15.100000, loss: 0.001711, epsilon: 0.050221, episode:  217\n",
            "frames: 252000, reward: -16.500000, loss: 0.001108, epsilon: 0.050214, episode:  218\n",
            "frames: 253000, reward: -16.600000, loss: 0.004870, epsilon: 0.050207, episode:  219\n",
            "frames: 254000, reward: -18.000000, loss: 0.003460, epsilon: 0.050200, episode:  220\n",
            "frames: 255000, reward: -17.900000, loss: 0.002467, epsilon: 0.050193, episode:  221\n",
            "frames: 256000, reward: -19.000000, loss: 0.001822, epsilon: 0.050187, episode:  223\n",
            "frames: 257000, reward: -19.000000, loss: 0.002434, epsilon: 0.050181, episode:  223\n",
            "frames: 258000, reward: -20.000000, loss: 0.002358, epsilon: 0.050175, episode:  224\n",
            "frames: 259000, reward: -19.900000, loss: 0.002056, epsilon: 0.050169, episode:  225\n",
            "frames: 260000, reward: -19.300000, loss: 0.001532, epsilon: 0.050164, episode:  226\n",
            "frames: 261000, reward: -19.400000, loss: 0.002919, epsilon: 0.050158, episode:  227\n",
            "frames: 262000, reward: -19.400000, loss: 0.006713, epsilon: 0.050153, episode:  227\n",
            "frames: 263000, reward: -19.100000, loss: 0.005750, epsilon: 0.050148, episode:  228\n",
            "frames: 264000, reward: -19.300000, loss: 0.005049, epsilon: 0.050143, episode:  229\n",
            "frames: 265000, reward: -18.600000, loss: 0.000952, epsilon: 0.050139, episode:  230\n",
            "frames: 266000, reward: -18.600000, loss: 0.001070, epsilon: 0.050134, episode:  230\n",
            "frames: 267000, reward: -18.600000, loss: 0.004019, epsilon: 0.050130, episode:  231\n",
            "frames: 268000, reward: -18.400000, loss: 0.002780, epsilon: 0.050125, episode:  232\n",
            "frames: 269000, reward: -18.400000, loss: 0.002804, epsilon: 0.050121, episode:  232\n",
            "frames: 270000, reward: -18.100000, loss: 0.003041, epsilon: 0.050117, episode:  233\n",
            "frames: 271000, reward: -18.100000, loss: 0.001101, epsilon: 0.050113, episode:  233\n",
            "frames: 272000, reward: -17.500000, loss: 0.003150, epsilon: 0.050110, episode:  234\n",
            "frames: 273000, reward: -17.500000, loss: 0.002057, epsilon: 0.050106, episode:  234\n",
            "frames: 274000, reward: -17.100000, loss: 0.002179, epsilon: 0.050103, episode:  235\n",
            "frames: 275000, reward: -17.200000, loss: 0.005864, epsilon: 0.050099, episode:  236\n",
            "frames: 276000, reward: -17.200000, loss: 0.002229, epsilon: 0.050096, episode:  236\n",
            "frames: 277000, reward: -16.000000, loss: 0.004063, epsilon: 0.050093, episode:  237\n",
            "frames: 278000, reward: -16.000000, loss: 0.001143, epsilon: 0.050090, episode:  237\n",
            "frames: 279000, reward: -16.200000, loss: 0.002042, epsilon: 0.050087, episode:  238\n",
            "frames: 280000, reward: -16.200000, loss: 0.000613, epsilon: 0.050084, episode:  238\n",
            "frames: 281000, reward: -15.300000, loss: 0.002811, epsilon: 0.050081, episode:  239\n",
            "frames: 282000, reward: -15.900000, loss: 0.003105, epsilon: 0.050079, episode:  240\n",
            "frames: 283000, reward: -15.900000, loss: 0.004496, epsilon: 0.050076, episode:  240\n",
            "frames: 284000, reward: -14.900000, loss: 0.002030, epsilon: 0.050074, episode:  241\n",
            "frames: 285000, reward: -14.900000, loss: 0.005018, epsilon: 0.050071, episode:  241\n",
            "frames: 286000, reward: -14.700000, loss: 0.002216, epsilon: 0.050069, episode:  242\n",
            "frames: 287000, reward: -14.700000, loss: 0.005351, epsilon: 0.050067, episode:  242\n",
            "frames: 288000, reward: -15.000000, loss: 0.004357, epsilon: 0.050064, episode:  243\n",
            "frames: 289000, reward: -15.000000, loss: 0.004522, epsilon: 0.050062, episode:  243\n",
            "frames: 290000, reward: -14.400000, loss: 0.005221, epsilon: 0.050060, episode:  244\n",
            "frames: 291000, reward: -14.900000, loss: 0.001727, epsilon: 0.050058, episode:  245\n",
            "frames: 292000, reward: -14.900000, loss: 0.002457, epsilon: 0.050056, episode:  245\n",
            "frames: 293000, reward: -14.900000, loss: 0.004249, epsilon: 0.050054, episode:  245\n",
            "frames: 294000, reward: -13.700000, loss: 0.001555, epsilon: 0.050053, episode:  246\n",
            "frames: 295000, reward: -13.700000, loss: 0.003049, epsilon: 0.050051, episode:  246\n",
            "frames: 296000, reward: -14.500000, loss: 0.001848, epsilon: 0.050049, episode:  247\n",
            "frames: 297000, reward: -14.500000, loss: 0.004683, epsilon: 0.050048, episode:  248\n",
            "frames: 298000, reward: -14.500000, loss: 0.002933, epsilon: 0.050046, episode:  248\n",
            "frames: 299000, reward: -14.600000, loss: 0.001781, epsilon: 0.050045, episode:  249\n",
            "frames: 300000, reward: -14.600000, loss: 0.002111, epsilon: 0.050043, episode:  249\n",
            "frames: 301000, reward: -14.300000, loss: 0.000456, epsilon: 0.050042, episode:  250\n",
            "frames: 302000, reward: -14.300000, loss: 0.008216, epsilon: 0.050040, episode:  250\n",
            "frames: 303000, reward: -13.600000, loss: 0.001429, epsilon: 0.050039, episode:  251\n",
            "frames: 304000, reward: -13.600000, loss: 0.002330, epsilon: 0.050038, episode:  251\n",
            "frames: 305000, reward: -13.300000, loss: 0.001081, epsilon: 0.050037, episode:  252\n",
            "frames: 306000, reward: -13.300000, loss: 0.002025, epsilon: 0.050035, episode:  252\n",
            "frames: 307000, reward: -12.900000, loss: 0.000936, epsilon: 0.050034, episode:  253\n",
            "frames: 308000, reward: -12.900000, loss: 0.006158, epsilon: 0.050033, episode:  253\n",
            "frames: 309000, reward: -13.000000, loss: 0.001109, epsilon: 0.050032, episode:  254\n",
            "frames: 310000, reward: -13.000000, loss: 0.002392, epsilon: 0.050031, episode:  254\n",
            "frames: 311000, reward: -13.000000, loss: 0.000817, epsilon: 0.050030, episode:  254\n",
            "frames: 312000, reward: -11.400000, loss: 0.002952, epsilon: 0.050029, episode:  255\n",
            "frames: 313000, reward: -11.400000, loss: 0.002139, epsilon: 0.050028, episode:  255\n",
            "frames: 314000, reward: -11.400000, loss: 0.007781, epsilon: 0.050027, episode:  255\n",
            "frames: 315000, reward: -11.900000, loss: 0.004982, epsilon: 0.050026, episode:  256\n",
            "frames: 316000, reward: -11.900000, loss: 0.003472, epsilon: 0.050025, episode:  256\n",
            "frames: 317000, reward: -11.600000, loss: 0.009265, epsilon: 0.050024, episode:  257\n",
            "frames: 318000, reward: -11.600000, loss: 0.003802, epsilon: 0.050024, episode:  257\n",
            "frames: 319000, reward: -11.300000, loss: 0.002657, epsilon: 0.050023, episode:  258\n",
            "frames: 320000, reward: -11.500000, loss: 0.000942, epsilon: 0.050022, episode:  259\n",
            "frames: 321000, reward: -11.500000, loss: 0.005632, epsilon: 0.050021, episode:  259\n",
            "frames: 322000, reward: -11.500000, loss: 0.001217, epsilon: 0.050021, episode:  259\n",
            "frames: 323000, reward: -11.100000, loss: 0.002826, epsilon: 0.050020, episode:  260\n",
            "frames: 324000, reward: -11.100000, loss: 0.003860, epsilon: 0.050019, episode:  260\n",
            "frames: 325000, reward: -11.300000, loss: 0.011011, epsilon: 0.050019, episode:  261\n",
            "frames: 326000, reward: -11.300000, loss: 0.004801, epsilon: 0.050018, episode:  261\n",
            "frames: 327000, reward: -11.300000, loss: 0.004619, epsilon: 0.050018, episode:  261\n",
            "frames: 328000, reward: -10.600000, loss: 0.002729, epsilon: 0.050017, episode:  262\n",
            "frames: 329000, reward: -10.600000, loss: 0.004214, epsilon: 0.050016, episode:  262\n",
            "frames: 330000, reward: -10.600000, loss: 0.001858, epsilon: 0.050016, episode:  263\n",
            "frames: 331000, reward: -10.600000, loss: 0.002989, epsilon: 0.050015, episode:  263\n",
            "frames: 332000, reward: -10.600000, loss: 0.002800, epsilon: 0.050015, episode:  263\n",
            "frames: 333000, reward: -10.500000, loss: 0.012800, epsilon: 0.050014, episode:  264\n",
            "frames: 334000, reward: -11.700000, loss: 0.005169, epsilon: 0.050014, episode:  265\n",
            "frames: 335000, reward: -11.700000, loss: 0.001553, epsilon: 0.050013, episode:  265\n",
            "frames: 336000, reward: -11.700000, loss: 0.003797, epsilon: 0.050013, episode:  265\n",
            "frames: 337000, reward: -11.700000, loss: 0.001114, epsilon: 0.050013, episode:  266\n",
            "frames: 338000, reward: -12.100000, loss: 0.002351, epsilon: 0.050012, episode:  267\n",
            "frames: 339000, reward: -12.100000, loss: 0.001983, epsilon: 0.050012, episode:  267\n",
            "frames: 340000, reward: -12.100000, loss: 0.001762, epsilon: 0.050011, episode:  267\n",
            "frames: 341000, reward: -11.300000, loss: 0.006054, epsilon: 0.050011, episode:  268\n",
            "frames: 342000, reward: -11.300000, loss: 0.006325, epsilon: 0.050011, episode:  268\n",
            "frames: 343000, reward: -11.300000, loss: 0.002173, epsilon: 0.050010, episode:  269\n",
            "frames: 344000, reward: -11.300000, loss: 0.002883, epsilon: 0.050010, episode:  269\n",
            "frames: 345000, reward: -11.600000, loss: 0.007747, epsilon: 0.050010, episode:  270\n",
            "frames: 346000, reward: -11.600000, loss: 0.005018, epsilon: 0.050009, episode:  270\n",
            "frames: 347000, reward: -11.600000, loss: 0.003259, epsilon: 0.050009, episode:  270\n",
            "frames: 348000, reward: -11.800000, loss: 0.015658, epsilon: 0.050009, episode:  271\n",
            "frames: 349000, reward: -11.800000, loss: 0.003497, epsilon: 0.050008, episode:  271\n",
            "frames: 350000, reward: -12.400000, loss: 0.002423, epsilon: 0.050008, episode:  272\n",
            "frames: 351000, reward: -12.400000, loss: 0.002576, epsilon: 0.050008, episode:  272\n",
            "frames: 352000, reward: -12.500000, loss: 0.000563, epsilon: 0.050008, episode:  273\n",
            "frames: 353000, reward: -13.600000, loss: 0.004180, epsilon: 0.050007, episode:  274\n",
            "frames: 354000, reward: -13.600000, loss: 0.006639, epsilon: 0.050007, episode:  274\n",
            "frames: 355000, reward: -13.400000, loss: 0.001873, epsilon: 0.050007, episode:  275\n",
            "frames: 356000, reward: -13.400000, loss: 0.003891, epsilon: 0.050007, episode:  275\n",
            "frames: 357000, reward: -13.400000, loss: 0.003081, epsilon: 0.050006, episode:  275\n",
            "frames: 358000, reward: -13.000000, loss: 0.003170, epsilon: 0.050006, episode:  276\n",
            "frames: 359000, reward: -13.000000, loss: 0.004352, epsilon: 0.050006, episode:  276\n",
            "frames: 360000, reward: -13.000000, loss: 0.002023, epsilon: 0.050006, episode:  276\n",
            "frames: 361000, reward: -11.500000, loss: 0.002233, epsilon: 0.050006, episode:  277\n",
            "frames: 362000, reward: -11.500000, loss: 0.003047, epsilon: 0.050005, episode:  277\n",
            "frames: 363000, reward: -11.500000, loss: 0.003140, epsilon: 0.050005, episode:  277\n",
            "frames: 364000, reward: -11.900000, loss: 0.003565, epsilon: 0.050005, episode:  278\n",
            "frames: 365000, reward: -11.900000, loss: 0.002185, epsilon: 0.050005, episode:  278\n",
            "frames: 366000, reward: -11.300000, loss: 0.001487, epsilon: 0.050005, episode:  279\n",
            "frames: 367000, reward: -11.300000, loss: 0.001337, epsilon: 0.050005, episode:  279\n",
            "frames: 368000, reward: -11.300000, loss: 0.001218, epsilon: 0.050004, episode:  279\n",
            "frames: 369000, reward: -10.600000, loss: 0.004056, epsilon: 0.050004, episode:  280\n",
            "frames: 370000, reward: -10.600000, loss: 0.002504, epsilon: 0.050004, episode:  280\n",
            "frames: 371000, reward: -11.100000, loss: 0.002416, epsilon: 0.050004, episode:  281\n",
            "frames: 372000, reward: -11.100000, loss: 0.001868, epsilon: 0.050004, episode:  281\n",
            "frames: 373000, reward: -11.100000, loss: 0.002305, epsilon: 0.050004, episode:  281\n",
            "frames: 374000, reward: -11.200000, loss: 0.005092, epsilon: 0.050004, episode:  282\n",
            "frames: 375000, reward: -11.200000, loss: 0.002356, epsilon: 0.050004, episode:  282\n",
            "frames: 376000, reward: -10.700000, loss: 0.001878, epsilon: 0.050003, episode:  283\n",
            "frames: 377000, reward: -10.700000, loss: 0.001680, epsilon: 0.050003, episode:  283\n",
            "frames: 378000, reward: -10.700000, loss: 0.004650, epsilon: 0.050003, episode:  283\n",
            "frames: 379000, reward: -9.600000, loss: 0.001423, epsilon: 0.050003, episode:  284\n",
            "frames: 380000, reward: -9.600000, loss: 0.001430, epsilon: 0.050003, episode:  284\n",
            "frames: 381000, reward: -9.600000, loss: 0.002218, epsilon: 0.050003, episode:  284\n",
            "frames: 382000, reward: -8.000000, loss: 0.031146, epsilon: 0.050003, episode:  285\n",
            "frames: 383000, reward: -8.000000, loss: 0.003323, epsilon: 0.050003, episode:  285\n",
            "frames: 384000, reward: -8.000000, loss: 0.007375, epsilon: 0.050003, episode:  285\n",
            "frames: 385000, reward: -8.500000, loss: 0.004558, epsilon: 0.050003, episode:  286\n",
            "frames: 386000, reward: -8.500000, loss: 0.007782, epsilon: 0.050002, episode:  286\n",
            "frames: 387000, reward: -8.500000, loss: 0.001061, epsilon: 0.050002, episode:  286\n",
            "frames: 388000, reward: -8.700000, loss: 0.002046, epsilon: 0.050002, episode:  287\n",
            "frames: 389000, reward: -8.700000, loss: 0.001602, epsilon: 0.050002, episode:  287\n",
            "frames: 390000, reward: -8.700000, loss: 0.009982, epsilon: 0.050002, episode:  287\n",
            "frames: 391000, reward: -8.700000, loss: 0.004583, epsilon: 0.050002, episode:  287\n",
            "frames: 392000, reward: -7.700000, loss: 0.004392, epsilon: 0.050002, episode:  288\n",
            "frames: 393000, reward: -7.700000, loss: 0.002278, epsilon: 0.050002, episode:  288\n",
            "frames: 394000, reward: -7.900000, loss: 0.007233, epsilon: 0.050002, episode:  289\n",
            "frames: 395000, reward: -7.900000, loss: 0.001326, epsilon: 0.050002, episode:  289\n",
            "frames: 396000, reward: -7.900000, loss: 0.002424, epsilon: 0.050002, episode:  289\n",
            "frames: 397000, reward: -8.100000, loss: 0.004131, epsilon: 0.050002, episode:  290\n",
            "frames: 398000, reward: -8.100000, loss: 0.002669, epsilon: 0.050002, episode:  290\n",
            "frames: 399000, reward: -8.100000, loss: 0.008596, epsilon: 0.050002, episode:  290\n",
            "frames: 400000, reward: -7.000000, loss: 0.001900, epsilon: 0.050002, episode:  291\n",
            "frames: 401000, reward: -7.000000, loss: 0.012153, epsilon: 0.050001, episode:  291\n",
            "frames: 402000, reward: -7.000000, loss: 0.002524, epsilon: 0.050001, episode:  291\n",
            "frames: 403000, reward: -7.000000, loss: 0.001099, epsilon: 0.050001, episode:  291\n",
            "frames: 404000, reward: -6.200000, loss: 0.004212, epsilon: 0.050001, episode:  292\n",
            "frames: 405000, reward: -6.200000, loss: 0.002604, epsilon: 0.050001, episode:  292\n",
            "frames: 406000, reward: -6.200000, loss: 0.001524, epsilon: 0.050001, episode:  292\n",
            "frames: 407000, reward: -6.200000, loss: 0.001481, epsilon: 0.050001, episode:  292\n",
            "frames: 408000, reward: -4.500000, loss: 0.003096, epsilon: 0.050001, episode:  293\n",
            "frames: 409000, reward: -4.500000, loss: 0.001324, epsilon: 0.050001, episode:  293\n",
            "frames: 410000, reward: -4.500000, loss: 0.002110, epsilon: 0.050001, episode:  293\n",
            "frames: 411000, reward: -4.300000, loss: 0.004044, epsilon: 0.050001, episode:  294\n",
            "frames: 412000, reward: -4.300000, loss: 0.009674, epsilon: 0.050001, episode:  294\n",
            "frames: 413000, reward: -4.300000, loss: 0.005348, epsilon: 0.050001, episode:  294\n",
            "frames: 414000, reward: -5.200000, loss: 0.002716, epsilon: 0.050001, episode:  295\n",
            "frames: 415000, reward: -5.200000, loss: 0.003536, epsilon: 0.050001, episode:  295\n",
            "frames: 416000, reward: -5.200000, loss: 0.001721, epsilon: 0.050001, episode:  295\n",
            "frames: 417000, reward: -5.200000, loss: 0.001808, epsilon: 0.050001, episode:  295\n",
            "frames: 418000, reward: -5.100000, loss: 0.002636, epsilon: 0.050001, episode:  296\n",
            "frames: 419000, reward: -5.100000, loss: 0.003073, epsilon: 0.050001, episode:  296\n",
            "frames: 420000, reward: -5.100000, loss: 0.001361, epsilon: 0.050001, episode:  296\n",
            "frames: 421000, reward: -5.200000, loss: 0.001328, epsilon: 0.050001, episode:  297\n",
            "frames: 422000, reward: -5.200000, loss: 0.002078, epsilon: 0.050001, episode:  297\n",
            "frames: 423000, reward: -5.200000, loss: 0.002026, epsilon: 0.050001, episode:  297\n",
            "frames: 424000, reward: -5.200000, loss: 0.003167, epsilon: 0.050001, episode:  297\n",
            "frames: 425000, reward: -5.500000, loss: 0.000796, epsilon: 0.050001, episode:  298\n",
            "frames: 426000, reward: -5.500000, loss: 0.003050, epsilon: 0.050001, episode:  298\n",
            "frames: 427000, reward: -5.500000, loss: 0.001692, epsilon: 0.050001, episode:  298\n",
            "frames: 428000, reward: -5.500000, loss: 0.003726, epsilon: 0.050001, episode:  298\n",
            "frames: 429000, reward: -4.700000, loss: 0.002209, epsilon: 0.050001, episode:  299\n",
            "frames: 430000, reward: -4.700000, loss: 0.009893, epsilon: 0.050001, episode:  299\n",
            "frames: 431000, reward: -4.700000, loss: 0.003216, epsilon: 0.050001, episode:  299\n",
            "frames: 432000, reward: -4.700000, loss: 0.001018, epsilon: 0.050001, episode:  299\n",
            "frames: 433000, reward: -4.200000, loss: 0.003636, epsilon: 0.050001, episode:  300\n",
            "frames: 434000, reward: -4.200000, loss: 0.005219, epsilon: 0.050000, episode:  300\n",
            "frames: 435000, reward: -4.200000, loss: 0.001810, epsilon: 0.050000, episode:  300\n",
            "frames: 436000, reward: -4.800000, loss: 0.002731, epsilon: 0.050000, episode:  301\n",
            "frames: 437000, reward: -4.800000, loss: 0.001600, epsilon: 0.050000, episode:  301\n",
            "frames: 438000, reward: -4.800000, loss: 0.004861, epsilon: 0.050000, episode:  301\n",
            "frames: 439000, reward: -4.800000, loss: 0.002130, epsilon: 0.050000, episode:  301\n",
            "frames: 440000, reward: -4.900000, loss: 0.006215, epsilon: 0.050000, episode:  302\n",
            "frames: 441000, reward: -4.900000, loss: 0.001144, epsilon: 0.050000, episode:  302\n",
            "frames: 442000, reward: -4.900000, loss: 0.002810, epsilon: 0.050000, episode:  302\n",
            "frames: 443000, reward: -4.900000, loss: 0.001704, epsilon: 0.050000, episode:  302\n",
            "frames: 444000, reward: -5.600000, loss: 0.004455, epsilon: 0.050000, episode:  303\n",
            "frames: 445000, reward: -5.600000, loss: 0.001859, epsilon: 0.050000, episode:  303\n",
            "frames: 446000, reward: -5.600000, loss: 0.005416, epsilon: 0.050000, episode:  303\n",
            "frames: 447000, reward: -5.700000, loss: 0.001336, epsilon: 0.050000, episode:  304\n",
            "frames: 448000, reward: -5.700000, loss: 0.003225, epsilon: 0.050000, episode:  304\n",
            "frames: 449000, reward: -5.700000, loss: 0.001773, epsilon: 0.050000, episode:  304\n",
            "frames: 450000, reward: -5.700000, loss: 0.001941, epsilon: 0.050000, episode:  304\n",
            "frames: 451000, reward: -5.700000, loss: 0.003519, epsilon: 0.050000, episode:  304\n",
            "frames: 452000, reward: -4.700000, loss: 0.001410, epsilon: 0.050000, episode:  305\n",
            "frames: 453000, reward: -4.700000, loss: 0.001906, epsilon: 0.050000, episode:  305\n",
            "frames: 454000, reward: -4.700000, loss: 0.004623, epsilon: 0.050000, episode:  305\n",
            "frames: 455000, reward: -4.700000, loss: 0.001475, epsilon: 0.050000, episode:  305\n",
            "frames: 456000, reward: -3.600000, loss: 0.001564, epsilon: 0.050000, episode:  306\n",
            "frames: 457000, reward: -3.600000, loss: 0.002048, epsilon: 0.050000, episode:  306\n",
            "frames: 458000, reward: -3.600000, loss: 0.001094, epsilon: 0.050000, episode:  306\n",
            "frames: 459000, reward: -3.700000, loss: 0.001925, epsilon: 0.050000, episode:  307\n",
            "frames: 460000, reward: -3.700000, loss: 0.002182, epsilon: 0.050000, episode:  307\n",
            "frames: 461000, reward: -3.700000, loss: 0.001196, epsilon: 0.050000, episode:  307\n",
            "frames: 462000, reward: -3.700000, loss: 0.001709, epsilon: 0.050000, episode:  307\n",
            "frames: 463000, reward: -2.900000, loss: 0.003519, epsilon: 0.050000, episode:  308\n",
            "frames: 464000, reward: -2.900000, loss: 0.001703, epsilon: 0.050000, episode:  308\n",
            "frames: 465000, reward: -2.900000, loss: 0.001845, epsilon: 0.050000, episode:  308\n",
            "frames: 466000, reward: -3.200000, loss: 0.003297, epsilon: 0.050000, episode:  309\n",
            "frames: 467000, reward: -3.200000, loss: 0.001060, epsilon: 0.050000, episode:  309\n",
            "frames: 468000, reward: -3.200000, loss: 0.001592, epsilon: 0.050000, episode:  309\n",
            "frames: 469000, reward: -3.200000, loss: 0.002578, epsilon: 0.050000, episode:  309\n",
            "frames: 470000, reward: -3.300000, loss: 0.001508, epsilon: 0.050000, episode:  310\n",
            "frames: 471000, reward: -3.300000, loss: 0.001653, epsilon: 0.050000, episode:  310\n",
            "frames: 472000, reward: -3.600000, loss: 0.040271, epsilon: 0.050000, episode:  311\n",
            "frames: 473000, reward: -3.600000, loss: 0.012982, epsilon: 0.050000, episode:  311\n",
            "frames: 474000, reward: -3.600000, loss: 0.002659, epsilon: 0.050000, episode:  311\n",
            "frames: 475000, reward: -3.600000, loss: 0.005199, epsilon: 0.050000, episode:  311\n",
            "frames: 476000, reward: -3.600000, loss: 0.001371, epsilon: 0.050000, episode:  311\n",
            "frames: 477000, reward: -3.300000, loss: 0.001026, epsilon: 0.050000, episode:  312\n",
            "frames: 478000, reward: -3.300000, loss: 0.001825, epsilon: 0.050000, episode:  312\n",
            "frames: 479000, reward: -3.300000, loss: 0.001465, epsilon: 0.050000, episode:  312\n",
            "frames: 480000, reward: -3.300000, loss: 0.002442, epsilon: 0.050000, episode:  312\n",
            "frames: 481000, reward: -3.300000, loss: 0.002625, epsilon: 0.050000, episode:  313\n",
            "frames: 482000, reward: -3.300000, loss: 0.001419, epsilon: 0.050000, episode:  313\n",
            "frames: 483000, reward: -3.300000, loss: 0.004363, epsilon: 0.050000, episode:  313\n",
            "frames: 484000, reward: -3.300000, loss: 0.002992, epsilon: 0.050000, episode:  313\n",
            "frames: 485000, reward: -3.100000, loss: 0.001057, epsilon: 0.050000, episode:  314\n",
            "frames: 486000, reward: -3.100000, loss: 0.002743, epsilon: 0.050000, episode:  314\n",
            "frames: 487000, reward: -3.100000, loss: 0.004206, epsilon: 0.050000, episode:  314\n",
            "frames: 488000, reward: -3.100000, loss: 0.001705, epsilon: 0.050000, episode:  314\n",
            "frames: 489000, reward: -3.200000, loss: 0.011667, epsilon: 0.050000, episode:  315\n",
            "frames: 490000, reward: -3.200000, loss: 0.002817, epsilon: 0.050000, episode:  315\n",
            "frames: 491000, reward: -3.200000, loss: 0.000753, epsilon: 0.050000, episode:  315\n",
            "frames: 492000, reward: -3.800000, loss: 0.003482, epsilon: 0.050000, episode:  316\n",
            "frames: 493000, reward: -3.800000, loss: 0.002850, epsilon: 0.050000, episode:  316\n",
            "frames: 494000, reward: -3.800000, loss: 0.000844, epsilon: 0.050000, episode:  316\n",
            "frames: 495000, reward: -3.800000, loss: 0.002304, epsilon: 0.050000, episode:  316\n",
            "frames: 496000, reward: -3.800000, loss: 0.002161, epsilon: 0.050000, episode:  316\n",
            "frames: 497000, reward: -3.200000, loss: 0.001723, epsilon: 0.050000, episode:  317\n",
            "frames: 498000, reward: -3.200000, loss: 0.001560, epsilon: 0.050000, episode:  317\n",
            "frames: 499000, reward: -3.200000, loss: 0.005152, epsilon: 0.050000, episode:  317\n",
            "frames: 500000, reward: -3.700000, loss: 0.006223, epsilon: 0.050000, episode:  318\n",
            "frames: 501000, reward: -3.700000, loss: 0.002652, epsilon: 0.050000, episode:  318\n",
            "frames: 502000, reward: -3.700000, loss: 0.002120, epsilon: 0.050000, episode:  318\n",
            "frames: 503000, reward: -3.700000, loss: 0.001642, epsilon: 0.050000, episode:  318\n",
            "frames: 504000, reward: -3.700000, loss: 0.002567, epsilon: 0.050000, episode:  318\n",
            "frames: 505000, reward: -3.200000, loss: 0.004404, epsilon: 0.050000, episode:  319\n",
            "frames: 506000, reward: -3.200000, loss: 0.000766, epsilon: 0.050000, episode:  319\n",
            "frames: 507000, reward: -3.200000, loss: 0.001738, epsilon: 0.050000, episode:  319\n",
            "frames: 508000, reward: -3.200000, loss: 0.001849, epsilon: 0.050000, episode:  319\n",
            "frames: 509000, reward: -3.200000, loss: 0.001243, epsilon: 0.050000, episode:  319\n",
            "frames: 510000, reward: -3.000000, loss: 0.001636, epsilon: 0.050000, episode:  320\n",
            "frames: 511000, reward: -3.000000, loss: 0.001807, epsilon: 0.050000, episode:  320\n",
            "frames: 512000, reward: -3.000000, loss: 0.005674, epsilon: 0.050000, episode:  320\n",
            "frames: 513000, reward: -3.000000, loss: 0.006059, epsilon: 0.050000, episode:  320\n",
            "frames: 514000, reward: -2.300000, loss: 0.003371, epsilon: 0.050000, episode:  321\n",
            "frames: 515000, reward: -2.300000, loss: 0.002460, epsilon: 0.050000, episode:  321\n",
            "frames: 516000, reward: -2.300000, loss: 0.001512, epsilon: 0.050000, episode:  321\n",
            "frames: 517000, reward: -2.300000, loss: 0.008416, epsilon: 0.050000, episode:  321\n",
            "frames: 518000, reward: -1.400000, loss: 0.004244, epsilon: 0.050000, episode:  322\n",
            "frames: 519000, reward: -1.400000, loss: 0.001432, epsilon: 0.050000, episode:  322\n",
            "frames: 520000, reward: -1.400000, loss: 0.000907, epsilon: 0.050000, episode:  322\n",
            "frames: 521000, reward: -1.400000, loss: 0.000478, epsilon: 0.050000, episode:  322\n",
            "frames: 522000, reward: -1.300000, loss: 0.001336, epsilon: 0.050000, episode:  323\n",
            "frames: 523000, reward: -1.300000, loss: 0.000774, epsilon: 0.050000, episode:  323\n",
            "frames: 524000, reward: -1.300000, loss: 0.003857, epsilon: 0.050000, episode:  323\n",
            "frames: 525000, reward: -1.300000, loss: 0.002316, epsilon: 0.050000, episode:  323\n",
            "frames: 526000, reward: -1.300000, loss: 0.005659, epsilon: 0.050000, episode:  324\n",
            "frames: 527000, reward: -1.300000, loss: 0.003474, epsilon: 0.050000, episode:  324\n",
            "frames: 528000, reward: -1.300000, loss: 0.001703, epsilon: 0.050000, episode:  324\n",
            "frames: 529000, reward: -1.300000, loss: 0.001053, epsilon: 0.050000, episode:  324\n",
            "frames: 530000, reward: -1.000000, loss: 0.001710, epsilon: 0.050000, episode:  325\n",
            "frames: 531000, reward: -1.000000, loss: 0.002553, epsilon: 0.050000, episode:  325\n",
            "frames: 532000, reward: -1.000000, loss: 0.003432, epsilon: 0.050000, episode:  325\n",
            "frames: 533000, reward: -1.000000, loss: 0.004782, epsilon: 0.050000, episode:  325\n",
            "frames: 534000, reward: -1.000000, loss: 0.001104, epsilon: 0.050000, episode:  325\n",
            "frames: 535000, reward: -1.100000, loss: 0.002995, epsilon: 0.050000, episode:  326\n",
            "frames: 536000, reward: -1.100000, loss: 0.001271, epsilon: 0.050000, episode:  326\n",
            "frames: 537000, reward: -1.100000, loss: 0.002548, epsilon: 0.050000, episode:  326\n",
            "frames: 538000, reward: -0.400000, loss: 0.004680, epsilon: 0.050000, episode:  327\n",
            "frames: 539000, reward: -0.400000, loss: 0.000641, epsilon: 0.050000, episode:  327\n",
            "frames: 540000, reward: -0.400000, loss: 0.001671, epsilon: 0.050000, episode:  327\n",
            "frames: 541000, reward: -0.400000, loss: 0.002891, epsilon: 0.050000, episode:  327\n",
            "frames: 542000, reward: -0.400000, loss: 0.002405, epsilon: 0.050000, episode:  328\n",
            "frames: 543000, reward: -0.400000, loss: 0.001451, epsilon: 0.050000, episode:  328\n",
            "frames: 544000, reward: -0.400000, loss: 0.005428, epsilon: 0.050000, episode:  328\n",
            "frames: 545000, reward: -0.400000, loss: 0.005250, epsilon: 0.050000, episode:  328\n",
            "frames: 546000, reward: 0.200000, loss: 0.002798, epsilon: 0.050000, episode:  329\n",
            "frames: 547000, reward: 0.200000, loss: 0.002255, epsilon: 0.050000, episode:  329\n",
            "frames: 548000, reward: 0.200000, loss: 0.001043, epsilon: 0.050000, episode:  329\n",
            "frames: 549000, reward: 0.200000, loss: 0.001603, epsilon: 0.050000, episode:  329\n",
            "frames: 550000, reward: 0.900000, loss: 0.001594, epsilon: 0.050000, episode:  330\n",
            "frames: 551000, reward: 0.900000, loss: 0.001830, epsilon: 0.050000, episode:  330\n",
            "frames: 552000, reward: 0.900000, loss: 0.005386, epsilon: 0.050000, episode:  330\n",
            "frames: 553000, reward: 0.900000, loss: 0.001768, epsilon: 0.050000, episode:  330\n",
            "frames: 554000, reward: 0.900000, loss: 0.010592, epsilon: 0.050000, episode:  331\n",
            "frames: 555000, reward: 0.900000, loss: 0.000835, epsilon: 0.050000, episode:  331\n",
            "frames: 556000, reward: 0.900000, loss: 0.003497, epsilon: 0.050000, episode:  331\n",
            "frames: 557000, reward: 0.900000, loss: 0.000809, epsilon: 0.050000, episode:  331\n",
            "frames: 558000, reward: 0.600000, loss: 0.001820, epsilon: 0.050000, episode:  332\n",
            "frames: 559000, reward: 0.600000, loss: 0.001523, epsilon: 0.050000, episode:  332\n",
            "frames: 560000, reward: 0.600000, loss: 0.013887, epsilon: 0.050000, episode:  332\n",
            "frames: 561000, reward: 0.100000, loss: 0.002530, epsilon: 0.050000, episode:  333\n",
            "frames: 562000, reward: 0.100000, loss: 0.003259, epsilon: 0.050000, episode:  333\n",
            "frames: 563000, reward: 0.100000, loss: 0.000922, epsilon: 0.050000, episode:  333\n",
            "frames: 564000, reward: 0.100000, loss: 0.001919, epsilon: 0.050000, episode:  333\n",
            "frames: 565000, reward: 0.900000, loss: 0.000645, epsilon: 0.050000, episode:  334\n",
            "frames: 566000, reward: 0.900000, loss: 0.000859, epsilon: 0.050000, episode:  334\n",
            "frames: 567000, reward: 0.900000, loss: 0.001503, epsilon: 0.050000, episode:  334\n",
            "frames: 568000, reward: 0.900000, loss: 0.001441, epsilon: 0.050000, episode:  335\n",
            "frames: 569000, reward: 0.900000, loss: 0.000890, epsilon: 0.050000, episode:  335\n",
            "frames: 570000, reward: 0.900000, loss: 0.005144, epsilon: 0.050000, episode:  335\n",
            "frames: 571000, reward: 0.900000, loss: 0.000917, epsilon: 0.050000, episode:  335\n",
            "frames: 572000, reward: 1.700000, loss: 0.002105, epsilon: 0.050000, episode:  336\n",
            "frames: 573000, reward: 1.700000, loss: 0.001771, epsilon: 0.050000, episode:  336\n",
            "frames: 574000, reward: 1.700000, loss: 0.006683, epsilon: 0.050000, episode:  336\n",
            "frames: 575000, reward: 1.700000, loss: 0.001200, epsilon: 0.050000, episode:  336\n",
            "frames: 576000, reward: 1.500000, loss: 0.002487, epsilon: 0.050000, episode:  337\n",
            "frames: 577000, reward: 1.500000, loss: 0.001733, epsilon: 0.050000, episode:  337\n",
            "frames: 578000, reward: 1.500000, loss: 0.001443, epsilon: 0.050000, episode:  337\n",
            "frames: 579000, reward: 1.600000, loss: 0.001086, epsilon: 0.050000, episode:  338\n",
            "frames: 580000, reward: 1.600000, loss: 0.002783, epsilon: 0.050000, episode:  338\n",
            "frames: 581000, reward: 1.600000, loss: 0.002387, epsilon: 0.050000, episode:  338\n",
            "frames: 582000, reward: 1.600000, loss: 0.003971, epsilon: 0.050000, episode:  338\n",
            "frames: 583000, reward: 1.300000, loss: 0.001123, epsilon: 0.050000, episode:  339\n",
            "frames: 584000, reward: 1.300000, loss: 0.001885, epsilon: 0.050000, episode:  339\n",
            "frames: 585000, reward: 1.300000, loss: 0.000992, epsilon: 0.050000, episode:  339\n",
            "frames: 586000, reward: 1.600000, loss: 0.002339, epsilon: 0.050000, episode:  340\n",
            "frames: 587000, reward: 1.600000, loss: 0.001909, epsilon: 0.050000, episode:  340\n",
            "frames: 588000, reward: 1.600000, loss: 0.001746, epsilon: 0.050000, episode:  340\n",
            "frames: 589000, reward: 2.400000, loss: 0.001302, epsilon: 0.050000, episode:  341\n",
            "frames: 590000, reward: 2.400000, loss: 0.009645, epsilon: 0.050000, episode:  341\n",
            "frames: 591000, reward: 2.400000, loss: 0.003484, epsilon: 0.050000, episode:  341\n",
            "frames: 592000, reward: 2.400000, loss: 0.005791, epsilon: 0.050000, episode:  341\n",
            "frames: 593000, reward: 2.900000, loss: 0.001280, epsilon: 0.050000, episode:  342\n",
            "frames: 594000, reward: 2.900000, loss: 0.003509, epsilon: 0.050000, episode:  342\n",
            "frames: 595000, reward: 2.900000, loss: 0.005044, epsilon: 0.050000, episode:  342\n",
            "frames: 596000, reward: 2.900000, loss: 0.004270, epsilon: 0.050000, episode:  342\n",
            "frames: 597000, reward: 2.900000, loss: 0.001655, epsilon: 0.050000, episode:  342\n",
            "frames: 598000, reward: 3.400000, loss: 0.003876, epsilon: 0.050000, episode:  343\n",
            "frames: 599000, reward: 3.400000, loss: 0.001446, epsilon: 0.050000, episode:  343\n",
            "frames: 600000, reward: 3.400000, loss: 0.001072, epsilon: 0.050000, episode:  343\n",
            "frames: 601000, reward: 3.400000, loss: 0.001145, epsilon: 0.050000, episode:  343\n",
            "frames: 602000, reward: 3.400000, loss: 0.001261, epsilon: 0.050000, episode:  343\n",
            "frames: 603000, reward: 2.700000, loss: 0.002277, epsilon: 0.050000, episode:  344\n",
            "frames: 604000, reward: 2.700000, loss: 0.001256, epsilon: 0.050000, episode:  344\n",
            "frames: 605000, reward: 2.700000, loss: 0.001026, epsilon: 0.050000, episode:  344\n",
            "frames: 606000, reward: 2.700000, loss: 0.001880, epsilon: 0.050000, episode:  345\n",
            "frames: 607000, reward: 2.700000, loss: 0.001901, epsilon: 0.050000, episode:  345\n",
            "frames: 608000, reward: 2.700000, loss: 0.000976, epsilon: 0.050000, episode:  345\n",
            "frames: 609000, reward: 2.700000, loss: 0.002936, epsilon: 0.050000, episode:  345\n",
            "frames: 610000, reward: 3.000000, loss: 0.008102, epsilon: 0.050000, episode:  346\n",
            "frames: 611000, reward: 3.000000, loss: 0.000525, epsilon: 0.050000, episode:  346\n",
            "frames: 612000, reward: 3.000000, loss: 0.000968, epsilon: 0.050000, episode:  346\n",
            "frames: 613000, reward: 3.000000, loss: 0.001724, epsilon: 0.050000, episode:  346\n",
            "frames: 614000, reward: 2.900000, loss: 0.004130, epsilon: 0.050000, episode:  347\n",
            "frames: 615000, reward: 2.900000, loss: 0.002968, epsilon: 0.050000, episode:  347\n",
            "frames: 616000, reward: 2.900000, loss: 0.003382, epsilon: 0.050000, episode:  347\n",
            "frames: 617000, reward: 2.900000, loss: 0.002086, epsilon: 0.050000, episode:  347\n",
            "frames: 618000, reward: 3.300000, loss: 0.004542, epsilon: 0.050000, episode:  348\n",
            "frames: 619000, reward: 3.300000, loss: 0.000741, epsilon: 0.050000, episode:  348\n",
            "frames: 620000, reward: 3.300000, loss: 0.001341, epsilon: 0.050000, episode:  348\n",
            "frames: 621000, reward: 3.800000, loss: 0.001630, epsilon: 0.050000, episode:  349\n",
            "frames: 622000, reward: 3.800000, loss: 0.007170, epsilon: 0.050000, episode:  349\n",
            "frames: 623000, reward: 3.800000, loss: 0.001651, epsilon: 0.050000, episode:  349\n",
            "frames: 624000, reward: 3.500000, loss: 0.002002, epsilon: 0.050000, episode:  350\n",
            "frames: 625000, reward: 3.500000, loss: 0.003854, epsilon: 0.050000, episode:  350\n",
            "frames: 626000, reward: 3.500000, loss: 0.005442, epsilon: 0.050000, episode:  350\n",
            "frames: 627000, reward: 3.500000, loss: 0.003852, epsilon: 0.050000, episode:  350\n",
            "frames: 628000, reward: 3.200000, loss: 0.000796, epsilon: 0.050000, episode:  351\n",
            "frames: 629000, reward: 3.200000, loss: 0.002615, epsilon: 0.050000, episode:  351\n",
            "frames: 630000, reward: 3.200000, loss: 0.001800, epsilon: 0.050000, episode:  351\n",
            "frames: 631000, reward: 2.800000, loss: 0.001095, epsilon: 0.050000, episode:  352\n",
            "frames: 632000, reward: 2.800000, loss: 0.003038, epsilon: 0.050000, episode:  352\n",
            "frames: 633000, reward: 2.800000, loss: 0.001980, epsilon: 0.050000, episode:  352\n",
            "frames: 634000, reward: 3.800000, loss: 0.006745, epsilon: 0.050000, episode:  353\n",
            "frames: 635000, reward: 3.800000, loss: 0.002814, epsilon: 0.050000, episode:  353\n",
            "frames: 636000, reward: 3.800000, loss: 0.000782, epsilon: 0.050000, episode:  353\n",
            "frames: 637000, reward: 3.800000, loss: 0.001813, epsilon: 0.050000, episode:  353\n",
            "frames: 638000, reward: 4.400000, loss: 0.002390, epsilon: 0.050000, episode:  354\n",
            "frames: 639000, reward: 4.400000, loss: 0.000937, epsilon: 0.050000, episode:  354\n",
            "frames: 640000, reward: 4.400000, loss: 0.001771, epsilon: 0.050000, episode:  354\n",
            "frames: 641000, reward: 4.300000, loss: 0.001528, epsilon: 0.050000, episode:  355\n",
            "frames: 642000, reward: 4.300000, loss: 0.001292, epsilon: 0.050000, episode:  355\n",
            "frames: 643000, reward: 4.300000, loss: 0.006582, epsilon: 0.050000, episode:  355\n",
            "frames: 644000, reward: 4.300000, loss: 0.000728, epsilon: 0.050000, episode:  355\n",
            "frames: 645000, reward: 4.200000, loss: 0.005795, epsilon: 0.050000, episode:  356\n",
            "frames: 646000, reward: 4.200000, loss: 0.001220, epsilon: 0.050000, episode:  356\n",
            "frames: 647000, reward: 4.200000, loss: 0.004073, epsilon: 0.050000, episode:  356\n",
            "frames: 648000, reward: 4.200000, loss: 0.003186, epsilon: 0.050000, episode:  357\n",
            "frames: 649000, reward: 4.200000, loss: 0.001785, epsilon: 0.050000, episode:  357\n",
            "frames: 650000, reward: 4.200000, loss: 0.003289, epsilon: 0.050000, episode:  357\n",
            "frames: 651000, reward: 4.800000, loss: 0.001239, epsilon: 0.050000, episode:  358\n",
            "frames: 652000, reward: 4.800000, loss: 0.000480, epsilon: 0.050000, episode:  358\n",
            "frames: 653000, reward: 4.800000, loss: 0.018809, epsilon: 0.050000, episode:  358\n",
            "frames: 654000, reward: 4.700000, loss: 0.002716, epsilon: 0.050000, episode:  359\n",
            "frames: 655000, reward: 4.700000, loss: 0.000836, epsilon: 0.050000, episode:  359\n",
            "frames: 656000, reward: 4.700000, loss: 0.002259, epsilon: 0.050000, episode:  359\n",
            "frames: 657000, reward: 5.100000, loss: 0.001817, epsilon: 0.050000, episode:  360\n",
            "frames: 658000, reward: 5.100000, loss: 0.002839, epsilon: 0.050000, episode:  360\n",
            "frames: 659000, reward: 5.100000, loss: 0.001467, epsilon: 0.050000, episode:  360\n",
            "frames: 660000, reward: 5.900000, loss: 0.001423, epsilon: 0.050000, episode:  361\n",
            "frames: 661000, reward: 5.900000, loss: 0.001082, epsilon: 0.050000, episode:  361\n",
            "frames: 662000, reward: 5.900000, loss: 0.000892, epsilon: 0.050000, episode:  361\n",
            "frames: 663000, reward: 5.900000, loss: 0.003511, epsilon: 0.050000, episode:  361\n",
            "frames: 664000, reward: 5.400000, loss: 0.001540, epsilon: 0.050000, episode:  362\n",
            "frames: 665000, reward: 5.400000, loss: 0.003679, epsilon: 0.050000, episode:  362\n",
            "frames: 666000, reward: 5.400000, loss: 0.005886, epsilon: 0.050000, episode:  362\n",
            "frames: 667000, reward: 5.400000, loss: 0.000661, epsilon: 0.050000, episode:  362\n",
            "frames: 668000, reward: 5.100000, loss: 0.001462, epsilon: 0.050000, episode:  363\n",
            "frames: 669000, reward: 5.100000, loss: 0.001234, epsilon: 0.050000, episode:  363\n",
            "frames: 670000, reward: 5.100000, loss: 0.001463, epsilon: 0.050000, episode:  363\n",
            "frames: 671000, reward: 5.700000, loss: 0.000733, epsilon: 0.050000, episode:  364\n",
            "frames: 672000, reward: 5.700000, loss: 0.002069, epsilon: 0.050000, episode:  364\n",
            "frames: 673000, reward: 5.700000, loss: 0.002767, epsilon: 0.050000, episode:  364\n",
            "frames: 674000, reward: 6.300000, loss: 0.001576, epsilon: 0.050000, episode:  365\n",
            "frames: 675000, reward: 6.300000, loss: 0.002337, epsilon: 0.050000, episode:  365\n",
            "frames: 676000, reward: 6.300000, loss: 0.002949, epsilon: 0.050000, episode:  365\n",
            "frames: 677000, reward: 6.300000, loss: 0.000544, epsilon: 0.050000, episode:  365\n",
            "frames: 678000, reward: 6.700000, loss: 0.001309, epsilon: 0.050000, episode:  366\n",
            "frames: 679000, reward: 6.700000, loss: 0.002906, epsilon: 0.050000, episode:  366\n",
            "frames: 680000, reward: 6.700000, loss: 0.000645, epsilon: 0.050000, episode:  366\n",
            "frames: 681000, reward: 6.700000, loss: 0.001437, epsilon: 0.050000, episode:  366\n",
            "frames: 682000, reward: 6.800000, loss: 0.001198, epsilon: 0.050000, episode:  367\n",
            "frames: 683000, reward: 6.800000, loss: 0.000871, epsilon: 0.050000, episode:  367\n",
            "frames: 684000, reward: 6.800000, loss: 0.001622, epsilon: 0.050000, episode:  367\n",
            "frames: 685000, reward: 7.200000, loss: 0.004833, epsilon: 0.050000, episode:  368\n",
            "frames: 686000, reward: 7.200000, loss: 0.003029, epsilon: 0.050000, episode:  368\n",
            "frames: 687000, reward: 7.200000, loss: 0.004462, epsilon: 0.050000, episode:  368\n",
            "frames: 688000, reward: 7.200000, loss: 0.001450, epsilon: 0.050000, episode:  368\n",
            "frames: 689000, reward: 6.300000, loss: 0.003252, epsilon: 0.050000, episode:  369\n",
            "frames: 690000, reward: 6.300000, loss: 0.000808, epsilon: 0.050000, episode:  369\n",
            "frames: 691000, reward: 6.300000, loss: 0.001945, epsilon: 0.050000, episode:  369\n",
            "frames: 692000, reward: 6.500000, loss: 0.001362, epsilon: 0.050000, episode:  370\n",
            "frames: 693000, reward: 6.500000, loss: 0.001529, epsilon: 0.050000, episode:  370\n",
            "frames: 694000, reward: 6.500000, loss: 0.002500, epsilon: 0.050000, episode:  370\n",
            "frames: 695000, reward: 6.500000, loss: 0.003968, epsilon: 0.050000, episode:  370\n",
            "frames: 696000, reward: 5.700000, loss: 0.002839, epsilon: 0.050000, episode:  371\n",
            "frames: 697000, reward: 5.700000, loss: 0.001398, epsilon: 0.050000, episode:  371\n",
            "frames: 698000, reward: 5.700000, loss: 0.004868, epsilon: 0.050000, episode:  371\n",
            "frames: 699000, reward: 6.700000, loss: 0.001072, epsilon: 0.050000, episode:  372\n",
            "frames: 700000, reward: 6.700000, loss: 0.001685, epsilon: 0.050000, episode:  372\n",
            "frames: 701000, reward: 6.700000, loss: 0.005430, epsilon: 0.050000, episode:  372\n",
            "frames: 702000, reward: 7.300000, loss: 0.000677, epsilon: 0.050000, episode:  373\n",
            "frames: 703000, reward: 7.300000, loss: 0.001037, epsilon: 0.050000, episode:  373\n",
            "frames: 704000, reward: 7.300000, loss: 0.002656, epsilon: 0.050000, episode:  373\n",
            "frames: 705000, reward: 7.600000, loss: 0.003157, epsilon: 0.050000, episode:  374\n",
            "frames: 706000, reward: 7.600000, loss: 0.000663, epsilon: 0.050000, episode:  374\n",
            "frames: 707000, reward: 7.600000, loss: 0.000721, epsilon: 0.050000, episode:  374\n",
            "frames: 708000, reward: 7.400000, loss: 0.000717, epsilon: 0.050000, episode:  375\n",
            "frames: 709000, reward: 7.400000, loss: 0.001187, epsilon: 0.050000, episode:  375\n",
            "frames: 710000, reward: 7.400000, loss: 0.020697, epsilon: 0.050000, episode:  376\n",
            "frames: 711000, reward: 7.400000, loss: 0.000571, epsilon: 0.050000, episode:  376\n",
            "frames: 712000, reward: 7.400000, loss: 0.002095, epsilon: 0.050000, episode:  376\n",
            "frames: 713000, reward: 7.900000, loss: 0.000882, epsilon: 0.050000, episode:  377\n",
            "frames: 714000, reward: 7.900000, loss: 0.001714, epsilon: 0.050000, episode:  377\n",
            "frames: 715000, reward: 7.900000, loss: 0.000711, epsilon: 0.050000, episode:  377\n",
            "frames: 716000, reward: 8.400000, loss: 0.001184, epsilon: 0.050000, episode:  378\n",
            "frames: 717000, reward: 8.400000, loss: 0.001634, epsilon: 0.050000, episode:  378\n",
            "frames: 718000, reward: 9.400000, loss: 0.001144, epsilon: 0.050000, episode:  379\n",
            "frames: 719000, reward: 9.400000, loss: 0.001192, epsilon: 0.050000, episode:  379\n",
            "frames: 720000, reward: 9.400000, loss: 0.002054, epsilon: 0.050000, episode:  379\n",
            "frames: 721000, reward: 9.800000, loss: 0.004445, epsilon: 0.050000, episode:  380\n",
            "frames: 722000, reward: 9.800000, loss: 0.004482, epsilon: 0.050000, episode:  380\n",
            "frames: 723000, reward: 11.000000, loss: 0.001011, epsilon: 0.050000, episode:  381\n",
            "frames: 724000, reward: 11.000000, loss: 0.002386, epsilon: 0.050000, episode:  381\n",
            "frames: 725000, reward: 11.000000, loss: 0.001306, epsilon: 0.050000, episode:  381\n",
            "frames: 726000, reward: 11.700000, loss: 0.001520, epsilon: 0.050000, episode:  382\n",
            "frames: 727000, reward: 11.700000, loss: 0.002617, epsilon: 0.050000, episode:  382\n",
            "frames: 728000, reward: 12.100000, loss: 0.001429, epsilon: 0.050000, episode:  383\n",
            "frames: 729000, reward: 12.100000, loss: 0.001664, epsilon: 0.050000, episode:  383\n",
            "frames: 730000, reward: 12.400000, loss: 0.001084, epsilon: 0.050000, episode:  384\n",
            "frames: 731000, reward: 12.400000, loss: 0.001256, epsilon: 0.050000, episode:  384\n",
            "frames: 732000, reward: 13.200000, loss: 0.001917, epsilon: 0.050000, episode:  385\n",
            "frames: 733000, reward: 13.200000, loss: 0.002090, epsilon: 0.050000, episode:  385\n",
            "frames: 734000, reward: 13.900000, loss: 0.003157, epsilon: 0.050000, episode:  386\n",
            "frames: 735000, reward: 13.900000, loss: 0.003429, epsilon: 0.050000, episode:  386\n",
            "frames: 736000, reward: 13.900000, loss: 0.001433, epsilon: 0.050000, episode:  386\n",
            "frames: 737000, reward: 13.900000, loss: 0.002261, epsilon: 0.050000, episode:  387\n",
            "frames: 738000, reward: 13.900000, loss: 0.001052, epsilon: 0.050000, episode:  387\n",
            "frames: 739000, reward: 14.000000, loss: 0.012358, epsilon: 0.050000, episode:  388\n",
            "frames: 740000, reward: 14.000000, loss: 0.004151, epsilon: 0.050000, episode:  388\n",
            "frames: 741000, reward: 15.000000, loss: 0.000554, epsilon: 0.050000, episode:  389\n",
            "frames: 742000, reward: 15.000000, loss: 0.003723, epsilon: 0.050000, episode:  389\n",
            "frames: 743000, reward: 15.400000, loss: 0.002794, epsilon: 0.050000, episode:  390\n",
            "frames: 744000, reward: 15.400000, loss: 0.001719, epsilon: 0.050000, episode:  390\n",
            "frames: 745000, reward: 15.400000, loss: 0.006787, epsilon: 0.050000, episode:  390\n",
            "frames: 746000, reward: 15.200000, loss: 0.000750, epsilon: 0.050000, episode:  391\n",
            "frames: 747000, reward: 15.200000, loss: 0.001520, epsilon: 0.050000, episode:  391\n",
            "frames: 748000, reward: 14.600000, loss: 0.002559, epsilon: 0.050000, episode:  392\n",
            "frames: 749000, reward: 14.600000, loss: 0.001913, epsilon: 0.050000, episode:  392\n",
            "frames: 750000, reward: 14.600000, loss: 0.001370, epsilon: 0.050000, episode:  392\n",
            "frames: 751000, reward: 14.600000, loss: 0.001019, epsilon: 0.050000, episode:  393\n",
            "frames: 752000, reward: 14.600000, loss: 0.000855, epsilon: 0.050000, episode:  393\n",
            "frames: 753000, reward: 14.700000, loss: 0.001045, epsilon: 0.050000, episode:  394\n",
            "frames: 754000, reward: 14.700000, loss: 0.000781, epsilon: 0.050000, episode:  394\n",
            "frames: 755000, reward: 14.700000, loss: 0.001288, epsilon: 0.050000, episode:  394\n",
            "frames: 756000, reward: 14.300000, loss: 0.001374, epsilon: 0.050000, episode:  395\n",
            "frames: 757000, reward: 14.300000, loss: 0.000528, epsilon: 0.050000, episode:  395\n",
            "frames: 758000, reward: 14.300000, loss: 0.001267, epsilon: 0.050000, episode:  395\n",
            "frames: 759000, reward: 13.300000, loss: 0.001361, epsilon: 0.050000, episode:  396\n",
            "frames: 760000, reward: 13.300000, loss: 0.000923, epsilon: 0.050000, episode:  396\n",
            "frames: 761000, reward: 13.700000, loss: 0.001104, epsilon: 0.050000, episode:  397\n",
            "frames: 762000, reward: 13.700000, loss: 0.006854, epsilon: 0.050000, episode:  397\n",
            "frames: 763000, reward: 13.000000, loss: 0.000828, epsilon: 0.050000, episode:  398\n",
            "frames: 764000, reward: 13.000000, loss: 0.001285, epsilon: 0.050000, episode:  398\n",
            "frames: 765000, reward: 13.000000, loss: 0.001101, epsilon: 0.050000, episode:  398\n",
            "frames: 766000, reward: 12.700000, loss: 0.001269, epsilon: 0.050000, episode:  399\n",
            "frames: 767000, reward: 12.700000, loss: 0.001460, epsilon: 0.050000, episode:  399\n",
            "frames: 768000, reward: 12.500000, loss: 0.001013, epsilon: 0.050000, episode:  400\n",
            "frames: 769000, reward: 12.500000, loss: 0.001588, epsilon: 0.050000, episode:  400\n",
            "frames: 770000, reward: 13.000000, loss: 0.000866, epsilon: 0.050000, episode:  401\n",
            "frames: 771000, reward: 13.000000, loss: 0.002064, epsilon: 0.050000, episode:  401\n",
            "frames: 772000, reward: 13.000000, loss: 0.000741, epsilon: 0.050000, episode:  401\n",
            "frames: 773000, reward: 13.500000, loss: 0.000883, epsilon: 0.050000, episode:  402\n",
            "frames: 774000, reward: 13.600000, loss: 0.001382, epsilon: 0.050000, episode:  403\n",
            "frames: 775000, reward: 13.600000, loss: 0.000242, epsilon: 0.050000, episode:  403\n",
            "frames: 776000, reward: 13.600000, loss: 0.001287, epsilon: 0.050000, episode:  403\n",
            "frames: 777000, reward: 13.700000, loss: 0.001824, epsilon: 0.050000, episode:  404\n",
            "frames: 778000, reward: 13.700000, loss: 0.001572, epsilon: 0.050000, episode:  404\n",
            "frames: 779000, reward: 14.200000, loss: 0.002157, epsilon: 0.050000, episode:  405\n",
            "frames: 780000, reward: 14.200000, loss: 0.000806, epsilon: 0.050000, episode:  405\n",
            "frames: 781000, reward: 15.600000, loss: 0.000608, epsilon: 0.050000, episode:  406\n",
            "frames: 782000, reward: 15.600000, loss: 0.000611, epsilon: 0.050000, episode:  406\n",
            "frames: 783000, reward: 15.600000, loss: 0.001709, epsilon: 0.050000, episode:  406\n",
            "frames: 784000, reward: 16.100000, loss: 0.000625, epsilon: 0.050000, episode:  407\n",
            "frames: 785000, reward: 16.100000, loss: 0.000718, epsilon: 0.050000, episode:  407\n",
            "frames: 786000, reward: 16.000000, loss: 0.001911, epsilon: 0.050000, episode:  408\n",
            "frames: 787000, reward: 16.000000, loss: 0.001471, epsilon: 0.050000, episode:  408\n",
            "frames: 788000, reward: 16.000000, loss: 0.000628, epsilon: 0.050000, episode:  408\n",
            "frames: 789000, reward: 16.200000, loss: 0.000849, epsilon: 0.050000, episode:  409\n",
            "frames: 790000, reward: 16.200000, loss: 0.001559, epsilon: 0.050000, episode:  409\n",
            "frames: 791000, reward: 16.200000, loss: 0.000943, epsilon: 0.050000, episode:  410\n",
            "frames: 792000, reward: 16.200000, loss: 0.000612, epsilon: 0.050000, episode:  410\n",
            "frames: 793000, reward: 16.300000, loss: 0.001678, epsilon: 0.050000, episode:  411\n",
            "frames: 794000, reward: 16.300000, loss: 0.001242, epsilon: 0.050000, episode:  411\n",
            "frames: 795000, reward: 15.800000, loss: 0.000661, epsilon: 0.050000, episode:  412\n",
            "frames: 796000, reward: 15.800000, loss: 0.001415, epsilon: 0.050000, episode:  412\n",
            "frames: 797000, reward: 15.800000, loss: 0.000475, epsilon: 0.050000, episode:  412\n",
            "frames: 798000, reward: 15.800000, loss: 0.000587, epsilon: 0.050000, episode:  413\n",
            "frames: 799000, reward: 15.800000, loss: 0.000994, epsilon: 0.050000, episode:  413\n",
            "frames: 800000, reward: 15.800000, loss: 0.000886, epsilon: 0.050000, episode:  413\n",
            "frames: 801000, reward: 14.700000, loss: 0.000998, epsilon: 0.050000, episode:  414\n",
            "frames: 802000, reward: 14.700000, loss: 0.001112, epsilon: 0.050000, episode:  414\n",
            "frames: 803000, reward: 14.200000, loss: 0.001552, epsilon: 0.050000, episode:  415\n",
            "frames: 804000, reward: 14.200000, loss: 0.000812, epsilon: 0.050000, episode:  415\n",
            "frames: 805000, reward: 13.800000, loss: 0.001012, epsilon: 0.050000, episode:  416\n",
            "frames: 806000, reward: 13.800000, loss: 0.000665, epsilon: 0.050000, episode:  416\n",
            "frames: 807000, reward: 12.900000, loss: 0.003118, epsilon: 0.050000, episode:  417\n",
            "frames: 808000, reward: 12.900000, loss: 0.000645, epsilon: 0.050000, episode:  417\n",
            "frames: 809000, reward: 12.900000, loss: 0.000961, epsilon: 0.050000, episode:  417\n",
            "frames: 810000, reward: 13.400000, loss: 0.000841, epsilon: 0.050000, episode:  418\n",
            "frames: 811000, reward: 13.400000, loss: 0.000252, epsilon: 0.050000, episode:  418\n",
            "frames: 812000, reward: 13.500000, loss: 0.020991, epsilon: 0.050000, episode:  419\n",
            "frames: 813000, reward: 13.500000, loss: 0.001763, epsilon: 0.050000, episode:  419\n",
            "frames: 814000, reward: 13.200000, loss: 0.000810, epsilon: 0.050000, episode:  420\n",
            "frames: 815000, reward: 13.200000, loss: 0.001288, epsilon: 0.050000, episode:  420\n",
            "frames: 816000, reward: 13.200000, loss: 0.001827, epsilon: 0.050000, episode:  420\n",
            "frames: 817000, reward: 12.800000, loss: 0.002672, epsilon: 0.050000, episode:  421\n",
            "frames: 818000, reward: 12.800000, loss: 0.002317, epsilon: 0.050000, episode:  421\n",
            "frames: 819000, reward: 13.500000, loss: 0.000865, epsilon: 0.050000, episode:  422\n",
            "frames: 820000, reward: 13.500000, loss: 0.000615, epsilon: 0.050000, episode:  422\n",
            "frames: 821000, reward: 13.100000, loss: 0.000724, epsilon: 0.050000, episode:  423\n",
            "frames: 822000, reward: 13.100000, loss: 0.001933, epsilon: 0.050000, episode:  423\n",
            "frames: 823000, reward: 13.100000, loss: 0.000768, epsilon: 0.050000, episode:  423\n",
            "frames: 824000, reward: 13.600000, loss: 0.002166, epsilon: 0.050000, episode:  424\n",
            "frames: 825000, reward: 13.600000, loss: 0.000524, epsilon: 0.050000, episode:  424\n",
            "frames: 826000, reward: 13.900000, loss: 0.000775, epsilon: 0.050000, episode:  425\n",
            "frames: 827000, reward: 13.900000, loss: 0.001184, epsilon: 0.050000, episode:  425\n",
            "frames: 828000, reward: 14.200000, loss: 0.000650, epsilon: 0.050000, episode:  426\n",
            "frames: 829000, reward: 14.200000, loss: 0.000985, epsilon: 0.050000, episode:  426\n",
            "frames: 830000, reward: 14.200000, loss: 0.000312, epsilon: 0.050000, episode:  426\n",
            "frames: 831000, reward: 14.300000, loss: 0.000700, epsilon: 0.050000, episode:  427\n",
            "frames: 832000, reward: 14.300000, loss: 0.000573, epsilon: 0.050000, episode:  427\n",
            "frames: 833000, reward: 14.000000, loss: 0.000774, epsilon: 0.050000, episode:  428\n",
            "frames: 834000, reward: 14.000000, loss: 0.002502, epsilon: 0.050000, episode:  428\n",
            "frames: 835000, reward: 13.800000, loss: 0.001021, epsilon: 0.050000, episode:  429\n",
            "frames: 836000, reward: 13.800000, loss: 0.000480, epsilon: 0.050000, episode:  429\n",
            "frames: 837000, reward: 14.200000, loss: 0.000295, epsilon: 0.050000, episode:  430\n",
            "frames: 838000, reward: 14.200000, loss: 0.000909, epsilon: 0.050000, episode:  430\n",
            "frames: 839000, reward: 14.700000, loss: 0.000377, epsilon: 0.050000, episode:  431\n",
            "frames: 840000, reward: 14.700000, loss: 0.001112, epsilon: 0.050000, episode:  431\n",
            "frames: 841000, reward: 14.700000, loss: 0.000644, epsilon: 0.050000, episode:  431\n",
            "frames: 842000, reward: 13.700000, loss: 0.000353, epsilon: 0.050000, episode:  432\n",
            "frames: 843000, reward: 14.500000, loss: 0.000626, epsilon: 0.050000, episode:  433\n",
            "frames: 844000, reward: 14.500000, loss: 0.000315, epsilon: 0.050000, episode:  433\n",
            "frames: 845000, reward: 15.000000, loss: 0.001015, epsilon: 0.050000, episode:  434\n",
            "frames: 846000, reward: 15.000000, loss: 0.001212, epsilon: 0.050000, episode:  434\n",
            "frames: 847000, reward: 15.000000, loss: 0.000541, epsilon: 0.050000, episode:  434\n",
            "frames: 848000, reward: 15.000000, loss: 0.000416, epsilon: 0.050000, episode:  435\n",
            "frames: 849000, reward: 15.000000, loss: 0.000905, epsilon: 0.050000, episode:  435\n",
            "frames: 850000, reward: 14.200000, loss: 0.000609, epsilon: 0.050000, episode:  436\n",
            "frames: 851000, reward: 14.200000, loss: 0.000962, epsilon: 0.050000, episode:  436\n",
            "frames: 852000, reward: 14.200000, loss: 0.000378, epsilon: 0.050000, episode:  436\n",
            "frames: 853000, reward: 14.300000, loss: 0.003911, epsilon: 0.050000, episode:  437\n",
            "frames: 854000, reward: 14.300000, loss: 0.001575, epsilon: 0.050000, episode:  437\n",
            "frames: 855000, reward: 14.300000, loss: 0.000253, epsilon: 0.050000, episode:  437\n",
            "frames: 856000, reward: 14.300000, loss: 0.001171, epsilon: 0.050000, episode:  438\n",
            "frames: 857000, reward: 14.300000, loss: 0.000562, epsilon: 0.050000, episode:  438\n",
            "frames: 858000, reward: 14.600000, loss: 0.000391, epsilon: 0.050000, episode:  439\n",
            "frames: 859000, reward: 14.600000, loss: 0.001250, epsilon: 0.050000, episode:  439\n",
            "frames: 860000, reward: 14.300000, loss: 0.000681, epsilon: 0.050000, episode:  440\n",
            "frames: 861000, reward: 14.300000, loss: 0.000934, epsilon: 0.050000, episode:  440\n",
            "frames: 862000, reward: 14.300000, loss: 0.001729, epsilon: 0.050000, episode:  440\n",
            "frames: 863000, reward: 13.400000, loss: 0.001280, epsilon: 0.050000, episode:  441\n",
            "frames: 864000, reward: 13.400000, loss: 0.000600, epsilon: 0.050000, episode:  441\n",
            "frames: 865000, reward: 13.400000, loss: 0.000783, epsilon: 0.050000, episode:  441\n",
            "frames: 866000, reward: 14.100000, loss: 0.000642, epsilon: 0.050000, episode:  442\n",
            "frames: 867000, reward: 14.100000, loss: 0.000683, epsilon: 0.050000, episode:  442\n",
            "frames: 868000, reward: 13.900000, loss: 0.001032, epsilon: 0.050000, episode:  443\n",
            "frames: 869000, reward: 13.900000, loss: 0.001374, epsilon: 0.050000, episode:  443\n",
            "frames: 870000, reward: 13.700000, loss: 0.000413, epsilon: 0.050000, episode:  444\n",
            "frames: 871000, reward: 13.700000, loss: 0.000321, epsilon: 0.050000, episode:  444\n",
            "frames: 872000, reward: 13.700000, loss: 0.000277, epsilon: 0.050000, episode:  444\n",
            "frames: 873000, reward: 13.700000, loss: 0.000802, epsilon: 0.050000, episode:  445\n",
            "frames: 874000, reward: 13.700000, loss: 0.000443, epsilon: 0.050000, episode:  445\n",
            "frames: 875000, reward: 14.300000, loss: 0.001010, epsilon: 0.050000, episode:  446\n",
            "frames: 876000, reward: 14.300000, loss: 0.000619, epsilon: 0.050000, episode:  446\n",
            "frames: 877000, reward: 14.300000, loss: 0.001008, epsilon: 0.050000, episode:  446\n",
            "frames: 878000, reward: 14.800000, loss: 0.000559, epsilon: 0.050000, episode:  447\n",
            "frames: 879000, reward: 14.800000, loss: 0.000512, epsilon: 0.050000, episode:  447\n",
            "frames: 880000, reward: 14.800000, loss: 0.001934, epsilon: 0.050000, episode:  447\n",
            "frames: 881000, reward: 14.700000, loss: 0.000456, epsilon: 0.050000, episode:  448\n",
            "frames: 882000, reward: 14.700000, loss: 0.000806, epsilon: 0.050000, episode:  448\n",
            "frames: 883000, reward: 14.000000, loss: 0.000676, epsilon: 0.050000, episode:  449\n",
            "frames: 884000, reward: 14.000000, loss: 0.000691, epsilon: 0.050000, episode:  449\n",
            "frames: 885000, reward: 14.300000, loss: 0.000735, epsilon: 0.050000, episode:  450\n",
            "frames: 886000, reward: 14.300000, loss: 0.000206, epsilon: 0.050000, episode:  450\n",
            "frames: 887000, reward: 14.300000, loss: 0.000329, epsilon: 0.050000, episode:  450\n",
            "frames: 888000, reward: 14.100000, loss: 0.000631, epsilon: 0.050000, episode:  451\n",
            "frames: 889000, reward: 14.100000, loss: 0.002411, epsilon: 0.050000, episode:  451\n",
            "frames: 890000, reward: 14.100000, loss: 0.000591, epsilon: 0.050000, episode:  451\n",
            "frames: 891000, reward: 14.200000, loss: 0.000739, epsilon: 0.050000, episode:  452\n",
            "frames: 892000, reward: 14.200000, loss: 0.003313, epsilon: 0.050000, episode:  452\n",
            "frames: 893000, reward: 13.900000, loss: 0.000497, epsilon: 0.050000, episode:  453\n",
            "frames: 894000, reward: 13.900000, loss: 0.000310, epsilon: 0.050000, episode:  453\n",
            "frames: 895000, reward: 13.900000, loss: 0.000454, epsilon: 0.050000, episode:  453\n",
            "frames: 896000, reward: 14.100000, loss: 0.001072, epsilon: 0.050000, episode:  454\n",
            "frames: 897000, reward: 14.100000, loss: 0.000533, epsilon: 0.050000, episode:  454\n",
            "frames: 898000, reward: 14.100000, loss: 0.001366, epsilon: 0.050000, episode:  454\n",
            "frames: 899000, reward: 13.300000, loss: 0.001749, epsilon: 0.050000, episode:  455\n",
            "frames: 900000, reward: 13.300000, loss: 0.003392, epsilon: 0.050000, episode:  455\n",
            "frames: 901000, reward: 13.100000, loss: 0.000215, epsilon: 0.050000, episode:  456\n",
            "frames: 902000, reward: 13.100000, loss: 0.000504, epsilon: 0.050000, episode:  456\n",
            "frames: 903000, reward: 13.500000, loss: 0.000532, epsilon: 0.050000, episode:  457\n",
            "frames: 904000, reward: 13.500000, loss: 0.000553, epsilon: 0.050000, episode:  457\n",
            "frames: 905000, reward: 14.300000, loss: 0.000336, epsilon: 0.050000, episode:  458\n",
            "frames: 906000, reward: 14.300000, loss: 0.000534, epsilon: 0.050000, episode:  458\n",
            "frames: 907000, reward: 15.000000, loss: 0.001988, epsilon: 0.050000, episode:  459\n",
            "frames: 908000, reward: 15.000000, loss: 0.000490, epsilon: 0.050000, episode:  459\n",
            "frames: 909000, reward: 15.200000, loss: 0.000736, epsilon: 0.050000, episode:  460\n",
            "frames: 910000, reward: 15.200000, loss: 0.000778, epsilon: 0.050000, episode:  460\n",
            "frames: 911000, reward: 16.000000, loss: 0.000662, epsilon: 0.050000, episode:  461\n",
            "frames: 912000, reward: 16.000000, loss: 0.000187, epsilon: 0.050000, episode:  461\n",
            "frames: 913000, reward: 15.800000, loss: 0.001009, epsilon: 0.050000, episode:  462\n",
            "frames: 914000, reward: 15.800000, loss: 0.000884, epsilon: 0.050000, episode:  462\n",
            "frames: 915000, reward: 15.800000, loss: 0.000736, epsilon: 0.050000, episode:  462\n",
            "frames: 916000, reward: 15.000000, loss: 0.001198, epsilon: 0.050000, episode:  463\n",
            "frames: 917000, reward: 15.000000, loss: 0.002559, epsilon: 0.050000, episode:  463\n",
            "frames: 918000, reward: 15.000000, loss: 0.000619, epsilon: 0.050000, episode:  463\n",
            "frames: 919000, reward: 14.900000, loss: 0.001359, epsilon: 0.050000, episode:  464\n",
            "frames: 920000, reward: 14.900000, loss: 0.000494, epsilon: 0.050000, episode:  464\n",
            "frames: 921000, reward: 14.900000, loss: 0.000854, epsilon: 0.050000, episode:  464\n",
            "frames: 922000, reward: 15.300000, loss: 0.000862, epsilon: 0.050000, episode:  465\n",
            "frames: 923000, reward: 15.300000, loss: 0.000611, epsilon: 0.050000, episode:  465\n",
            "frames: 924000, reward: 15.100000, loss: 0.000336, epsilon: 0.050000, episode:  466\n",
            "frames: 925000, reward: 15.100000, loss: 0.001611, epsilon: 0.050000, episode:  466\n",
            "frames: 926000, reward: 14.800000, loss: 0.000499, epsilon: 0.050000, episode:  467\n",
            "frames: 927000, reward: 14.800000, loss: 0.000772, epsilon: 0.050000, episode:  467\n",
            "frames: 928000, reward: 14.800000, loss: 0.000631, epsilon: 0.050000, episode:  467\n",
            "frames: 929000, reward: 14.400000, loss: 0.000677, epsilon: 0.050000, episode:  468\n",
            "frames: 930000, reward: 14.400000, loss: 0.000627, epsilon: 0.050000, episode:  468\n",
            "frames: 931000, reward: 14.100000, loss: 0.000866, epsilon: 0.050000, episode:  469\n",
            "frames: 932000, reward: 14.100000, loss: 0.001403, epsilon: 0.050000, episode:  469\n",
            "frames: 933000, reward: 14.100000, loss: 0.000374, epsilon: 0.050000, episode:  469\n",
            "frames: 934000, reward: 13.600000, loss: 0.000757, epsilon: 0.050000, episode:  470\n",
            "frames: 935000, reward: 13.600000, loss: 0.000612, epsilon: 0.050000, episode:  470\n",
            "frames: 936000, reward: 13.900000, loss: 0.000884, epsilon: 0.050000, episode:  471\n",
            "frames: 937000, reward: 13.900000, loss: 0.000543, epsilon: 0.050000, episode:  471\n",
            "frames: 938000, reward: 14.000000, loss: 0.004042, epsilon: 0.050000, episode:  472\n",
            "frames: 939000, reward: 14.000000, loss: 0.000820, epsilon: 0.050000, episode:  472\n",
            "frames: 940000, reward: 14.000000, loss: 0.000727, epsilon: 0.050000, episode:  472\n",
            "frames: 941000, reward: 14.700000, loss: 0.000653, epsilon: 0.050000, episode:  473\n",
            "frames: 942000, reward: 14.700000, loss: 0.002525, epsilon: 0.050000, episode:  473\n",
            "frames: 943000, reward: 15.000000, loss: 0.001168, epsilon: 0.050000, episode:  474\n",
            "frames: 944000, reward: 15.000000, loss: 0.001095, epsilon: 0.050000, episode:  474\n",
            "frames: 945000, reward: 15.300000, loss: 0.001570, epsilon: 0.050000, episode:  475\n",
            "frames: 946000, reward: 15.300000, loss: 0.000544, epsilon: 0.050000, episode:  475\n",
            "frames: 947000, reward: 15.700000, loss: 0.001131, epsilon: 0.050000, episode:  476\n",
            "frames: 948000, reward: 15.700000, loss: 0.000542, epsilon: 0.050000, episode:  476\n",
            "frames: 949000, reward: 15.700000, loss: 0.000250, epsilon: 0.050000, episode:  476\n",
            "frames: 950000, reward: 15.200000, loss: 0.001450, epsilon: 0.050000, episode:  477\n",
            "frames: 951000, reward: 15.200000, loss: 0.001002, epsilon: 0.050000, episode:  477\n",
            "frames: 952000, reward: 15.300000, loss: 0.000776, epsilon: 0.050000, episode:  478\n",
            "frames: 953000, reward: 15.300000, loss: 0.000746, epsilon: 0.050000, episode:  478\n",
            "frames: 954000, reward: 15.300000, loss: 0.001342, epsilon: 0.050000, episode:  478\n",
            "frames: 955000, reward: 14.900000, loss: 0.000475, epsilon: 0.050000, episode:  479\n",
            "frames: 956000, reward: 14.900000, loss: 0.000407, epsilon: 0.050000, episode:  479\n",
            "frames: 957000, reward: 14.900000, loss: 0.000590, epsilon: 0.050000, episode:  479\n",
            "frames: 958000, reward: 15.000000, loss: 0.000593, epsilon: 0.050000, episode:  480\n",
            "frames: 959000, reward: 15.000000, loss: 0.000540, epsilon: 0.050000, episode:  480\n",
            "frames: 960000, reward: 15.000000, loss: 0.001167, epsilon: 0.050000, episode:  480\n",
            "frames: 961000, reward: 14.000000, loss: 0.001289, epsilon: 0.050000, episode:  481\n",
            "frames: 962000, reward: 14.000000, loss: 0.000502, epsilon: 0.050000, episode:  481\n",
            "frames: 963000, reward: 14.000000, loss: 0.007395, epsilon: 0.050000, episode:  481\n",
            "frames: 964000, reward: 13.900000, loss: 0.000603, epsilon: 0.050000, episode:  482\n",
            "frames: 965000, reward: 13.900000, loss: 0.000734, epsilon: 0.050000, episode:  482\n",
            "frames: 966000, reward: 13.800000, loss: 0.001111, epsilon: 0.050000, episode:  483\n",
            "frames: 967000, reward: 13.800000, loss: 0.000602, epsilon: 0.050000, episode:  483\n",
            "frames: 968000, reward: 13.800000, loss: 0.000868, epsilon: 0.050000, episode:  483\n",
            "frames: 969000, reward: 13.800000, loss: 0.000758, epsilon: 0.050000, episode:  483\n",
            "frames: 970000, reward: 12.600000, loss: 0.000544, epsilon: 0.050000, episode:  484\n",
            "frames: 971000, reward: 13.000000, loss: 0.000793, epsilon: 0.050000, episode:  485\n",
            "frames: 972000, reward: 13.000000, loss: 0.002435, epsilon: 0.050000, episode:  485\n",
            "frames: 973000, reward: 12.700000, loss: 0.001079, epsilon: 0.050000, episode:  486\n",
            "frames: 974000, reward: 12.700000, loss: 0.000465, epsilon: 0.050000, episode:  486\n",
            "frames: 975000, reward: 12.700000, loss: 0.000766, epsilon: 0.050000, episode:  486\n",
            "frames: 976000, reward: 12.900000, loss: 0.001905, epsilon: 0.050000, episode:  487\n",
            "frames: 977000, reward: 12.900000, loss: 0.000453, epsilon: 0.050000, episode:  487\n",
            "frames: 978000, reward: 12.800000, loss: 0.000671, epsilon: 0.050000, episode:  488\n",
            "frames: 979000, reward: 12.800000, loss: 0.001738, epsilon: 0.050000, episode:  488\n",
            "frames: 980000, reward: 12.600000, loss: 0.000672, epsilon: 0.050000, episode:  489\n",
            "frames: 981000, reward: 12.600000, loss: 0.000650, epsilon: 0.050000, episode:  489\n",
            "frames: 982000, reward: 12.800000, loss: 0.000953, epsilon: 0.050000, episode:  490\n",
            "frames: 983000, reward: 12.800000, loss: 0.000752, epsilon: 0.050000, episode:  490\n",
            "frames: 984000, reward: 13.400000, loss: 0.000410, epsilon: 0.050000, episode:  491\n",
            "frames: 985000, reward: 13.400000, loss: 0.000869, epsilon: 0.050000, episode:  491\n",
            "frames: 986000, reward: 13.600000, loss: 0.000508, epsilon: 0.050000, episode:  492\n",
            "frames: 987000, reward: 13.600000, loss: 0.000463, epsilon: 0.050000, episode:  492\n",
            "frames: 988000, reward: 13.600000, loss: 0.001157, epsilon: 0.050000, episode:  492\n",
            "frames: 989000, reward: 13.800000, loss: 0.000828, epsilon: 0.050000, episode:  493\n",
            "frames: 990000, reward: 15.200000, loss: 0.000905, epsilon: 0.050000, episode:  494\n",
            "frames: 991000, reward: 15.200000, loss: 0.000691, epsilon: 0.050000, episode:  494\n",
            "frames: 992000, reward: 15.200000, loss: 0.000686, epsilon: 0.050000, episode:  494\n",
            "frames: 993000, reward: 14.900000, loss: 0.000345, epsilon: 0.050000, episode:  495\n",
            "frames: 994000, reward: 15.200000, loss: 0.000762, epsilon: 0.050000, episode:  496\n",
            "frames: 995000, reward: 15.200000, loss: 0.000435, epsilon: 0.050000, episode:  496\n",
            "frames: 996000, reward: 15.200000, loss: 0.001517, epsilon: 0.050000, episode:  496\n",
            "frames: 997000, reward: 14.900000, loss: 0.000329, epsilon: 0.050000, episode:  497\n",
            "frames: 998000, reward: 14.900000, loss: 0.001064, epsilon: 0.050000, episode:  497\n",
            "frames: 999000, reward: 14.900000, loss: 0.001893, epsilon: 0.050000, episode:  497\n",
            "frames: 1000000, reward: 13.900000, loss: 0.000475, epsilon: 0.050000, episode:  498\n",
            "frames: 1001000, reward: 13.900000, loss: 0.000826, epsilon: 0.050000, episode:  498\n",
            "frames: 1002000, reward: 14.900000, loss: 0.000611, epsilon: 0.050000, episode:  499\n",
            "frames: 1003000, reward: 14.900000, loss: 0.000673, epsilon: 0.050000, episode:  499\n",
            "frames: 1004000, reward: 14.600000, loss: 0.001969, epsilon: 0.050000, episode:  500\n",
            "frames: 1005000, reward: 14.600000, loss: 0.006494, epsilon: 0.050000, episode:  500\n",
            "frames: 1006000, reward: 14.900000, loss: 0.000653, epsilon: 0.050000, episode:  501\n",
            "frames: 1007000, reward: 14.900000, loss: 0.001118, epsilon: 0.050000, episode:  501\n",
            "frames: 1008000, reward: 15.000000, loss: 0.001463, epsilon: 0.050000, episode:  502\n",
            "frames: 1009000, reward: 15.000000, loss: 0.000433, epsilon: 0.050000, episode:  502\n",
            "frames: 1010000, reward: 15.000000, loss: 0.004529, epsilon: 0.050000, episode:  502\n",
            "frames: 1011000, reward: 15.000000, loss: 0.000628, epsilon: 0.050000, episode:  503\n",
            "frames: 1012000, reward: 15.000000, loss: 0.000763, epsilon: 0.050000, episode:  503\n",
            "frames: 1013000, reward: 14.500000, loss: 0.001106, epsilon: 0.050000, episode:  504\n",
            "frames: 1014000, reward: 14.500000, loss: 0.000756, epsilon: 0.050000, episode:  504\n",
            "frames: 1015000, reward: 14.500000, loss: 0.003100, epsilon: 0.050000, episode:  504\n",
            "frames: 1016000, reward: 14.800000, loss: 0.000722, epsilon: 0.050000, episode:  505\n",
            "frames: 1017000, reward: 14.800000, loss: 0.000399, epsilon: 0.050000, episode:  505\n",
            "frames: 1018000, reward: 14.800000, loss: 0.000632, epsilon: 0.050000, episode:  506\n",
            "frames: 1019000, reward: 14.800000, loss: 0.000784, epsilon: 0.050000, episode:  506\n",
            "frames: 1020000, reward: 15.300000, loss: 0.000871, epsilon: 0.050000, episode:  507\n",
            "frames: 1021000, reward: 15.300000, loss: 0.001880, epsilon: 0.050000, episode:  507\n",
            "frames: 1022000, reward: 15.300000, loss: 0.000357, epsilon: 0.050000, episode:  507\n",
            "frames: 1023000, reward: 15.600000, loss: 0.002583, epsilon: 0.050000, episode:  508\n",
            "frames: 1024000, reward: 15.600000, loss: 0.000462, epsilon: 0.050000, episode:  508\n",
            "frames: 1025000, reward: 15.200000, loss: 0.003298, epsilon: 0.050000, episode:  509\n",
            "frames: 1026000, reward: 15.200000, loss: 0.000831, epsilon: 0.050000, episode:  509\n",
            "frames: 1027000, reward: 15.800000, loss: 0.001467, epsilon: 0.050000, episode:  510\n",
            "frames: 1028000, reward: 15.800000, loss: 0.000452, epsilon: 0.050000, episode:  510\n",
            "frames: 1029000, reward: 15.900000, loss: 0.001238, epsilon: 0.050000, episode:  511\n",
            "frames: 1030000, reward: 15.900000, loss: 0.001274, epsilon: 0.050000, episode:  511\n",
            "frames: 1031000, reward: 15.300000, loss: 0.000687, epsilon: 0.050000, episode:  512\n",
            "frames: 1032000, reward: 15.300000, loss: 0.000566, epsilon: 0.050000, episode:  512\n",
            "frames: 1033000, reward: 15.600000, loss: 0.004728, epsilon: 0.050000, episode:  513\n",
            "frames: 1034000, reward: 15.600000, loss: 0.000902, epsilon: 0.050000, episode:  513\n",
            "frames: 1035000, reward: 16.000000, loss: 0.003345, epsilon: 0.050000, episode:  514\n",
            "frames: 1036000, reward: 16.000000, loss: 0.000618, epsilon: 0.050000, episode:  514\n",
            "frames: 1037000, reward: 16.000000, loss: 0.000425, epsilon: 0.050000, episode:  514\n",
            "frames: 1038000, reward: 16.100000, loss: 0.000373, epsilon: 0.050000, episode:  515\n",
            "frames: 1039000, reward: 16.100000, loss: 0.000652, epsilon: 0.050000, episode:  515\n",
            "frames: 1040000, reward: 15.500000, loss: 0.001368, epsilon: 0.050000, episode:  516\n",
            "frames: 1041000, reward: 15.500000, loss: 0.000353, epsilon: 0.050000, episode:  516\n",
            "frames: 1042000, reward: 15.500000, loss: 0.000353, epsilon: 0.050000, episode:  516\n",
            "frames: 1043000, reward: 15.200000, loss: 0.000462, epsilon: 0.050000, episode:  517\n",
            "frames: 1044000, reward: 15.200000, loss: 0.001300, epsilon: 0.050000, episode:  517\n",
            "frames: 1045000, reward: 15.800000, loss: 0.001835, epsilon: 0.050000, episode:  518\n",
            "frames: 1046000, reward: 15.800000, loss: 0.001313, epsilon: 0.050000, episode:  518\n",
            "frames: 1047000, reward: 15.800000, loss: 0.000370, epsilon: 0.050000, episode:  518\n",
            "frames: 1048000, reward: 15.700000, loss: 0.000768, epsilon: 0.050000, episode:  519\n",
            "frames: 1049000, reward: 15.700000, loss: 0.000345, epsilon: 0.050000, episode:  519\n",
            "frames: 1050000, reward: 15.400000, loss: 0.003769, epsilon: 0.050000, episode:  520\n",
            "frames: 1051000, reward: 15.400000, loss: 0.001422, epsilon: 0.050000, episode:  520\n",
            "frames: 1052000, reward: 15.200000, loss: 0.000879, epsilon: 0.050000, episode:  521\n",
            "frames: 1053000, reward: 15.200000, loss: 0.001056, epsilon: 0.050000, episode:  521\n",
            "frames: 1054000, reward: 15.800000, loss: 0.000749, epsilon: 0.050000, episode:  522\n",
            "frames: 1055000, reward: 15.800000, loss: 0.000497, epsilon: 0.050000, episode:  522\n",
            "frames: 1056000, reward: 15.800000, loss: 0.000361, epsilon: 0.050000, episode:  522\n",
            "frames: 1057000, reward: 15.400000, loss: 0.000446, epsilon: 0.050000, episode:  523\n",
            "frames: 1058000, reward: 15.400000, loss: 0.000328, epsilon: 0.050000, episode:  523\n",
            "frames: 1059000, reward: 15.400000, loss: 0.000510, epsilon: 0.050000, episode:  523\n",
            "frames: 1060000, reward: 15.000000, loss: 0.000859, epsilon: 0.050000, episode:  524\n",
            "frames: 1061000, reward: 15.000000, loss: 0.000291, epsilon: 0.050000, episode:  524\n",
            "frames: 1062000, reward: 14.600000, loss: 0.001721, epsilon: 0.050000, episode:  525\n",
            "frames: 1063000, reward: 14.600000, loss: 0.005998, epsilon: 0.050000, episode:  525\n",
            "frames: 1064000, reward: 15.500000, loss: 0.000593, epsilon: 0.050000, episode:  526\n",
            "frames: 1065000, reward: 15.500000, loss: 0.009713, epsilon: 0.050000, episode:  526\n",
            "frames: 1066000, reward: 16.200000, loss: 0.000481, epsilon: 0.050000, episode:  527\n",
            "frames: 1067000, reward: 16.200000, loss: 0.000362, epsilon: 0.050000, episode:  527\n",
            "frames: 1068000, reward: 16.300000, loss: 0.000757, epsilon: 0.050000, episode:  528\n",
            "frames: 1069000, reward: 16.300000, loss: 0.000395, epsilon: 0.050000, episode:  528\n",
            "frames: 1070000, reward: 16.800000, loss: 0.000538, epsilon: 0.050000, episode:  529\n",
            "frames: 1071000, reward: 16.800000, loss: 0.000964, epsilon: 0.050000, episode:  529\n",
            "frames: 1072000, reward: 17.200000, loss: 0.000208, epsilon: 0.050000, episode:  530\n",
            "frames: 1073000, reward: 17.200000, loss: 0.001520, epsilon: 0.050000, episode:  530\n",
            "frames: 1074000, reward: 17.200000, loss: 0.001488, epsilon: 0.050000, episode:  531\n",
            "frames: 1075000, reward: 17.200000, loss: 0.000654, epsilon: 0.050000, episode:  531\n",
            "frames: 1076000, reward: 17.400000, loss: 0.000611, epsilon: 0.050000, episode:  532\n",
            "frames: 1077000, reward: 17.400000, loss: 0.000716, epsilon: 0.050000, episode:  532\n",
            "frames: 1078000, reward: 17.400000, loss: 0.000655, epsilon: 0.050000, episode:  532\n",
            "frames: 1079000, reward: 17.400000, loss: 0.003327, epsilon: 0.050000, episode:  533\n",
            "frames: 1080000, reward: 17.400000, loss: 0.000515, epsilon: 0.050000, episode:  533\n",
            "frames: 1081000, reward: 17.400000, loss: 0.000201, epsilon: 0.050000, episode:  533\n",
            "frames: 1082000, reward: 17.000000, loss: 0.000420, epsilon: 0.050000, episode:  534\n",
            "frames: 1083000, reward: 17.000000, loss: 0.000742, epsilon: 0.050000, episode:  534\n",
            "frames: 1084000, reward: 17.300000, loss: 0.001309, epsilon: 0.050000, episode:  535\n",
            "frames: 1085000, reward: 17.300000, loss: 0.000418, epsilon: 0.050000, episode:  535\n",
            "frames: 1086000, reward: 17.300000, loss: 0.000245, epsilon: 0.050000, episode:  535\n",
            "frames: 1087000, reward: 16.800000, loss: 0.001554, epsilon: 0.050000, episode:  536\n",
            "frames: 1088000, reward: 16.800000, loss: 0.003425, epsilon: 0.050000, episode:  536\n",
            "frames: 1089000, reward: 16.400000, loss: 0.000302, epsilon: 0.050000, episode:  537\n",
            "frames: 1090000, reward: 16.600000, loss: 0.000806, epsilon: 0.050000, episode:  538\n",
            "frames: 1091000, reward: 16.600000, loss: 0.000667, epsilon: 0.050000, episode:  538\n",
            "frames: 1092000, reward: 16.600000, loss: 0.000395, epsilon: 0.050000, episode:  538\n",
            "frames: 1093000, reward: 16.000000, loss: 0.004805, epsilon: 0.050000, episode:  539\n",
            "frames: 1094000, reward: 16.000000, loss: 0.000722, epsilon: 0.050000, episode:  539\n",
            "frames: 1095000, reward: 16.000000, loss: 0.000949, epsilon: 0.050000, episode:  540\n",
            "frames: 1096000, reward: 16.000000, loss: 0.000481, epsilon: 0.050000, episode:  540\n",
            "frames: 1097000, reward: 16.200000, loss: 0.000959, epsilon: 0.050000, episode:  541\n",
            "frames: 1098000, reward: 16.200000, loss: 0.000282, epsilon: 0.050000, episode:  541\n",
            "frames: 1099000, reward: 15.900000, loss: 0.000337, epsilon: 0.050000, episode:  542\n",
            "frames: 1100000, reward: 15.900000, loss: 0.000231, epsilon: 0.050000, episode:  542\n",
            "frames: 1101000, reward: 15.900000, loss: 0.000275, epsilon: 0.050000, episode:  542\n",
            "frames: 1102000, reward: 16.000000, loss: 0.000376, epsilon: 0.050000, episode:  543\n",
            "frames: 1103000, reward: 16.700000, loss: 0.000221, epsilon: 0.050000, episode:  544\n",
            "frames: 1104000, reward: 16.700000, loss: 0.000508, epsilon: 0.050000, episode:  544\n",
            "frames: 1105000, reward: 16.900000, loss: 0.000576, epsilon: 0.050000, episode:  545\n",
            "frames: 1106000, reward: 16.900000, loss: 0.000833, epsilon: 0.050000, episode:  545\n",
            "frames: 1107000, reward: 17.300000, loss: 0.000383, epsilon: 0.050000, episode:  546\n",
            "frames: 1108000, reward: 17.300000, loss: 0.000341, epsilon: 0.050000, episode:  546\n",
            "frames: 1109000, reward: 17.300000, loss: 0.000326, epsilon: 0.050000, episode:  547\n",
            "frames: 1110000, reward: 17.300000, loss: 0.000337, epsilon: 0.050000, episode:  547\n",
            "frames: 1111000, reward: 17.300000, loss: 0.000518, epsilon: 0.050000, episode:  548\n",
            "frames: 1112000, reward: 17.300000, loss: 0.002801, epsilon: 0.050000, episode:  548\n",
            "frames: 1113000, reward: 17.300000, loss: 0.000656, epsilon: 0.050000, episode:  548\n",
            "frames: 1114000, reward: 16.900000, loss: 0.000467, epsilon: 0.050000, episode:  549\n",
            "frames: 1115000, reward: 16.900000, loss: 0.000581, epsilon: 0.050000, episode:  549\n",
            "frames: 1116000, reward: 16.900000, loss: 0.000455, epsilon: 0.050000, episode:  549\n",
            "frames: 1117000, reward: 15.700000, loss: 0.000243, epsilon: 0.050000, episode:  550\n",
            "frames: 1118000, reward: 15.700000, loss: 0.000281, epsilon: 0.050000, episode:  550\n",
            "frames: 1119000, reward: 15.100000, loss: 0.003104, epsilon: 0.050000, episode:  551\n",
            "frames: 1120000, reward: 15.100000, loss: 0.000378, epsilon: 0.050000, episode:  551\n",
            "frames: 1121000, reward: 15.500000, loss: 0.000480, epsilon: 0.050000, episode:  552\n",
            "frames: 1122000, reward: 15.500000, loss: 0.000474, epsilon: 0.050000, episode:  552\n",
            "frames: 1123000, reward: 15.800000, loss: 0.000849, epsilon: 0.050000, episode:  553\n",
            "frames: 1124000, reward: 15.800000, loss: 0.000291, epsilon: 0.050000, episode:  553\n",
            "frames: 1125000, reward: 15.800000, loss: 0.000584, epsilon: 0.050000, episode:  553\n",
            "frames: 1126000, reward: 15.400000, loss: 0.000315, epsilon: 0.050000, episode:  554\n",
            "frames: 1127000, reward: 15.400000, loss: 0.000532, epsilon: 0.050000, episode:  554\n",
            "frames: 1128000, reward: 14.600000, loss: 0.000834, epsilon: 0.050000, episode:  555\n",
            "frames: 1129000, reward: 14.600000, loss: 0.001089, epsilon: 0.050000, episode:  555\n",
            "frames: 1130000, reward: 14.300000, loss: 0.000228, epsilon: 0.050000, episode:  556\n",
            "frames: 1131000, reward: 14.300000, loss: 0.000259, epsilon: 0.050000, episode:  556\n",
            "frames: 1132000, reward: 14.500000, loss: 0.001837, epsilon: 0.050000, episode:  557\n",
            "frames: 1133000, reward: 14.500000, loss: 0.004477, epsilon: 0.050000, episode:  557\n",
            "frames: 1134000, reward: 14.700000, loss: 0.000487, epsilon: 0.050000, episode:  558\n",
            "frames: 1135000, reward: 14.700000, loss: 0.000475, epsilon: 0.050000, episode:  558\n",
            "frames: 1136000, reward: 14.700000, loss: 0.000670, epsilon: 0.050000, episode:  558\n",
            "frames: 1137000, reward: 15.500000, loss: 0.000638, epsilon: 0.050000, episode:  559\n",
            "frames: 1138000, reward: 15.500000, loss: 0.000693, epsilon: 0.050000, episode:  559\n",
            "frames: 1139000, reward: 16.200000, loss: 0.000481, epsilon: 0.050000, episode:  560\n",
            "frames: 1140000, reward: 16.200000, loss: 0.000940, epsilon: 0.050000, episode:  560\n",
            "frames: 1141000, reward: 16.900000, loss: 0.000846, epsilon: 0.050000, episode:  561\n",
            "frames: 1142000, reward: 16.900000, loss: 0.001365, epsilon: 0.050000, episode:  561\n",
            "frames: 1143000, reward: 16.700000, loss: 0.002733, epsilon: 0.050000, episode:  562\n",
            "frames: 1144000, reward: 16.700000, loss: 0.000656, epsilon: 0.050000, episode:  562\n",
            "frames: 1145000, reward: 16.700000, loss: 0.000608, epsilon: 0.050000, episode:  562\n",
            "frames: 1146000, reward: 16.200000, loss: 0.001125, epsilon: 0.050000, episode:  563\n",
            "frames: 1147000, reward: 16.800000, loss: 0.001045, epsilon: 0.050000, episode:  564\n",
            "frames: 1148000, reward: 16.800000, loss: 0.000626, epsilon: 0.050000, episode:  564\n",
            "frames: 1149000, reward: 17.200000, loss: 0.000617, epsilon: 0.050000, episode:  565\n",
            "frames: 1150000, reward: 17.200000, loss: 0.000298, epsilon: 0.050000, episode:  565\n",
            "frames: 1151000, reward: 17.000000, loss: 0.001134, epsilon: 0.050000, episode:  566\n",
            "frames: 1152000, reward: 17.000000, loss: 0.000475, epsilon: 0.050000, episode:  566\n",
            "frames: 1153000, reward: 16.700000, loss: 0.000473, epsilon: 0.050000, episode:  567\n",
            "frames: 1154000, reward: 16.700000, loss: 0.000229, epsilon: 0.050000, episode:  567\n",
            "frames: 1155000, reward: 16.600000, loss: 0.000964, epsilon: 0.050000, episode:  568\n",
            "frames: 1156000, reward: 16.600000, loss: 0.001169, epsilon: 0.050000, episode:  568\n",
            "frames: 1157000, reward: 16.900000, loss: 0.000471, epsilon: 0.050000, episode:  569\n",
            "frames: 1158000, reward: 16.900000, loss: 0.000561, epsilon: 0.050000, episode:  569\n",
            "frames: 1159000, reward: 16.900000, loss: 0.000427, epsilon: 0.050000, episode:  569\n",
            "frames: 1160000, reward: 17.300000, loss: 0.000324, epsilon: 0.050000, episode:  570\n",
            "frames: 1161000, reward: 17.300000, loss: 0.001308, epsilon: 0.050000, episode:  570\n",
            "frames: 1162000, reward: 17.200000, loss: 0.000340, epsilon: 0.050000, episode:  571\n",
            "frames: 1163000, reward: 17.200000, loss: 0.000221, epsilon: 0.050000, episode:  571\n",
            "frames: 1164000, reward: 17.300000, loss: 0.000526, epsilon: 0.050000, episode:  572\n",
            "frames: 1165000, reward: 17.300000, loss: 0.000384, epsilon: 0.050000, episode:  572\n",
            "frames: 1166000, reward: 17.900000, loss: 0.000633, epsilon: 0.050000, episode:  573\n",
            "frames: 1167000, reward: 17.900000, loss: 0.000245, epsilon: 0.050000, episode:  573\n",
            "frames: 1168000, reward: 17.400000, loss: 0.000903, epsilon: 0.050000, episode:  574\n",
            "frames: 1169000, reward: 17.400000, loss: 0.000544, epsilon: 0.050000, episode:  574\n",
            "frames: 1170000, reward: 17.200000, loss: 0.001559, epsilon: 0.050000, episode:  575\n",
            "frames: 1171000, reward: 17.200000, loss: 0.000517, epsilon: 0.050000, episode:  575\n",
            "frames: 1172000, reward: 17.200000, loss: 0.001129, epsilon: 0.050000, episode:  575\n",
            "frames: 1173000, reward: 17.400000, loss: 0.001446, epsilon: 0.050000, episode:  576\n",
            "frames: 1174000, reward: 17.400000, loss: 0.000438, epsilon: 0.050000, episode:  576\n",
            "frames: 1175000, reward: 17.200000, loss: 0.002741, epsilon: 0.050000, episode:  577\n",
            "frames: 1176000, reward: 17.200000, loss: 0.000343, epsilon: 0.050000, episode:  577\n",
            "frames: 1177000, reward: 17.200000, loss: 0.000293, epsilon: 0.050000, episode:  577\n",
            "frames: 1178000, reward: 16.700000, loss: 0.000287, epsilon: 0.050000, episode:  578\n",
            "frames: 1179000, reward: 16.700000, loss: 0.000445, epsilon: 0.050000, episode:  578\n",
            "frames: 1180000, reward: 16.700000, loss: 0.000791, epsilon: 0.050000, episode:  578\n",
            "frames: 1181000, reward: 16.100000, loss: 0.000546, epsilon: 0.050000, episode:  579\n",
            "frames: 1182000, reward: 16.100000, loss: 0.000573, epsilon: 0.050000, episode:  579\n",
            "frames: 1183000, reward: 15.800000, loss: 0.000516, epsilon: 0.050000, episode:  580\n",
            "frames: 1184000, reward: 15.800000, loss: 0.000977, epsilon: 0.050000, episode:  580\n",
            "frames: 1185000, reward: 15.800000, loss: 0.003997, epsilon: 0.050000, episode:  580\n",
            "frames: 1186000, reward: 15.500000, loss: 0.000552, epsilon: 0.050000, episode:  581\n",
            "frames: 1187000, reward: 15.500000, loss: 0.000266, epsilon: 0.050000, episode:  581\n",
            "frames: 1188000, reward: 15.000000, loss: 0.000362, epsilon: 0.050000, episode:  582\n",
            "frames: 1189000, reward: 15.000000, loss: 0.002102, epsilon: 0.050000, episode:  582\n",
            "frames: 1190000, reward: 15.000000, loss: 0.000449, epsilon: 0.050000, episode:  582\n",
            "frames: 1191000, reward: 14.600000, loss: 0.000453, epsilon: 0.050000, episode:  583\n",
            "frames: 1192000, reward: 14.600000, loss: 0.000455, epsilon: 0.050000, episode:  583\n",
            "frames: 1193000, reward: 15.100000, loss: 0.000386, epsilon: 0.050000, episode:  584\n",
            "frames: 1194000, reward: 15.100000, loss: 0.000339, epsilon: 0.050000, episode:  584\n",
            "frames: 1195000, reward: 15.100000, loss: 0.001384, epsilon: 0.050000, episode:  584\n",
            "frames: 1196000, reward: 15.300000, loss: 0.000401, epsilon: 0.050000, episode:  585\n",
            "frames: 1197000, reward: 15.300000, loss: 0.000238, epsilon: 0.050000, episode:  585\n",
            "frames: 1198000, reward: 15.200000, loss: 0.000377, epsilon: 0.050000, episode:  586\n",
            "frames: 1199000, reward: 15.200000, loss: 0.000288, epsilon: 0.050000, episode:  586\n",
            "frames: 1200000, reward: 15.600000, loss: 0.000459, epsilon: 0.050000, episode:  587\n",
            "frames: 1201000, reward: 15.600000, loss: 0.000229, epsilon: 0.050000, episode:  587\n",
            "frames: 1202000, reward: 15.600000, loss: 0.000288, epsilon: 0.050000, episode:  587\n",
            "frames: 1203000, reward: 15.600000, loss: 0.000355, epsilon: 0.050000, episode:  588\n",
            "frames: 1204000, reward: 15.600000, loss: 0.000555, epsilon: 0.050000, episode:  588\n",
            "frames: 1205000, reward: 15.600000, loss: 0.000331, epsilon: 0.050000, episode:  589\n",
            "frames: 1206000, reward: 16.100000, loss: 0.000863, epsilon: 0.050000, episode:  590\n",
            "frames: 1207000, reward: 16.100000, loss: 0.000913, epsilon: 0.050000, episode:  590\n",
            "frames: 1208000, reward: 16.300000, loss: 0.000498, epsilon: 0.050000, episode:  591\n",
            "frames: 1209000, reward: 16.300000, loss: 0.000193, epsilon: 0.050000, episode:  591\n",
            "frames: 1210000, reward: 16.900000, loss: 0.000775, epsilon: 0.050000, episode:  592\n",
            "frames: 1211000, reward: 16.900000, loss: 0.000303, epsilon: 0.050000, episode:  592\n",
            "frames: 1212000, reward: 17.000000, loss: 0.001366, epsilon: 0.050000, episode:  593\n",
            "frames: 1213000, reward: 17.000000, loss: 0.000596, epsilon: 0.050000, episode:  593\n",
            "frames: 1214000, reward: 17.000000, loss: 0.000513, epsilon: 0.050000, episode:  593\n",
            "frames: 1215000, reward: 17.000000, loss: 0.000483, epsilon: 0.050000, episode:  593\n",
            "frames: 1216000, reward: 15.300000, loss: 0.000270, epsilon: 0.050000, episode:  594\n",
            "frames: 1217000, reward: 15.300000, loss: 0.000290, epsilon: 0.050000, episode:  594\n",
            "frames: 1218000, reward: 15.200000, loss: 0.001063, epsilon: 0.050000, episode:  595\n",
            "frames: 1219000, reward: 15.200000, loss: 0.000721, epsilon: 0.050000, episode:  595\n",
            "frames: 1220000, reward: 15.200000, loss: 0.000398, epsilon: 0.050000, episode:  595\n",
            "frames: 1221000, reward: 15.100000, loss: 0.000518, epsilon: 0.050000, episode:  596\n",
            "frames: 1222000, reward: 15.100000, loss: 0.001375, epsilon: 0.050000, episode:  596\n",
            "frames: 1223000, reward: 15.000000, loss: 0.000835, epsilon: 0.050000, episode:  597\n",
            "frames: 1224000, reward: 15.000000, loss: 0.000595, epsilon: 0.050000, episode:  597\n",
            "frames: 1225000, reward: 15.300000, loss: 0.000535, epsilon: 0.050000, episode:  598\n",
            "frames: 1226000, reward: 15.300000, loss: 0.001083, epsilon: 0.050000, episode:  598\n",
            "frames: 1227000, reward: 15.600000, loss: 0.000510, epsilon: 0.050000, episode:  599\n",
            "frames: 1228000, reward: 15.600000, loss: 0.000610, epsilon: 0.050000, episode:  599\n",
            "frames: 1229000, reward: 15.100000, loss: 0.000900, epsilon: 0.050000, episode:  600\n",
            "frames: 1230000, reward: 15.300000, loss: 0.000410, epsilon: 0.050000, episode:  601\n",
            "frames: 1231000, reward: 15.300000, loss: 0.000101, epsilon: 0.050000, episode:  601\n",
            "frames: 1232000, reward: 15.300000, loss: 0.000354, epsilon: 0.050000, episode:  601\n",
            "frames: 1233000, reward: 15.000000, loss: 0.000471, epsilon: 0.050000, episode:  602\n",
            "frames: 1234000, reward: 15.000000, loss: 0.001010, epsilon: 0.050000, episode:  602\n",
            "frames: 1235000, reward: 14.600000, loss: 0.000345, epsilon: 0.050000, episode:  603\n",
            "frames: 1236000, reward: 14.600000, loss: 0.001325, epsilon: 0.050000, episode:  603\n",
            "frames: 1237000, reward: 16.100000, loss: 0.000657, epsilon: 0.050000, episode:  604\n",
            "frames: 1238000, reward: 16.100000, loss: 0.000668, epsilon: 0.050000, episode:  604\n",
            "frames: 1239000, reward: 16.300000, loss: 0.000856, epsilon: 0.050000, episode:  605\n",
            "frames: 1240000, reward: 16.300000, loss: 0.001201, epsilon: 0.050000, episode:  605\n",
            "frames: 1241000, reward: 16.600000, loss: 0.000313, epsilon: 0.050000, episode:  606\n",
            "frames: 1242000, reward: 16.600000, loss: 0.000362, epsilon: 0.050000, episode:  606\n",
            "frames: 1243000, reward: 16.600000, loss: 0.000676, epsilon: 0.050000, episode:  607\n",
            "frames: 1244000, reward: 16.600000, loss: 0.004092, epsilon: 0.050000, episode:  607\n",
            "frames: 1245000, reward: 16.600000, loss: 0.000389, epsilon: 0.050000, episode:  607\n",
            "frames: 1246000, reward: 16.700000, loss: 0.000280, epsilon: 0.050000, episode:  608\n",
            "frames: 1247000, reward: 16.700000, loss: 0.000366, epsilon: 0.050000, episode:  608\n",
            "frames: 1248000, reward: 16.700000, loss: 0.000333, epsilon: 0.050000, episode:  608\n",
            "frames: 1249000, reward: 15.600000, loss: 0.000740, epsilon: 0.050000, episode:  609\n",
            "frames: 1250000, reward: 15.600000, loss: 0.000668, epsilon: 0.050000, episode:  609\n",
            "frames: 1251000, reward: 15.600000, loss: 0.000706, epsilon: 0.050000, episode:  610\n",
            "frames: 1252000, reward: 15.600000, loss: 0.000183, epsilon: 0.050000, episode:  610\n",
            "frames: 1253000, reward: 15.400000, loss: 0.001219, epsilon: 0.050000, episode:  611\n",
            "frames: 1254000, reward: 15.400000, loss: 0.000395, epsilon: 0.050000, episode:  611\n",
            "frames: 1255000, reward: 15.300000, loss: 0.000860, epsilon: 0.050000, episode:  612\n",
            "frames: 1256000, reward: 15.300000, loss: 0.000572, epsilon: 0.050000, episode:  612\n",
            "frames: 1257000, reward: 15.700000, loss: 0.000631, epsilon: 0.050000, episode:  613\n",
            "frames: 1258000, reward: 15.700000, loss: 0.000257, epsilon: 0.050000, episode:  613\n",
            "frames: 1259000, reward: 15.800000, loss: 0.000299, epsilon: 0.050000, episode:  614\n",
            "frames: 1260000, reward: 15.800000, loss: 0.000493, epsilon: 0.050000, episode:  614\n",
            "frames: 1261000, reward: 16.200000, loss: 0.001474, epsilon: 0.050000, episode:  615\n",
            "frames: 1262000, reward: 16.200000, loss: 0.002094, epsilon: 0.050000, episode:  615\n",
            "frames: 1263000, reward: 16.300000, loss: 0.000661, epsilon: 0.050000, episode:  616\n",
            "frames: 1264000, reward: 16.300000, loss: 0.000729, epsilon: 0.050000, episode:  616\n",
            "frames: 1265000, reward: 16.200000, loss: 0.001524, epsilon: 0.050000, episode:  617\n",
            "frames: 1266000, reward: 16.200000, loss: 0.000837, epsilon: 0.050000, episode:  617\n",
            "frames: 1267000, reward: 16.200000, loss: 0.000326, epsilon: 0.050000, episode:  617\n",
            "frames: 1268000, reward: 16.400000, loss: 0.000415, epsilon: 0.050000, episode:  618\n",
            "frames: 1269000, reward: 16.400000, loss: 0.000416, epsilon: 0.050000, episode:  618\n",
            "frames: 1270000, reward: 17.800000, loss: 0.000457, epsilon: 0.050000, episode:  619\n",
            "frames: 1271000, reward: 18.200000, loss: 0.000390, epsilon: 0.050000, episode:  620\n",
            "frames: 1272000, reward: 18.200000, loss: 0.000460, epsilon: 0.050000, episode:  620\n",
            "frames: 1273000, reward: 18.000000, loss: 0.000559, epsilon: 0.050000, episode:  621\n",
            "frames: 1274000, reward: 18.000000, loss: 0.000438, epsilon: 0.050000, episode:  621\n",
            "frames: 1275000, reward: 18.000000, loss: 0.000877, epsilon: 0.050000, episode:  621\n",
            "frames: 1276000, reward: 17.700000, loss: 0.000400, epsilon: 0.050000, episode:  622\n",
            "frames: 1277000, reward: 17.700000, loss: 0.000296, epsilon: 0.050000, episode:  622\n",
            "frames: 1278000, reward: 17.700000, loss: 0.000466, epsilon: 0.050000, episode:  623\n",
            "frames: 1279000, reward: 17.700000, loss: 0.000418, epsilon: 0.050000, episode:  623\n",
            "frames: 1280000, reward: 17.100000, loss: 0.000428, epsilon: 0.050000, episode:  624\n",
            "frames: 1281000, reward: 17.100000, loss: 0.000208, epsilon: 0.050000, episode:  624\n",
            "frames: 1282000, reward: 16.700000, loss: 0.000321, epsilon: 0.050000, episode:  625\n",
            "frames: 1283000, reward: 16.700000, loss: 0.000268, epsilon: 0.050000, episode:  625\n",
            "frames: 1284000, reward: 16.600000, loss: 0.000603, epsilon: 0.050000, episode:  626\n",
            "frames: 1285000, reward: 16.600000, loss: 0.000301, epsilon: 0.050000, episode:  626\n",
            "frames: 1286000, reward: 17.000000, loss: 0.000566, epsilon: 0.050000, episode:  627\n",
            "frames: 1287000, reward: 17.000000, loss: 0.000928, epsilon: 0.050000, episode:  627\n",
            "frames: 1288000, reward: 16.900000, loss: 0.000488, epsilon: 0.050000, episode:  628\n",
            "frames: 1289000, reward: 16.900000, loss: 0.000498, epsilon: 0.050000, episode:  628\n",
            "frames: 1290000, reward: 16.900000, loss: 0.000949, epsilon: 0.050000, episode:  628\n",
            "frames: 1291000, reward: 16.600000, loss: 0.001714, epsilon: 0.050000, episode:  629\n",
            "frames: 1292000, reward: 16.600000, loss: 0.000255, epsilon: 0.050000, episode:  629\n",
            "frames: 1293000, reward: 16.400000, loss: 0.000372, epsilon: 0.050000, episode:  630\n",
            "frames: 1294000, reward: 16.400000, loss: 0.000906, epsilon: 0.050000, episode:  630\n",
            "frames: 1295000, reward: 16.400000, loss: 0.001091, epsilon: 0.050000, episode:  631\n",
            "frames: 1296000, reward: 16.400000, loss: 0.000501, epsilon: 0.050000, episode:  631\n",
            "frames: 1297000, reward: 16.900000, loss: 0.001141, epsilon: 0.050000, episode:  632\n",
            "frames: 1298000, reward: 16.900000, loss: 0.001221, epsilon: 0.050000, episode:  632\n",
            "frames: 1299000, reward: 16.900000, loss: 0.000134, epsilon: 0.050000, episode:  633\n",
            "frames: 1300000, reward: 16.900000, loss: 0.000482, epsilon: 0.050000, episode:  633\n",
            "frames: 1301000, reward: 17.300000, loss: 0.000221, epsilon: 0.050000, episode:  634\n",
            "frames: 1302000, reward: 17.300000, loss: 0.000477, epsilon: 0.050000, episode:  634\n",
            "frames: 1303000, reward: 17.600000, loss: 0.000306, epsilon: 0.050000, episode:  635\n",
            "frames: 1304000, reward: 17.600000, loss: 0.000345, epsilon: 0.050000, episode:  635\n",
            "frames: 1305000, reward: 17.700000, loss: 0.000262, epsilon: 0.050000, episode:  636\n",
            "frames: 1306000, reward: 17.700000, loss: 0.000419, epsilon: 0.050000, episode:  636\n",
            "frames: 1307000, reward: 17.700000, loss: 0.001023, epsilon: 0.050000, episode:  636\n",
            "frames: 1308000, reward: 17.400000, loss: 0.000340, epsilon: 0.050000, episode:  637\n",
            "frames: 1309000, reward: 17.400000, loss: 0.001562, epsilon: 0.050000, episode:  637\n",
            "frames: 1310000, reward: 17.400000, loss: 0.000719, epsilon: 0.050000, episode:  638\n",
            "frames: 1311000, reward: 17.400000, loss: 0.000236, epsilon: 0.050000, episode:  638\n",
            "frames: 1312000, reward: 17.600000, loss: 0.000316, epsilon: 0.050000, episode:  639\n",
            "frames: 1313000, reward: 17.600000, loss: 0.000298, epsilon: 0.050000, episode:  639\n",
            "frames: 1314000, reward: 17.600000, loss: 0.000420, epsilon: 0.050000, episode:  640\n",
            "frames: 1315000, reward: 17.600000, loss: 0.000290, epsilon: 0.050000, episode:  640\n",
            "frames: 1316000, reward: 17.800000, loss: 0.000292, epsilon: 0.050000, episode:  641\n",
            "frames: 1317000, reward: 17.800000, loss: 0.000203, epsilon: 0.050000, episode:  641\n",
            "frames: 1318000, reward: 17.800000, loss: 0.000185, epsilon: 0.050000, episode:  642\n",
            "frames: 1319000, reward: 17.800000, loss: 0.000326, epsilon: 0.050000, episode:  642\n",
            "frames: 1320000, reward: 18.100000, loss: 0.000529, epsilon: 0.050000, episode:  643\n",
            "frames: 1321000, reward: 18.100000, loss: 0.000758, epsilon: 0.050000, episode:  643\n",
            "frames: 1322000, reward: 18.300000, loss: 0.000265, epsilon: 0.050000, episode:  644\n",
            "frames: 1323000, reward: 18.300000, loss: 0.000343, epsilon: 0.050000, episode:  644\n",
            "frames: 1324000, reward: 18.100000, loss: 0.000500, epsilon: 0.050000, episode:  645\n",
            "frames: 1325000, reward: 18.100000, loss: 0.000307, epsilon: 0.050000, episode:  645\n",
            "frames: 1326000, reward: 18.200000, loss: 0.000131, epsilon: 0.050000, episode:  646\n",
            "frames: 1327000, reward: 18.200000, loss: 0.002185, epsilon: 0.050000, episode:  646\n",
            "frames: 1328000, reward: 18.500000, loss: 0.000359, epsilon: 0.050000, episode:  647\n",
            "frames: 1329000, reward: 18.500000, loss: 0.000998, epsilon: 0.050000, episode:  647\n",
            "frames: 1330000, reward: 18.800000, loss: 0.000149, epsilon: 0.050000, episode:  648\n",
            "frames: 1331000, reward: 18.800000, loss: 0.000598, epsilon: 0.050000, episode:  648\n",
            "frames: 1332000, reward: 18.600000, loss: 0.000362, epsilon: 0.050000, episode:  649\n",
            "frames: 1333000, reward: 18.600000, loss: 0.000313, epsilon: 0.050000, episode:  649\n",
            "frames: 1334000, reward: 18.600000, loss: 0.000258, epsilon: 0.050000, episode:  649\n",
            "frames: 1335000, reward: 18.400000, loss: 0.001134, epsilon: 0.050000, episode:  650\n",
            "frames: 1336000, reward: 18.400000, loss: 0.000392, epsilon: 0.050000, episode:  650\n",
            "frames: 1337000, reward: 18.100000, loss: 0.002748, epsilon: 0.050000, episode:  651\n",
            "frames: 1338000, reward: 18.100000, loss: 0.001078, epsilon: 0.050000, episode:  651\n",
            "frames: 1339000, reward: 17.900000, loss: 0.000308, epsilon: 0.050000, episode:  652\n",
            "frames: 1340000, reward: 17.900000, loss: 0.000619, epsilon: 0.050000, episode:  652\n",
            "frames: 1341000, reward: 17.600000, loss: 0.000419, epsilon: 0.050000, episode:  653\n",
            "frames: 1342000, reward: 17.600000, loss: 0.001425, epsilon: 0.050000, episode:  653\n",
            "frames: 1343000, reward: 17.600000, loss: 0.000517, epsilon: 0.050000, episode:  653\n",
            "frames: 1344000, reward: 16.100000, loss: 0.000360, epsilon: 0.050000, episode:  654\n",
            "frames: 1345000, reward: 16.100000, loss: 0.001223, epsilon: 0.050000, episode:  654\n",
            "frames: 1346000, reward: 16.100000, loss: 0.000366, epsilon: 0.050000, episode:  655\n",
            "frames: 1347000, reward: 16.100000, loss: 0.000221, epsilon: 0.050000, episode:  655\n",
            "frames: 1348000, reward: 15.600000, loss: 0.000381, epsilon: 0.050000, episode:  656\n",
            "frames: 1349000, reward: 15.600000, loss: 0.000319, epsilon: 0.050000, episode:  656\n",
            "frames: 1350000, reward: 15.300000, loss: 0.000719, epsilon: 0.050000, episode:  657\n",
            "frames: 1351000, reward: 15.300000, loss: 0.000370, epsilon: 0.050000, episode:  657\n",
            "frames: 1352000, reward: 15.300000, loss: 0.000761, epsilon: 0.050000, episode:  657\n",
            "frames: 1353000, reward: 14.400000, loss: 0.000412, epsilon: 0.050000, episode:  658\n",
            "frames: 1354000, reward: 14.400000, loss: 0.001672, epsilon: 0.050000, episode:  658\n",
            "frames: 1355000, reward: 14.500000, loss: 0.000339, epsilon: 0.050000, episode:  659\n",
            "frames: 1356000, reward: 14.500000, loss: 0.000203, epsilon: 0.050000, episode:  659\n",
            "frames: 1357000, reward: 14.500000, loss: 0.002649, epsilon: 0.050000, episode:  659\n",
            "frames: 1358000, reward: 14.700000, loss: 0.009382, epsilon: 0.050000, episode:  660\n",
            "frames: 1359000, reward: 14.700000, loss: 0.000415, epsilon: 0.050000, episode:  660\n",
            "frames: 1360000, reward: 15.000000, loss: 0.000777, epsilon: 0.050000, episode:  661\n",
            "frames: 1361000, reward: 15.000000, loss: 0.000629, epsilon: 0.050000, episode:  661\n",
            "frames: 1362000, reward: 15.100000, loss: 0.000564, epsilon: 0.050000, episode:  662\n",
            "frames: 1363000, reward: 15.100000, loss: 0.000318, epsilon: 0.050000, episode:  662\n",
            "frames: 1364000, reward: 15.300000, loss: 0.000983, epsilon: 0.050000, episode:  663\n",
            "frames: 1365000, reward: 15.300000, loss: 0.000606, epsilon: 0.050000, episode:  663\n",
            "frames: 1366000, reward: 15.300000, loss: 0.000535, epsilon: 0.050000, episode:  663\n",
            "frames: 1367000, reward: 16.800000, loss: 0.000502, epsilon: 0.050000, episode:  664\n",
            "frames: 1368000, reward: 16.800000, loss: 0.000257, epsilon: 0.050000, episode:  664\n",
            "frames: 1369000, reward: 16.500000, loss: 0.000669, epsilon: 0.050000, episode:  665\n",
            "frames: 1370000, reward: 16.500000, loss: 0.000274, epsilon: 0.050000, episode:  665\n",
            "frames: 1371000, reward: 16.800000, loss: 0.000298, epsilon: 0.050000, episode:  666\n",
            "frames: 1372000, reward: 17.200000, loss: 0.000442, epsilon: 0.050000, episode:  667\n",
            "frames: 1373000, reward: 17.200000, loss: 0.000200, epsilon: 0.050000, episode:  667\n",
            "frames: 1374000, reward: 17.200000, loss: 0.000409, epsilon: 0.050000, episode:  667\n",
            "frames: 1375000, reward: 17.800000, loss: 0.000292, epsilon: 0.050000, episode:  668\n",
            "frames: 1376000, reward: 17.800000, loss: 0.002344, epsilon: 0.050000, episode:  668\n",
            "frames: 1377000, reward: 18.000000, loss: 0.000851, epsilon: 0.050000, episode:  669\n",
            "frames: 1378000, reward: 18.000000, loss: 0.000922, epsilon: 0.050000, episode:  669\n",
            "frames: 1379000, reward: 17.100000, loss: 0.000487, epsilon: 0.050000, episode:  670\n",
            "frames: 1380000, reward: 17.100000, loss: 0.000283, epsilon: 0.050000, episode:  670\n",
            "frames: 1381000, reward: 17.100000, loss: 0.004017, epsilon: 0.050000, episode:  670\n",
            "frames: 1382000, reward: 17.100000, loss: 0.000333, epsilon: 0.050000, episode:  671\n",
            "frames: 1383000, reward: 17.100000, loss: 0.000266, epsilon: 0.050000, episode:  671\n",
            "frames: 1384000, reward: 16.700000, loss: 0.000542, epsilon: 0.050000, episode:  672\n",
            "frames: 1385000, reward: 16.700000, loss: 0.000293, epsilon: 0.050000, episode:  672\n",
            "frames: 1386000, reward: 16.800000, loss: 0.000287, epsilon: 0.050000, episode:  673\n",
            "frames: 1387000, reward: 16.800000, loss: 0.002872, epsilon: 0.050000, episode:  673\n",
            "frames: 1388000, reward: 16.700000, loss: 0.000602, epsilon: 0.050000, episode:  674\n",
            "frames: 1389000, reward: 16.700000, loss: 0.000809, epsilon: 0.050000, episode:  674\n",
            "frames: 1390000, reward: 17.100000, loss: 0.001047, epsilon: 0.050000, episode:  675\n",
            "frames: 1391000, reward: 17.100000, loss: 0.000309, epsilon: 0.050000, episode:  675\n",
            "frames: 1392000, reward: 17.500000, loss: 0.000356, epsilon: 0.050000, episode:  676\n",
            "frames: 1393000, reward: 17.500000, loss: 0.000316, epsilon: 0.050000, episode:  676\n",
            "frames: 1394000, reward: 17.100000, loss: 0.000109, epsilon: 0.050000, episode:  677\n",
            "frames: 1395000, reward: 17.100000, loss: 0.002186, epsilon: 0.050000, episode:  677\n",
            "frames: 1396000, reward: 17.100000, loss: 0.000523, epsilon: 0.050000, episode:  677\n",
            "frames: 1397000, reward: 17.100000, loss: 0.000541, epsilon: 0.050000, episode:  678\n",
            "frames: 1398000, reward: 17.100000, loss: 0.000223, epsilon: 0.050000, episode:  678\n",
            "frames: 1399000, reward: 16.900000, loss: 0.000364, epsilon: 0.050000, episode:  679\n",
            "frames: 1400000, reward: 16.900000, loss: 0.000538, epsilon: 0.050000, episode:  679\n",
            "frames: 1401000, reward: 17.400000, loss: 0.000276, epsilon: 0.050000, episode:  680\n",
            "frames: 1402000, reward: 17.400000, loss: 0.000356, epsilon: 0.050000, episode:  680\n",
            "frames: 1403000, reward: 17.400000, loss: 0.000484, epsilon: 0.050000, episode:  681\n",
            "frames: 1404000, reward: 17.400000, loss: 0.000976, epsilon: 0.050000, episode:  681\n",
            "frames: 1405000, reward: 17.800000, loss: 0.000151, epsilon: 0.050000, episode:  682\n",
            "frames: 1406000, reward: 17.800000, loss: 0.000452, epsilon: 0.050000, episode:  682\n",
            "frames: 1407000, reward: 17.500000, loss: 0.000260, epsilon: 0.050000, episode:  683\n",
            "frames: 1408000, reward: 17.500000, loss: 0.000289, epsilon: 0.050000, episode:  683\n",
            "frames: 1409000, reward: 17.500000, loss: 0.000601, epsilon: 0.050000, episode:  683\n",
            "frames: 1410000, reward: 17.500000, loss: 0.000255, epsilon: 0.050000, episode:  684\n",
            "frames: 1411000, reward: 17.500000, loss: 0.000257, epsilon: 0.050000, episode:  684\n",
            "frames: 1412000, reward: 17.600000, loss: 0.000351, epsilon: 0.050000, episode:  685\n",
            "frames: 1413000, reward: 17.600000, loss: 0.000299, epsilon: 0.050000, episode:  685\n",
            "frames: 1414000, reward: 17.400000, loss: 0.000404, epsilon: 0.050000, episode:  686\n",
            "frames: 1415000, reward: 17.400000, loss: 0.000531, epsilon: 0.050000, episode:  686\n",
            "frames: 1416000, reward: 17.600000, loss: 0.000388, epsilon: 0.050000, episode:  687\n",
            "frames: 1417000, reward: 17.600000, loss: 0.000616, epsilon: 0.050000, episode:  687\n",
            "frames: 1418000, reward: 17.500000, loss: 0.001110, epsilon: 0.050000, episode:  688\n",
            "frames: 1419000, reward: 17.500000, loss: 0.000630, epsilon: 0.050000, episode:  688\n",
            "frames: 1420000, reward: 17.500000, loss: 0.001178, epsilon: 0.050000, episode:  689\n",
            "frames: 1421000, reward: 17.500000, loss: 0.000324, epsilon: 0.050000, episode:  689\n",
            "frames: 1422000, reward: 17.500000, loss: 0.000343, epsilon: 0.050000, episode:  690\n",
            "frames: 1423000, reward: 17.500000, loss: 0.005578, epsilon: 0.050000, episode:  690\n",
            "frames: 1424000, reward: 17.500000, loss: 0.000938, epsilon: 0.050000, episode:  690\n",
            "frames: 1425000, reward: 17.000000, loss: 0.000273, epsilon: 0.050000, episode:  691\n",
            "frames: 1426000, reward: 17.400000, loss: 0.000131, epsilon: 0.050000, episode:  692\n",
            "frames: 1427000, reward: 17.400000, loss: 0.000219, epsilon: 0.050000, episode:  692\n",
            "frames: 1428000, reward: 17.700000, loss: 0.000320, epsilon: 0.050000, episode:  693\n",
            "frames: 1429000, reward: 17.700000, loss: 0.000820, epsilon: 0.050000, episode:  693\n",
            "frames: 1430000, reward: 17.700000, loss: 0.000570, epsilon: 0.050000, episode:  693\n",
            "frames: 1431000, reward: 17.200000, loss: 0.000309, epsilon: 0.050000, episode:  694\n",
            "frames: 1432000, reward: 17.200000, loss: 0.000232, epsilon: 0.050000, episode:  694\n",
            "frames: 1433000, reward: 16.700000, loss: 0.000184, epsilon: 0.050000, episode:  695\n",
            "frames: 1434000, reward: 16.700000, loss: 0.000575, epsilon: 0.050000, episode:  695\n",
            "frames: 1435000, reward: 16.600000, loss: 0.002073, epsilon: 0.050000, episode:  696\n",
            "frames: 1436000, reward: 16.600000, loss: 0.000548, epsilon: 0.050000, episode:  696\n",
            "frames: 1437000, reward: 16.600000, loss: 0.000459, epsilon: 0.050000, episode:  696\n",
            "frames: 1438000, reward: 16.400000, loss: 0.000196, epsilon: 0.050000, episode:  697\n",
            "frames: 1439000, reward: 16.400000, loss: 0.000615, epsilon: 0.050000, episode:  697\n",
            "frames: 1440000, reward: 16.500000, loss: 0.000895, epsilon: 0.050000, episode:  698\n",
            "frames: 1441000, reward: 16.500000, loss: 0.000276, epsilon: 0.050000, episode:  698\n",
            "frames: 1442000, reward: 16.400000, loss: 0.000666, epsilon: 0.050000, episode:  699\n",
            "frames: 1443000, reward: 16.400000, loss: 0.001178, epsilon: 0.050000, episode:  699\n",
            "frames: 1444000, reward: 16.400000, loss: 0.000242, epsilon: 0.050000, episode:  700\n",
            "frames: 1445000, reward: 16.400000, loss: 0.000305, epsilon: 0.050000, episode:  700\n",
            "frames: 1446000, reward: 17.000000, loss: 0.000663, epsilon: 0.050000, episode:  701\n",
            "frames: 1447000, reward: 17.000000, loss: 0.000641, epsilon: 0.050000, episode:  701\n",
            "frames: 1448000, reward: 16.700000, loss: 0.000450, epsilon: 0.050000, episode:  702\n",
            "frames: 1449000, reward: 16.700000, loss: 0.003164, epsilon: 0.050000, episode:  702\n",
            "frames: 1450000, reward: 16.600000, loss: 0.000219, epsilon: 0.050000, episode:  703\n",
            "frames: 1451000, reward: 16.600000, loss: 0.000481, epsilon: 0.050000, episode:  703\n",
            "frames: 1452000, reward: 17.100000, loss: 0.000515, epsilon: 0.050000, episode:  704\n",
            "frames: 1453000, reward: 17.100000, loss: 0.000311, epsilon: 0.050000, episode:  704\n",
            "frames: 1454000, reward: 17.500000, loss: 0.000329, epsilon: 0.050000, episode:  705\n",
            "frames: 1455000, reward: 17.500000, loss: 0.001857, epsilon: 0.050000, episode:  705\n",
            "frames: 1456000, reward: 17.500000, loss: 0.000459, epsilon: 0.050000, episode:  705\n",
            "frames: 1457000, reward: 16.800000, loss: 0.001303, epsilon: 0.050000, episode:  706\n",
            "frames: 1458000, reward: 16.800000, loss: 0.000507, epsilon: 0.050000, episode:  706\n",
            "frames: 1459000, reward: 16.900000, loss: 0.000307, epsilon: 0.050000, episode:  707\n",
            "frames: 1460000, reward: 16.900000, loss: 0.000419, epsilon: 0.050000, episode:  707\n",
            "frames: 1461000, reward: 16.300000, loss: 0.000384, epsilon: 0.050000, episode:  708\n",
            "frames: 1462000, reward: 16.300000, loss: 0.000709, epsilon: 0.050000, episode:  708\n",
            "frames: 1463000, reward: 16.300000, loss: 0.000325, epsilon: 0.050000, episode:  708\n",
            "frames: 1464000, reward: 16.200000, loss: 0.000118, epsilon: 0.050000, episode:  709\n",
            "frames: 1465000, reward: 16.200000, loss: 0.000513, epsilon: 0.050000, episode:  709\n",
            "frames: 1466000, reward: 16.700000, loss: 0.000385, epsilon: 0.050000, episode:  710\n",
            "frames: 1467000, reward: 16.700000, loss: 0.000544, epsilon: 0.050000, episode:  711\n",
            "frames: 1468000, reward: 16.700000, loss: 0.000125, epsilon: 0.050000, episode:  711\n",
            "frames: 1469000, reward: 16.700000, loss: 0.000123, epsilon: 0.050000, episode:  711\n",
            "frames: 1470000, reward: 16.700000, loss: 0.000112, epsilon: 0.050000, episode:  712\n",
            "frames: 1471000, reward: 16.700000, loss: 0.000292, epsilon: 0.050000, episode:  712\n",
            "frames: 1472000, reward: 16.600000, loss: 0.000353, epsilon: 0.050000, episode:  713\n",
            "frames: 1473000, reward: 16.600000, loss: 0.000280, epsilon: 0.050000, episode:  713\n",
            "frames: 1474000, reward: 16.600000, loss: 0.000668, epsilon: 0.050000, episode:  714\n",
            "frames: 1475000, reward: 16.600000, loss: 0.000237, epsilon: 0.050000, episode:  714\n",
            "frames: 1476000, reward: 16.500000, loss: 0.000213, epsilon: 0.050000, episode:  715\n",
            "frames: 1477000, reward: 16.500000, loss: 0.000185, epsilon: 0.050000, episode:  715\n",
            "frames: 1478000, reward: 17.300000, loss: 0.000196, epsilon: 0.050000, episode:  716\n",
            "frames: 1479000, reward: 17.300000, loss: 0.000559, epsilon: 0.050000, episode:  716\n",
            "frames: 1480000, reward: 17.600000, loss: 0.000349, epsilon: 0.050000, episode:  717\n",
            "frames: 1481000, reward: 17.600000, loss: 0.000933, epsilon: 0.050000, episode:  717\n",
            "frames: 1482000, reward: 18.200000, loss: 0.000522, epsilon: 0.050000, episode:  718\n",
            "frames: 1483000, reward: 18.200000, loss: 0.000420, epsilon: 0.050000, episode:  718\n",
            "frames: 1484000, reward: 18.200000, loss: 0.000355, epsilon: 0.050000, episode:  719\n",
            "frames: 1485000, reward: 18.200000, loss: 0.004823, epsilon: 0.050000, episode:  719\n",
            "frames: 1486000, reward: 18.200000, loss: 0.000370, epsilon: 0.050000, episode:  719\n",
            "frames: 1487000, reward: 17.600000, loss: 0.000685, epsilon: 0.050000, episode:  720\n",
            "frames: 1488000, reward: 17.600000, loss: 0.001302, epsilon: 0.050000, episode:  720\n",
            "frames: 1489000, reward: 17.400000, loss: 0.000609, epsilon: 0.050000, episode:  721\n",
            "frames: 1490000, reward: 17.400000, loss: 0.000503, epsilon: 0.050000, episode:  721\n",
            "frames: 1491000, reward: 17.300000, loss: 0.000458, epsilon: 0.050000, episode:  722\n",
            "frames: 1492000, reward: 17.300000, loss: 0.000256, epsilon: 0.050000, episode:  722\n",
            "frames: 1493000, reward: 17.300000, loss: 0.000229, epsilon: 0.050000, episode:  722\n",
            "frames: 1494000, reward: 17.200000, loss: 0.000168, epsilon: 0.050000, episode:  723\n",
            "frames: 1495000, reward: 17.300000, loss: 0.000749, epsilon: 0.050000, episode:  724\n",
            "frames: 1496000, reward: 17.300000, loss: 0.001457, epsilon: 0.050000, episode:  724\n",
            "frames: 1497000, reward: 17.300000, loss: 0.000378, epsilon: 0.050000, episode:  725\n",
            "frames: 1498000, reward: 17.300000, loss: 0.000319, epsilon: 0.050000, episode:  725\n",
            "frames: 1499000, reward: 17.300000, loss: 0.002412, epsilon: 0.050000, episode:  725\n",
            "frames: 1500000, reward: 16.600000, loss: 0.000272, epsilon: 0.050000, episode:  726\n",
            "frames: 1501000, reward: 16.600000, loss: 0.000406, epsilon: 0.050000, episode:  726\n",
            "frames: 1502000, reward: 16.100000, loss: 0.000458, epsilon: 0.050000, episode:  727\n",
            "frames: 1503000, reward: 16.100000, loss: 0.000152, epsilon: 0.050000, episode:  727\n",
            "frames: 1504000, reward: 16.000000, loss: 0.000222, epsilon: 0.050000, episode:  728\n",
            "frames: 1505000, reward: 16.000000, loss: 0.000318, epsilon: 0.050000, episode:  728\n",
            "frames: 1506000, reward: 16.400000, loss: 0.000236, epsilon: 0.050000, episode:  729\n",
            "frames: 1507000, reward: 16.400000, loss: 0.000360, epsilon: 0.050000, episode:  729\n",
            "frames: 1508000, reward: 16.900000, loss: 0.000204, epsilon: 0.050000, episode:  730\n",
            "frames: 1509000, reward: 16.900000, loss: 0.000489, epsilon: 0.050000, episode:  730\n",
            "frames: 1510000, reward: 16.900000, loss: 0.000152, epsilon: 0.050000, episode:  730\n",
            "frames: 1511000, reward: 16.500000, loss: 0.000425, epsilon: 0.050000, episode:  731\n",
            "frames: 1512000, reward: 16.900000, loss: 0.000403, epsilon: 0.050000, episode:  732\n",
            "frames: 1513000, reward: 16.900000, loss: 0.000654, epsilon: 0.050000, episode:  732\n",
            "frames: 1514000, reward: 16.900000, loss: 0.000206, epsilon: 0.050000, episode:  732\n",
            "frames: 1515000, reward: 16.800000, loss: 0.000627, epsilon: 0.050000, episode:  733\n",
            "frames: 1516000, reward: 16.800000, loss: 0.000247, epsilon: 0.050000, episode:  733\n",
            "frames: 1517000, reward: 16.500000, loss: 0.000785, epsilon: 0.050000, episode:  734\n",
            "frames: 1518000, reward: 16.500000, loss: 0.000258, epsilon: 0.050000, episode:  734\n",
            "frames: 1519000, reward: 16.500000, loss: 0.000463, epsilon: 0.050000, episode:  734\n",
            "frames: 1520000, reward: 16.300000, loss: 0.001730, epsilon: 0.050000, episode:  735\n",
            "frames: 1521000, reward: 16.300000, loss: 0.000993, epsilon: 0.050000, episode:  735\n",
            "frames: 1522000, reward: 16.800000, loss: 0.000297, epsilon: 0.050000, episode:  736\n",
            "frames: 1523000, reward: 16.800000, loss: 0.000216, epsilon: 0.050000, episode:  736\n",
            "frames: 1524000, reward: 16.900000, loss: 0.000234, epsilon: 0.050000, episode:  737\n",
            "frames: 1525000, reward: 16.900000, loss: 0.000433, epsilon: 0.050000, episode:  737\n",
            "frames: 1526000, reward: 16.900000, loss: 0.000528, epsilon: 0.050000, episode:  738\n",
            "frames: 1527000, reward: 16.900000, loss: 0.000123, epsilon: 0.050000, episode:  738\n",
            "frames: 1528000, reward: 16.500000, loss: 0.000417, epsilon: 0.050000, episode:  739\n",
            "frames: 1529000, reward: 16.500000, loss: 0.009359, epsilon: 0.050000, episode:  739\n",
            "frames: 1530000, reward: 16.300000, loss: 0.000360, epsilon: 0.050000, episode:  740\n",
            "frames: 1531000, reward: 16.300000, loss: 0.001598, epsilon: 0.050000, episode:  740\n",
            "frames: 1532000, reward: 16.600000, loss: 0.000264, epsilon: 0.050000, episode:  741\n",
            "frames: 1533000, reward: 16.600000, loss: 0.001214, epsilon: 0.050000, episode:  741\n",
            "frames: 1534000, reward: 16.600000, loss: 0.009436, epsilon: 0.050000, episode:  742\n",
            "frames: 1535000, reward: 16.600000, loss: 0.000568, epsilon: 0.050000, episode:  742\n",
            "frames: 1536000, reward: 16.900000, loss: 0.000361, epsilon: 0.050000, episode:  743\n",
            "frames: 1537000, reward: 16.900000, loss: 0.000161, epsilon: 0.050000, episode:  743\n",
            "frames: 1538000, reward: 17.100000, loss: 0.000248, epsilon: 0.050000, episode:  744\n",
            "frames: 1539000, reward: 17.100000, loss: 0.000319, epsilon: 0.050000, episode:  744\n",
            "frames: 1540000, reward: 17.100000, loss: 0.000329, epsilon: 0.050000, episode:  744\n",
            "frames: 1541000, reward: 16.600000, loss: 0.000284, epsilon: 0.050000, episode:  745\n",
            "frames: 1542000, reward: 16.600000, loss: 0.000087, epsilon: 0.050000, episode:  745\n",
            "frames: 1543000, reward: 16.800000, loss: 0.000182, epsilon: 0.050000, episode:  746\n",
            "frames: 1544000, reward: 16.800000, loss: 0.001532, epsilon: 0.050000, episode:  746\n",
            "frames: 1545000, reward: 17.200000, loss: 0.000222, epsilon: 0.050000, episode:  747\n",
            "frames: 1546000, reward: 17.300000, loss: 0.000697, epsilon: 0.050000, episode:  748\n",
            "frames: 1547000, reward: 17.300000, loss: 0.000581, epsilon: 0.050000, episode:  748\n",
            "frames: 1548000, reward: 17.500000, loss: 0.000661, epsilon: 0.050000, episode:  749\n",
            "frames: 1549000, reward: 17.500000, loss: 0.000291, epsilon: 0.050000, episode:  749\n",
            "frames: 1550000, reward: 17.500000, loss: 0.000179, epsilon: 0.050000, episode:  750\n",
            "frames: 1551000, reward: 17.500000, loss: 0.000812, epsilon: 0.050000, episode:  750\n",
            "frames: 1552000, reward: 17.500000, loss: 0.000412, epsilon: 0.050000, episode:  750\n",
            "frames: 1553000, reward: 17.500000, loss: 0.001141, epsilon: 0.050000, episode:  751\n",
            "frames: 1554000, reward: 17.500000, loss: 0.000735, epsilon: 0.050000, episode:  751\n",
            "frames: 1555000, reward: 17.200000, loss: 0.000381, epsilon: 0.050000, episode:  752\n",
            "frames: 1556000, reward: 17.200000, loss: 0.002025, epsilon: 0.050000, episode:  752\n",
            "frames: 1557000, reward: 17.100000, loss: 0.000358, epsilon: 0.050000, episode:  753\n",
            "frames: 1558000, reward: 17.100000, loss: 0.000142, epsilon: 0.050000, episode:  753\n",
            "frames: 1559000, reward: 16.900000, loss: 0.000201, epsilon: 0.050000, episode:  754\n",
            "frames: 1560000, reward: 16.900000, loss: 0.000295, epsilon: 0.050000, episode:  754\n",
            "frames: 1561000, reward: 17.500000, loss: 0.000655, epsilon: 0.050000, episode:  755\n",
            "frames: 1562000, reward: 17.500000, loss: 0.000256, epsilon: 0.050000, episode:  755\n",
            "frames: 1563000, reward: 17.500000, loss: 0.000507, epsilon: 0.050000, episode:  755\n",
            "frames: 1564000, reward: 17.400000, loss: 0.000393, epsilon: 0.050000, episode:  756\n",
            "frames: 1565000, reward: 17.400000, loss: 0.000549, epsilon: 0.050000, episode:  756\n",
            "frames: 1566000, reward: 17.500000, loss: 0.003619, epsilon: 0.050000, episode:  757\n",
            "frames: 1567000, reward: 17.500000, loss: 0.000858, epsilon: 0.050000, episode:  757\n",
            "frames: 1568000, reward: 17.100000, loss: 0.001082, epsilon: 0.050000, episode:  758\n",
            "frames: 1569000, reward: 17.100000, loss: 0.000241, epsilon: 0.050000, episode:  758\n",
            "frames: 1570000, reward: 16.900000, loss: 0.000914, epsilon: 0.050000, episode:  759\n",
            "frames: 1571000, reward: 16.900000, loss: 0.000305, epsilon: 0.050000, episode:  759\n",
            "frames: 1572000, reward: 17.300000, loss: 0.000801, epsilon: 0.050000, episode:  760\n",
            "frames: 1573000, reward: 17.300000, loss: 0.015926, epsilon: 0.050000, episode:  760\n",
            "frames: 1574000, reward: 17.700000, loss: 0.000592, epsilon: 0.050000, episode:  761\n",
            "frames: 1575000, reward: 17.700000, loss: 0.000327, epsilon: 0.050000, episode:  761\n",
            "frames: 1576000, reward: 17.900000, loss: 0.000563, epsilon: 0.050000, episode:  762\n",
            "frames: 1577000, reward: 17.900000, loss: 0.000421, epsilon: 0.050000, episode:  762\n",
            "frames: 1578000, reward: 17.900000, loss: 0.000166, epsilon: 0.050000, episode:  762\n",
            "frames: 1579000, reward: 17.200000, loss: 0.000745, epsilon: 0.050000, episode:  763\n",
            "frames: 1580000, reward: 17.200000, loss: 0.000273, epsilon: 0.050000, episode:  763\n",
            "frames: 1581000, reward: 17.300000, loss: 0.000678, epsilon: 0.050000, episode:  764\n",
            "frames: 1582000, reward: 17.300000, loss: 0.000185, epsilon: 0.050000, episode:  764\n",
            "frames: 1583000, reward: 17.300000, loss: 0.002178, epsilon: 0.050000, episode:  765\n",
            "frames: 1584000, reward: 17.300000, loss: 0.000275, epsilon: 0.050000, episode:  765\n",
            "frames: 1585000, reward: 17.300000, loss: 0.000301, epsilon: 0.050000, episode:  765\n",
            "frames: 1586000, reward: 16.800000, loss: 0.003378, epsilon: 0.050000, episode:  766\n",
            "frames: 1587000, reward: 16.800000, loss: 0.000403, epsilon: 0.050000, episode:  766\n",
            "frames: 1588000, reward: 16.700000, loss: 0.000363, epsilon: 0.050000, episode:  767\n",
            "frames: 1589000, reward: 16.700000, loss: 0.000268, epsilon: 0.050000, episode:  767\n",
            "frames: 1590000, reward: 16.700000, loss: 0.003080, epsilon: 0.050000, episode:  767\n",
            "frames: 1591000, reward: 16.700000, loss: 0.000191, epsilon: 0.050000, episode:  768\n",
            "frames: 1592000, reward: 16.700000, loss: 0.000514, epsilon: 0.050000, episode:  768\n",
            "frames: 1593000, reward: 16.700000, loss: 0.000523, epsilon: 0.050000, episode:  768\n",
            "frames: 1594000, reward: 16.700000, loss: 0.000497, epsilon: 0.050000, episode:  769\n",
            "frames: 1595000, reward: 16.700000, loss: 0.000680, epsilon: 0.050000, episode:  769\n",
            "frames: 1596000, reward: 16.300000, loss: 0.000245, epsilon: 0.050000, episode:  770\n",
            "frames: 1597000, reward: 16.300000, loss: 0.001205, epsilon: 0.050000, episode:  770\n",
            "frames: 1598000, reward: 16.100000, loss: 0.000274, epsilon: 0.050000, episode:  771\n",
            "frames: 1599000, reward: 16.100000, loss: 0.002018, epsilon: 0.050000, episode:  771\n",
            "frames: 1600000, reward: 15.800000, loss: 0.000437, epsilon: 0.050000, episode:  772\n",
            "frames: 1601000, reward: 15.800000, loss: 0.000312, epsilon: 0.050000, episode:  772\n",
            "frames: 1602000, reward: 16.700000, loss: 0.000150, epsilon: 0.050000, episode:  773\n",
            "frames: 1603000, reward: 16.700000, loss: 0.000358, epsilon: 0.050000, episode:  773\n",
            "frames: 1604000, reward: 16.900000, loss: 0.000481, epsilon: 0.050000, episode:  774\n",
            "frames: 1605000, reward: 16.900000, loss: 0.000305, epsilon: 0.050000, episode:  774\n",
            "frames: 1606000, reward: 16.900000, loss: 0.000540, epsilon: 0.050000, episode:  775\n",
            "frames: 1607000, reward: 17.500000, loss: 0.001020, epsilon: 0.050000, episode:  776\n",
            "frames: 1608000, reward: 17.500000, loss: 0.000484, epsilon: 0.050000, episode:  776\n",
            "frames: 1609000, reward: 17.500000, loss: 0.000237, epsilon: 0.050000, episode:  776\n",
            "frames: 1610000, reward: 17.300000, loss: 0.000745, epsilon: 0.050000, episode:  777\n",
            "frames: 1611000, reward: 17.300000, loss: 0.000283, epsilon: 0.050000, episode:  777\n",
            "frames: 1612000, reward: 17.800000, loss: 0.000279, epsilon: 0.050000, episode:  778\n",
            "frames: 1613000, reward: 17.800000, loss: 0.000193, epsilon: 0.050000, episode:  778\n",
            "frames: 1614000, reward: 17.900000, loss: 0.000797, epsilon: 0.050000, episode:  779\n",
            "frames: 1615000, reward: 17.900000, loss: 0.000648, epsilon: 0.050000, episode:  779\n",
            "frames: 1616000, reward: 17.700000, loss: 0.000286, epsilon: 0.050000, episode:  780\n",
            "frames: 1617000, reward: 17.700000, loss: 0.003251, epsilon: 0.050000, episode:  780\n",
            "frames: 1618000, reward: 17.700000, loss: 0.000144, epsilon: 0.050000, episode:  780\n",
            "frames: 1619000, reward: 17.600000, loss: 0.001025, epsilon: 0.050000, episode:  781\n",
            "frames: 1620000, reward: 17.600000, loss: 0.000369, epsilon: 0.050000, episode:  781\n",
            "frames: 1621000, reward: 17.600000, loss: 0.000369, epsilon: 0.050000, episode:  781\n",
            "frames: 1622000, reward: 17.300000, loss: 0.001475, epsilon: 0.050000, episode:  782\n",
            "frames: 1623000, reward: 17.100000, loss: 0.000306, epsilon: 0.050000, episode:  783\n",
            "frames: 1624000, reward: 17.100000, loss: 0.000417, epsilon: 0.050000, episode:  783\n",
            "frames: 1625000, reward: 16.800000, loss: 0.001986, epsilon: 0.050000, episode:  784\n",
            "frames: 1626000, reward: 16.800000, loss: 0.000853, epsilon: 0.050000, episode:  784\n",
            "frames: 1627000, reward: 16.800000, loss: 0.000768, epsilon: 0.050000, episode:  784\n",
            "frames: 1628000, reward: 16.600000, loss: 0.002941, epsilon: 0.050000, episode:  785\n",
            "frames: 1629000, reward: 16.600000, loss: 0.000177, epsilon: 0.050000, episode:  785\n",
            "frames: 1630000, reward: 16.000000, loss: 0.000638, epsilon: 0.050000, episode:  786\n",
            "frames: 1631000, reward: 16.000000, loss: 0.000957, epsilon: 0.050000, episode:  786\n",
            "frames: 1632000, reward: 16.000000, loss: 0.001952, epsilon: 0.050000, episode:  786\n",
            "frames: 1633000, reward: 15.700000, loss: 0.000261, epsilon: 0.050000, episode:  787\n",
            "frames: 1634000, reward: 15.700000, loss: 0.000307, epsilon: 0.050000, episode:  787\n",
            "frames: 1635000, reward: 15.500000, loss: 0.000375, epsilon: 0.050000, episode:  788\n",
            "frames: 1636000, reward: 15.500000, loss: 0.000467, epsilon: 0.050000, episode:  788\n",
            "frames: 1637000, reward: 15.300000, loss: 0.000809, epsilon: 0.050000, episode:  789\n",
            "frames: 1638000, reward: 15.300000, loss: 0.000438, epsilon: 0.050000, episode:  789\n",
            "frames: 1639000, reward: 15.700000, loss: 0.000433, epsilon: 0.050000, episode:  790\n",
            "frames: 1640000, reward: 15.700000, loss: 0.000624, epsilon: 0.050000, episode:  790\n",
            "frames: 1641000, reward: 15.700000, loss: 0.000211, epsilon: 0.050000, episode:  790\n",
            "frames: 1642000, reward: 15.500000, loss: 0.000310, epsilon: 0.050000, episode:  791\n",
            "frames: 1643000, reward: 15.500000, loss: 0.000248, epsilon: 0.050000, episode:  791\n",
            "frames: 1644000, reward: 15.900000, loss: 0.000309, epsilon: 0.050000, episode:  792\n",
            "frames: 1645000, reward: 15.900000, loss: 0.000572, epsilon: 0.050000, episode:  792\n",
            "frames: 1646000, reward: 15.800000, loss: 0.000463, epsilon: 0.050000, episode:  793\n",
            "frames: 1647000, reward: 15.800000, loss: 0.000271, epsilon: 0.050000, episode:  793\n",
            "frames: 1648000, reward: 15.800000, loss: 0.002836, epsilon: 0.050000, episode:  793\n",
            "frames: 1649000, reward: 15.600000, loss: 0.000336, epsilon: 0.050000, episode:  794\n",
            "frames: 1650000, reward: 15.600000, loss: 0.000404, epsilon: 0.050000, episode:  794\n",
            "frames: 1651000, reward: 15.800000, loss: 0.000114, epsilon: 0.050000, episode:  795\n",
            "frames: 1652000, reward: 15.800000, loss: 0.000443, epsilon: 0.050000, episode:  795\n",
            "frames: 1653000, reward: 16.100000, loss: 0.000219, epsilon: 0.050000, episode:  796\n",
            "frames: 1654000, reward: 16.100000, loss: 0.000718, epsilon: 0.050000, episode:  796\n",
            "frames: 1655000, reward: 16.500000, loss: 0.000241, epsilon: 0.050000, episode:  797\n",
            "frames: 1656000, reward: 16.500000, loss: 0.000258, epsilon: 0.050000, episode:  797\n",
            "frames: 1657000, reward: 16.400000, loss: 0.001080, epsilon: 0.050000, episode:  798\n",
            "frames: 1658000, reward: 16.400000, loss: 0.000447, epsilon: 0.050000, episode:  798\n",
            "frames: 1659000, reward: 16.600000, loss: 0.000291, epsilon: 0.050000, episode:  799\n",
            "frames: 1660000, reward: 16.600000, loss: 0.000388, epsilon: 0.050000, episode:  799\n",
            "frames: 1661000, reward: 16.600000, loss: 0.000692, epsilon: 0.050000, episode:  799\n",
            "frames: 1662000, reward: 16.600000, loss: 0.000461, epsilon: 0.050000, episode:  800\n",
            "frames: 1663000, reward: 16.600000, loss: 0.000584, epsilon: 0.050000, episode:  800\n",
            "frames: 1664000, reward: 16.400000, loss: 0.001588, epsilon: 0.050000, episode:  801\n",
            "frames: 1665000, reward: 16.400000, loss: 0.000953, epsilon: 0.050000, episode:  801\n",
            "frames: 1666000, reward: 16.100000, loss: 0.000250, epsilon: 0.050000, episode:  802\n",
            "frames: 1667000, reward: 16.100000, loss: 0.004583, epsilon: 0.050000, episode:  802\n",
            "frames: 1668000, reward: 16.200000, loss: 0.000478, epsilon: 0.050000, episode:  803\n",
            "frames: 1669000, reward: 16.200000, loss: 0.000567, epsilon: 0.050000, episode:  803\n",
            "frames: 1670000, reward: 16.200000, loss: 0.000521, epsilon: 0.050000, episode:  803\n",
            "frames: 1671000, reward: 16.000000, loss: 0.000240, epsilon: 0.050000, episode:  804\n",
            "frames: 1672000, reward: 16.000000, loss: 0.000499, epsilon: 0.050000, episode:  804\n",
            "frames: 1673000, reward: 16.000000, loss: 0.000202, epsilon: 0.050000, episode:  804\n",
            "frames: 1674000, reward: 15.700000, loss: 0.000600, epsilon: 0.050000, episode:  805\n",
            "frames: 1675000, reward: 15.700000, loss: 0.000954, epsilon: 0.050000, episode:  805\n",
            "frames: 1676000, reward: 16.000000, loss: 0.000399, epsilon: 0.050000, episode:  806\n",
            "frames: 1677000, reward: 16.000000, loss: 0.001146, epsilon: 0.050000, episode:  806\n",
            "frames: 1678000, reward: 15.700000, loss: 0.000427, epsilon: 0.050000, episode:  807\n",
            "frames: 1679000, reward: 15.700000, loss: 0.000450, epsilon: 0.050000, episode:  807\n",
            "frames: 1680000, reward: 15.700000, loss: 0.000663, epsilon: 0.050000, episode:  808\n",
            "frames: 1681000, reward: 15.700000, loss: 0.001064, epsilon: 0.050000, episode:  808\n",
            "frames: 1682000, reward: 15.700000, loss: 0.000957, epsilon: 0.050000, episode:  808\n",
            "frames: 1683000, reward: 15.300000, loss: 0.000337, epsilon: 0.050000, episode:  809\n",
            "frames: 1684000, reward: 15.300000, loss: 0.000519, epsilon: 0.050000, episode:  809\n",
            "frames: 1685000, reward: 15.000000, loss: 0.000386, epsilon: 0.050000, episode:  810\n",
            "frames: 1686000, reward: 15.000000, loss: 0.000206, epsilon: 0.050000, episode:  810\n",
            "frames: 1687000, reward: 15.200000, loss: 0.001098, epsilon: 0.050000, episode:  811\n",
            "frames: 1688000, reward: 15.200000, loss: 0.000558, epsilon: 0.050000, episode:  811\n",
            "frames: 1689000, reward: 15.200000, loss: 0.000373, epsilon: 0.050000, episode:  811\n",
            "frames: 1690000, reward: 15.600000, loss: 0.000211, epsilon: 0.050000, episode:  812\n",
            "frames: 1691000, reward: 15.600000, loss: 0.000764, epsilon: 0.050000, episode:  812\n",
            "frames: 1692000, reward: 15.800000, loss: 0.012288, epsilon: 0.050000, episode:  813\n",
            "frames: 1693000, reward: 15.800000, loss: 0.000877, epsilon: 0.050000, episode:  813\n",
            "frames: 1694000, reward: 16.200000, loss: 0.000650, epsilon: 0.050000, episode:  814\n",
            "frames: 1695000, reward: 16.200000, loss: 0.000280, epsilon: 0.050000, episode:  814\n",
            "frames: 1696000, reward: 16.700000, loss: 0.000456, epsilon: 0.050000, episode:  815\n",
            "frames: 1697000, reward: 16.700000, loss: 0.000631, epsilon: 0.050000, episode:  815\n",
            "frames: 1698000, reward: 16.600000, loss: 0.000303, epsilon: 0.050000, episode:  816\n",
            "frames: 1699000, reward: 16.600000, loss: 0.000705, epsilon: 0.050000, episode:  816\n",
            "frames: 1700000, reward: 16.900000, loss: 0.000447, epsilon: 0.050000, episode:  817\n",
            "frames: 1701000, reward: 16.900000, loss: 0.000732, epsilon: 0.050000, episode:  817\n",
            "frames: 1702000, reward: 16.900000, loss: 0.000552, epsilon: 0.050000, episode:  817\n",
            "frames: 1703000, reward: 16.800000, loss: 0.000278, epsilon: 0.050000, episode:  818\n",
            "frames: 1704000, reward: 16.800000, loss: 0.000363, epsilon: 0.050000, episode:  818\n",
            "frames: 1705000, reward: 16.900000, loss: 0.000273, epsilon: 0.050000, episode:  819\n",
            "frames: 1706000, reward: 16.900000, loss: 0.000913, epsilon: 0.050000, episode:  819\n",
            "frames: 1707000, reward: 17.200000, loss: 0.000374, epsilon: 0.050000, episode:  820\n",
            "frames: 1708000, reward: 17.200000, loss: 0.001832, epsilon: 0.050000, episode:  820\n",
            "frames: 1709000, reward: 17.500000, loss: 0.000404, epsilon: 0.050000, episode:  821\n",
            "frames: 1710000, reward: 17.500000, loss: 0.000549, epsilon: 0.050000, episode:  821\n",
            "frames: 1711000, reward: 17.500000, loss: 0.001062, epsilon: 0.050000, episode:  821\n",
            "frames: 1712000, reward: 17.500000, loss: 0.000778, epsilon: 0.050000, episode:  822\n",
            "frames: 1713000, reward: 17.500000, loss: 0.000302, epsilon: 0.050000, episode:  822\n",
            "frames: 1714000, reward: 17.300000, loss: 0.000946, epsilon: 0.050000, episode:  823\n",
            "frames: 1715000, reward: 17.300000, loss: 0.000719, epsilon: 0.050000, episode:  823\n",
            "frames: 1716000, reward: 17.400000, loss: 0.000258, epsilon: 0.050000, episode:  824\n",
            "frames: 1717000, reward: 17.400000, loss: 0.000232, epsilon: 0.050000, episode:  824\n",
            "frames: 1718000, reward: 16.900000, loss: 0.001609, epsilon: 0.050000, episode:  825\n",
            "frames: 1719000, reward: 16.900000, loss: 0.000707, epsilon: 0.050000, episode:  825\n",
            "frames: 1720000, reward: 16.700000, loss: 0.000657, epsilon: 0.050000, episode:  826\n",
            "frames: 1721000, reward: 16.700000, loss: 0.001013, epsilon: 0.050000, episode:  826\n",
            "frames: 1722000, reward: 16.800000, loss: 0.011943, epsilon: 0.050000, episode:  827\n",
            "frames: 1723000, reward: 16.800000, loss: 0.000482, epsilon: 0.050000, episode:  827\n",
            "frames: 1724000, reward: 16.800000, loss: 0.000643, epsilon: 0.050000, episode:  828\n",
            "frames: 1725000, reward: 16.800000, loss: 0.000489, epsilon: 0.050000, episode:  828\n",
            "frames: 1726000, reward: 16.800000, loss: 0.002050, epsilon: 0.050000, episode:  828\n",
            "frames: 1727000, reward: 16.700000, loss: 0.001154, epsilon: 0.050000, episode:  829\n",
            "frames: 1728000, reward: 16.700000, loss: 0.000824, epsilon: 0.050000, episode:  829\n",
            "frames: 1729000, reward: 16.800000, loss: 0.000689, epsilon: 0.050000, episode:  830\n",
            "frames: 1730000, reward: 16.800000, loss: 0.000493, epsilon: 0.050000, episode:  830\n",
            "frames: 1731000, reward: 16.800000, loss: 0.000789, epsilon: 0.050000, episode:  830\n",
            "frames: 1732000, reward: 16.500000, loss: 0.004058, epsilon: 0.050000, episode:  831\n",
            "frames: 1733000, reward: 16.500000, loss: 0.000249, epsilon: 0.050000, episode:  831\n",
            "frames: 1734000, reward: 16.000000, loss: 0.000359, epsilon: 0.050000, episode:  832\n",
            "frames: 1735000, reward: 16.000000, loss: 0.000391, epsilon: 0.050000, episode:  832\n",
            "frames: 1736000, reward: 16.000000, loss: 0.000983, epsilon: 0.050000, episode:  832\n",
            "frames: 1737000, reward: 15.700000, loss: 0.000788, epsilon: 0.050000, episode:  833\n",
            "frames: 1738000, reward: 15.700000, loss: 0.001713, epsilon: 0.050000, episode:  833\n",
            "frames: 1739000, reward: 15.600000, loss: 0.000338, epsilon: 0.050000, episode:  834\n",
            "frames: 1740000, reward: 15.600000, loss: 0.000430, epsilon: 0.050000, episode:  834\n",
            "frames: 1741000, reward: 16.000000, loss: 0.000239, epsilon: 0.050000, episode:  835\n",
            "frames: 1742000, reward: 16.000000, loss: 0.017380, epsilon: 0.050000, episode:  835\n",
            "frames: 1743000, reward: 16.000000, loss: 0.001294, epsilon: 0.050000, episode:  835\n",
            "frames: 1744000, reward: 15.900000, loss: 0.000635, epsilon: 0.050000, episode:  836\n",
            "frames: 1745000, reward: 15.900000, loss: 0.000293, epsilon: 0.050000, episode:  836\n",
            "frames: 1746000, reward: 15.300000, loss: 0.000518, epsilon: 0.050000, episode:  837\n",
            "frames: 1747000, reward: 15.300000, loss: 0.000456, epsilon: 0.050000, episode:  837\n",
            "frames: 1748000, reward: 15.700000, loss: 0.000448, epsilon: 0.050000, episode:  838\n",
            "frames: 1749000, reward: 15.700000, loss: 0.000890, epsilon: 0.050000, episode:  838\n",
            "frames: 1750000, reward: 16.000000, loss: 0.001519, epsilon: 0.050000, episode:  839\n",
            "frames: 1751000, reward: 16.000000, loss: 0.000887, epsilon: 0.050000, episode:  839\n",
            "frames: 1752000, reward: 16.100000, loss: 0.000442, epsilon: 0.050000, episode:  840\n",
            "frames: 1753000, reward: 16.100000, loss: 0.000279, epsilon: 0.050000, episode:  840\n",
            "frames: 1754000, reward: 16.100000, loss: 0.001120, epsilon: 0.050000, episode:  840\n",
            "frames: 1755000, reward: 16.200000, loss: 0.000761, epsilon: 0.050000, episode:  841\n",
            "frames: 1756000, reward: 16.200000, loss: 0.000615, epsilon: 0.050000, episode:  841\n",
            "frames: 1757000, reward: 16.600000, loss: 0.000460, epsilon: 0.050000, episode:  842\n",
            "frames: 1758000, reward: 16.600000, loss: 0.000816, epsilon: 0.050000, episode:  842\n",
            "frames: 1759000, reward: 16.900000, loss: 0.000524, epsilon: 0.050000, episode:  843\n",
            "frames: 1760000, reward: 16.900000, loss: 0.000379, epsilon: 0.050000, episode:  843\n",
            "frames: 1761000, reward: 16.900000, loss: 0.000355, epsilon: 0.050000, episode:  843\n",
            "frames: 1762000, reward: 16.600000, loss: 0.001022, epsilon: 0.050000, episode:  844\n",
            "frames: 1763000, reward: 16.600000, loss: 0.001761, epsilon: 0.050000, episode:  844\n",
            "frames: 1764000, reward: 16.500000, loss: 0.001965, epsilon: 0.050000, episode:  845\n",
            "frames: 1765000, reward: 16.500000, loss: 0.000639, epsilon: 0.050000, episode:  845\n",
            "frames: 1766000, reward: 16.600000, loss: 0.000397, epsilon: 0.050000, episode:  846\n",
            "frames: 1767000, reward: 16.600000, loss: 0.000334, epsilon: 0.050000, episode:  846\n",
            "frames: 1768000, reward: 17.000000, loss: 0.001024, epsilon: 0.050000, episode:  847\n",
            "frames: 1769000, reward: 17.000000, loss: 0.000410, epsilon: 0.050000, episode:  847\n",
            "frames: 1770000, reward: 17.000000, loss: 0.005896, epsilon: 0.050000, episode:  847\n",
            "frames: 1771000, reward: 16.600000, loss: 0.000756, epsilon: 0.050000, episode:  848\n",
            "frames: 1772000, reward: 16.600000, loss: 0.000572, epsilon: 0.050000, episode:  848\n",
            "frames: 1773000, reward: 16.600000, loss: 0.000466, epsilon: 0.050000, episode:  849\n",
            "frames: 1774000, reward: 16.600000, loss: 0.002082, epsilon: 0.050000, episode:  849\n",
            "frames: 1775000, reward: 16.400000, loss: 0.000847, epsilon: 0.050000, episode:  850\n",
            "frames: 1776000, reward: 16.400000, loss: 0.000716, epsilon: 0.050000, episode:  850\n",
            "frames: 1777000, reward: 16.500000, loss: 0.000653, epsilon: 0.050000, episode:  851\n",
            "frames: 1778000, reward: 16.500000, loss: 0.000372, epsilon: 0.050000, episode:  851\n",
            "frames: 1779000, reward: 16.500000, loss: 0.000651, epsilon: 0.050000, episode:  851\n",
            "frames: 1780000, reward: 16.200000, loss: 0.000246, epsilon: 0.050000, episode:  852\n",
            "frames: 1781000, reward: 16.200000, loss: 0.001110, epsilon: 0.050000, episode:  852\n",
            "frames: 1782000, reward: 16.200000, loss: 0.000376, epsilon: 0.050000, episode:  853\n",
            "frames: 1783000, reward: 16.200000, loss: 0.000534, epsilon: 0.050000, episode:  853\n",
            "frames: 1784000, reward: 16.100000, loss: 0.000515, epsilon: 0.050000, episode:  854\n",
            "frames: 1785000, reward: 16.100000, loss: 0.003315, epsilon: 0.050000, episode:  854\n",
            "frames: 1786000, reward: 16.100000, loss: 0.000181, epsilon: 0.050000, episode:  854\n",
            "frames: 1787000, reward: 16.400000, loss: 0.000322, epsilon: 0.050000, episode:  855\n",
            "frames: 1788000, reward: 16.400000, loss: 0.000550, epsilon: 0.050000, episode:  855\n",
            "frames: 1789000, reward: 16.400000, loss: 0.000855, epsilon: 0.050000, episode:  855\n",
            "frames: 1790000, reward: 15.900000, loss: 0.000566, epsilon: 0.050000, episode:  856\n",
            "frames: 1791000, reward: 15.900000, loss: 0.000913, epsilon: 0.050000, episode:  856\n",
            "frames: 1792000, reward: 15.500000, loss: 0.000277, epsilon: 0.050000, episode:  857\n",
            "frames: 1793000, reward: 15.500000, loss: 0.001108, epsilon: 0.050000, episode:  857\n",
            "frames: 1794000, reward: 15.700000, loss: 0.000238, epsilon: 0.050000, episode:  858\n",
            "frames: 1795000, reward: 15.700000, loss: 0.000229, epsilon: 0.050000, episode:  858\n",
            "frames: 1796000, reward: 16.000000, loss: 0.000844, epsilon: 0.050000, episode:  859\n",
            "frames: 1797000, reward: 16.000000, loss: 0.000378, epsilon: 0.050000, episode:  859\n",
            "frames: 1798000, reward: 15.700000, loss: 0.000950, epsilon: 0.050000, episode:  860\n",
            "frames: 1799000, reward: 15.700000, loss: 0.000516, epsilon: 0.050000, episode:  860\n",
            "frames: 1800000, reward: 15.700000, loss: 0.003945, epsilon: 0.050000, episode:  860\n",
            "frames: 1801000, reward: 15.800000, loss: 0.000446, epsilon: 0.050000, episode:  861\n",
            "frames: 1802000, reward: 15.800000, loss: 0.001558, epsilon: 0.050000, episode:  861\n",
            "frames: 1803000, reward: 16.100000, loss: 0.000324, epsilon: 0.050000, episode:  862\n",
            "frames: 1804000, reward: 16.100000, loss: 0.000186, epsilon: 0.050000, episode:  862\n",
            "frames: 1805000, reward: 15.800000, loss: 0.000383, epsilon: 0.050000, episode:  863\n",
            "frames: 1806000, reward: 15.800000, loss: 0.000622, epsilon: 0.050000, episode:  863\n",
            "frames: 1807000, reward: 16.300000, loss: 0.000821, epsilon: 0.050000, episode:  864\n",
            "frames: 1808000, reward: 16.300000, loss: 0.000312, epsilon: 0.050000, episode:  864\n",
            "frames: 1809000, reward: 15.900000, loss: 0.003149, epsilon: 0.050000, episode:  865\n",
            "frames: 1810000, reward: 15.900000, loss: 0.000546, epsilon: 0.050000, episode:  865\n",
            "frames: 1811000, reward: 15.900000, loss: 0.000522, epsilon: 0.050000, episode:  865\n",
            "frames: 1812000, reward: 16.100000, loss: 0.000290, epsilon: 0.050000, episode:  866\n",
            "frames: 1813000, reward: 16.100000, loss: 0.000441, epsilon: 0.050000, episode:  866\n",
            "frames: 1814000, reward: 16.100000, loss: 0.000610, epsilon: 0.050000, episode:  866\n",
            "frames: 1815000, reward: 15.600000, loss: 0.002014, epsilon: 0.050000, episode:  867\n",
            "frames: 1816000, reward: 15.600000, loss: 0.000651, epsilon: 0.050000, episode:  867\n",
            "frames: 1817000, reward: 15.200000, loss: 0.001253, epsilon: 0.050000, episode:  868\n",
            "frames: 1818000, reward: 15.200000, loss: 0.000300, epsilon: 0.050000, episode:  868\n",
            "frames: 1819000, reward: 15.200000, loss: 0.000455, epsilon: 0.050000, episode:  868\n",
            "frames: 1820000, reward: 15.000000, loss: 0.001027, epsilon: 0.050000, episode:  869\n",
            "frames: 1821000, reward: 15.000000, loss: 0.000427, epsilon: 0.050000, episode:  869\n",
            "frames: 1822000, reward: 14.400000, loss: 0.000377, epsilon: 0.050000, episode:  870\n",
            "frames: 1823000, reward: 14.400000, loss: 0.001001, epsilon: 0.050000, episode:  870\n",
            "frames: 1824000, reward: 14.600000, loss: 0.000413, epsilon: 0.050000, episode:  871\n",
            "frames: 1825000, reward: 14.600000, loss: 0.000523, epsilon: 0.050000, episode:  871\n",
            "frames: 1826000, reward: 14.600000, loss: 0.006220, epsilon: 0.050000, episode:  872\n",
            "frames: 1827000, reward: 14.600000, loss: 0.000767, epsilon: 0.050000, episode:  872\n",
            "frames: 1828000, reward: 14.600000, loss: 0.001719, epsilon: 0.050000, episode:  872\n",
            "frames: 1829000, reward: 14.400000, loss: 0.001018, epsilon: 0.050000, episode:  873\n",
            "frames: 1830000, reward: 14.600000, loss: 0.000521, epsilon: 0.050000, episode:  874\n",
            "frames: 1831000, reward: 14.600000, loss: 0.000482, epsilon: 0.050000, episode:  874\n",
            "frames: 1832000, reward: 14.600000, loss: 0.000330, epsilon: 0.050000, episode:  874\n",
            "frames: 1833000, reward: 14.200000, loss: 0.000382, epsilon: 0.050000, episode:  875\n",
            "frames: 1834000, reward: 14.200000, loss: 0.000375, epsilon: 0.050000, episode:  875\n",
            "frames: 1835000, reward: 14.400000, loss: 0.002658, epsilon: 0.050000, episode:  876\n",
            "frames: 1836000, reward: 14.400000, loss: 0.000333, epsilon: 0.050000, episode:  876\n",
            "frames: 1837000, reward: 15.500000, loss: 0.000228, epsilon: 0.050000, episode:  877\n",
            "frames: 1838000, reward: 15.500000, loss: 0.000722, epsilon: 0.050000, episode:  877\n",
            "frames: 1839000, reward: 15.800000, loss: 0.000394, epsilon: 0.050000, episode:  878\n",
            "frames: 1840000, reward: 15.800000, loss: 0.000414, epsilon: 0.050000, episode:  879\n",
            "frames: 1841000, reward: 15.800000, loss: 0.000611, epsilon: 0.050000, episode:  879\n",
            "frames: 1842000, reward: 16.800000, loss: 0.000482, epsilon: 0.050000, episode:  880\n",
            "frames: 1843000, reward: 16.800000, loss: 0.000344, epsilon: 0.050000, episode:  880\n",
            "frames: 1844000, reward: 16.600000, loss: 0.001111, epsilon: 0.050000, episode:  881\n",
            "frames: 1845000, reward: 16.600000, loss: 0.000883, epsilon: 0.050000, episode:  881\n",
            "frames: 1846000, reward: 16.300000, loss: 0.000447, epsilon: 0.050000, episode:  882\n",
            "frames: 1847000, reward: 16.300000, loss: 0.002169, epsilon: 0.050000, episode:  882\n",
            "frames: 1848000, reward: 16.300000, loss: 0.000261, epsilon: 0.050000, episode:  882\n",
            "frames: 1849000, reward: 16.900000, loss: 0.000278, epsilon: 0.050000, episode:  883\n",
            "frames: 1850000, reward: 16.800000, loss: 0.000528, epsilon: 0.050000, episode:  884\n",
            "frames: 1851000, reward: 16.800000, loss: 0.000215, epsilon: 0.050000, episode:  884\n",
            "frames: 1852000, reward: 17.500000, loss: 0.000352, epsilon: 0.050000, episode:  885\n",
            "frames: 1853000, reward: 17.500000, loss: 0.000478, epsilon: 0.050000, episode:  885\n",
            "frames: 1854000, reward: 17.500000, loss: 0.000321, epsilon: 0.050000, episode:  885\n",
            "frames: 1855000, reward: 17.900000, loss: 0.000827, epsilon: 0.050000, episode:  886\n",
            "frames: 1856000, reward: 17.400000, loss: 0.000640, epsilon: 0.050000, episode:  887\n",
            "frames: 1857000, reward: 17.400000, loss: 0.000960, epsilon: 0.050000, episode:  887\n",
            "frames: 1858000, reward: 17.400000, loss: 0.000267, epsilon: 0.050000, episode:  887\n",
            "frames: 1859000, reward: 17.500000, loss: 0.001590, epsilon: 0.050000, episode:  888\n",
            "frames: 1860000, reward: 17.600000, loss: 0.000394, epsilon: 0.050000, episode:  889\n",
            "frames: 1861000, reward: 17.600000, loss: 0.000501, epsilon: 0.050000, episode:  889\n",
            "frames: 1862000, reward: 17.600000, loss: 0.000286, epsilon: 0.050000, episode:  889\n",
            "frames: 1863000, reward: 16.900000, loss: 0.000447, epsilon: 0.050000, episode:  890\n",
            "frames: 1864000, reward: 16.900000, loss: 0.000959, epsilon: 0.050000, episode:  890\n",
            "frames: 1865000, reward: 17.100000, loss: 0.000194, epsilon: 0.050000, episode:  891\n",
            "frames: 1866000, reward: 17.100000, loss: 0.000406, epsilon: 0.050000, episode:  891\n",
            "frames: 1867000, reward: 17.500000, loss: 0.000291, epsilon: 0.050000, episode:  892\n",
            "frames: 1868000, reward: 17.500000, loss: 0.000279, epsilon: 0.050000, episode:  892\n",
            "frames: 1869000, reward: 17.500000, loss: 0.004063, epsilon: 0.050000, episode:  892\n",
            "frames: 1870000, reward: 17.300000, loss: 0.000503, epsilon: 0.050000, episode:  893\n",
            "frames: 1871000, reward: 17.300000, loss: 0.001838, epsilon: 0.050000, episode:  893\n",
            "frames: 1872000, reward: 17.100000, loss: 0.000294, epsilon: 0.050000, episode:  894\n",
            "frames: 1873000, reward: 17.100000, loss: 0.001072, epsilon: 0.050000, episode:  894\n",
            "frames: 1874000, reward: 17.200000, loss: 0.001095, epsilon: 0.050000, episode:  895\n",
            "frames: 1875000, reward: 17.200000, loss: 0.000306, epsilon: 0.050000, episode:  895\n",
            "frames: 1876000, reward: 17.300000, loss: 0.000923, epsilon: 0.050000, episode:  896\n",
            "frames: 1877000, reward: 17.300000, loss: 0.000669, epsilon: 0.050000, episode:  896\n",
            "frames: 1878000, reward: 17.600000, loss: 0.000356, epsilon: 0.050000, episode:  897\n",
            "frames: 1879000, reward: 17.600000, loss: 0.000465, epsilon: 0.050000, episode:  897\n",
            "frames: 1880000, reward: 17.700000, loss: 0.000220, epsilon: 0.050000, episode:  898\n",
            "frames: 1881000, reward: 17.700000, loss: 0.000558, epsilon: 0.050000, episode:  898\n",
            "frames: 1882000, reward: 17.700000, loss: 0.000273, epsilon: 0.050000, episode:  898\n",
            "frames: 1883000, reward: 17.100000, loss: 0.000627, epsilon: 0.050000, episode:  899\n",
            "frames: 1884000, reward: 17.100000, loss: 0.000567, epsilon: 0.050000, episode:  899\n",
            "frames: 1885000, reward: 17.100000, loss: 0.000364, epsilon: 0.050000, episode:  899\n",
            "frames: 1886000, reward: 17.500000, loss: 0.002582, epsilon: 0.050000, episode:  900\n",
            "frames: 1887000, reward: 17.500000, loss: 0.000565, epsilon: 0.050000, episode:  900\n",
            "frames: 1888000, reward: 17.400000, loss: 0.001148, epsilon: 0.050000, episode:  901\n",
            "frames: 1889000, reward: 17.400000, loss: 0.000517, epsilon: 0.050000, episode:  902\n",
            "frames: 1890000, reward: 17.400000, loss: 0.000427, epsilon: 0.050000, episode:  902\n",
            "frames: 1891000, reward: 17.400000, loss: 0.001252, epsilon: 0.050000, episode:  902\n",
            "frames: 1892000, reward: 17.400000, loss: 0.000600, epsilon: 0.050000, episode:  903\n",
            "frames: 1893000, reward: 17.400000, loss: 0.000282, epsilon: 0.050000, episode:  903\n",
            "frames: 1894000, reward: 17.700000, loss: 0.000319, epsilon: 0.050000, episode:  904\n",
            "frames: 1895000, reward: 17.700000, loss: 0.000437, epsilon: 0.050000, episode:  904\n",
            "frames: 1896000, reward: 17.700000, loss: 0.000837, epsilon: 0.050000, episode:  904\n",
            "frames: 1897000, reward: 17.000000, loss: 0.000986, epsilon: 0.050000, episode:  905\n",
            "frames: 1898000, reward: 17.000000, loss: 0.000339, epsilon: 0.050000, episode:  905\n",
            "frames: 1899000, reward: 16.700000, loss: 0.000423, epsilon: 0.050000, episode:  906\n",
            "frames: 1900000, reward: 16.700000, loss: 0.000975, epsilon: 0.050000, episode:  906\n",
            "frames: 1901000, reward: 16.600000, loss: 0.000267, epsilon: 0.050000, episode:  907\n",
            "frames: 1902000, reward: 16.600000, loss: 0.000390, epsilon: 0.050000, episode:  907\n",
            "frames: 1903000, reward: 16.600000, loss: 0.000339, epsilon: 0.050000, episode:  908\n",
            "frames: 1904000, reward: 16.600000, loss: 0.000433, epsilon: 0.050000, episode:  908\n",
            "frames: 1905000, reward: 17.200000, loss: 0.001274, epsilon: 0.050000, episode:  909\n",
            "frames: 1906000, reward: 17.200000, loss: 0.001032, epsilon: 0.050000, episode:  909\n",
            "frames: 1907000, reward: 17.400000, loss: 0.000437, epsilon: 0.050000, episode:  910\n",
            "frames: 1908000, reward: 17.400000, loss: 0.000447, epsilon: 0.050000, episode:  910\n",
            "frames: 1909000, reward: 17.400000, loss: 0.000821, epsilon: 0.050000, episode:  911\n",
            "frames: 1910000, reward: 17.400000, loss: 0.000438, epsilon: 0.050000, episode:  911\n",
            "frames: 1911000, reward: 17.400000, loss: 0.000426, epsilon: 0.050000, episode:  911\n",
            "frames: 1912000, reward: 17.300000, loss: 0.000416, epsilon: 0.050000, episode:  912\n",
            "frames: 1913000, reward: 17.300000, loss: 0.000347, epsilon: 0.050000, episode:  912\n",
            "frames: 1914000, reward: 17.300000, loss: 0.003209, epsilon: 0.050000, episode:  912\n",
            "frames: 1915000, reward: 16.800000, loss: 0.000279, epsilon: 0.050000, episode:  913\n",
            "frames: 1916000, reward: 16.800000, loss: 0.001036, epsilon: 0.050000, episode:  913\n",
            "frames: 1917000, reward: 16.900000, loss: 0.000525, epsilon: 0.050000, episode:  914\n",
            "frames: 1918000, reward: 16.900000, loss: 0.000249, epsilon: 0.050000, episode:  914\n",
            "frames: 1919000, reward: 17.000000, loss: 0.000844, epsilon: 0.050000, episode:  915\n",
            "frames: 1920000, reward: 17.000000, loss: 0.002892, epsilon: 0.050000, episode:  915\n",
            "frames: 1921000, reward: 17.000000, loss: 0.000285, epsilon: 0.050000, episode:  915\n",
            "frames: 1922000, reward: 16.500000, loss: 0.000130, epsilon: 0.050000, episode:  916\n",
            "frames: 1923000, reward: 16.500000, loss: 0.000497, epsilon: 0.050000, episode:  916\n",
            "frames: 1924000, reward: 16.600000, loss: 0.000483, epsilon: 0.050000, episode:  917\n",
            "frames: 1925000, reward: 16.600000, loss: 0.000573, epsilon: 0.050000, episode:  917\n",
            "frames: 1926000, reward: 16.300000, loss: 0.000326, epsilon: 0.050000, episode:  918\n",
            "frames: 1927000, reward: 16.300000, loss: 0.000317, epsilon: 0.050000, episode:  918\n",
            "frames: 1928000, reward: 16.400000, loss: 0.000387, epsilon: 0.050000, episode:  919\n",
            "frames: 1929000, reward: 16.400000, loss: 0.000483, epsilon: 0.050000, episode:  919\n",
            "frames: 1930000, reward: 16.300000, loss: 0.000353, epsilon: 0.050000, episode:  920\n",
            "frames: 1931000, reward: 16.300000, loss: 0.000832, epsilon: 0.050000, episode:  920\n",
            "frames: 1932000, reward: 16.300000, loss: 0.000366, epsilon: 0.050000, episode:  920\n",
            "frames: 1933000, reward: 16.000000, loss: 0.000314, epsilon: 0.050000, episode:  921\n",
            "frames: 1934000, reward: 16.000000, loss: 0.000796, epsilon: 0.050000, episode:  921\n",
            "frames: 1935000, reward: 16.200000, loss: 0.000685, epsilon: 0.050000, episode:  922\n",
            "frames: 1936000, reward: 16.200000, loss: 0.000230, epsilon: 0.050000, episode:  922\n",
            "frames: 1937000, reward: 16.700000, loss: 0.000965, epsilon: 0.050000, episode:  923\n",
            "frames: 1938000, reward: 16.700000, loss: 0.000636, epsilon: 0.050000, episode:  923\n",
            "frames: 1939000, reward: 16.200000, loss: 0.000868, epsilon: 0.050000, episode:  924\n",
            "frames: 1940000, reward: 16.200000, loss: 0.001571, epsilon: 0.050000, episode:  924\n",
            "frames: 1941000, reward: 16.200000, loss: 0.000499, epsilon: 0.050000, episode:  924\n",
            "frames: 1942000, reward: 16.300000, loss: 0.000244, epsilon: 0.050000, episode:  925\n",
            "frames: 1943000, reward: 16.300000, loss: 0.000390, epsilon: 0.050000, episode:  925\n",
            "frames: 1944000, reward: 16.900000, loss: 0.000272, epsilon: 0.050000, episode:  926\n",
            "frames: 1945000, reward: 16.900000, loss: 0.000595, epsilon: 0.050000, episode:  926\n",
            "frames: 1946000, reward: 16.800000, loss: 0.000311, epsilon: 0.050000, episode:  927\n",
            "frames: 1947000, reward: 16.800000, loss: 0.000373, epsilon: 0.050000, episode:  927\n",
            "frames: 1948000, reward: 16.800000, loss: 0.000248, epsilon: 0.050000, episode:  928\n",
            "frames: 1949000, reward: 16.800000, loss: 0.000198, epsilon: 0.050000, episode:  928\n",
            "frames: 1950000, reward: 16.800000, loss: 0.001198, epsilon: 0.050000, episode:  928\n",
            "frames: 1951000, reward: 16.800000, loss: 0.000207, epsilon: 0.050000, episode:  929\n",
            "frames: 1952000, reward: 16.800000, loss: 0.000736, epsilon: 0.050000, episode:  929\n",
            "frames: 1953000, reward: 16.700000, loss: 0.000690, epsilon: 0.050000, episode:  930\n",
            "frames: 1954000, reward: 16.700000, loss: 0.000524, epsilon: 0.050000, episode:  930\n",
            "frames: 1955000, reward: 16.500000, loss: 0.000425, epsilon: 0.050000, episode:  931\n",
            "frames: 1956000, reward: 16.500000, loss: 0.000361, epsilon: 0.050000, episode:  931\n",
            "frames: 1957000, reward: 16.400000, loss: 0.000291, epsilon: 0.050000, episode:  932\n",
            "frames: 1958000, reward: 16.400000, loss: 0.000317, epsilon: 0.050000, episode:  932\n",
            "frames: 1959000, reward: 16.400000, loss: 0.000339, epsilon: 0.050000, episode:  932\n",
            "frames: 1960000, reward: 15.700000, loss: 0.000670, epsilon: 0.050000, episode:  933\n",
            "frames: 1961000, reward: 15.700000, loss: 0.000400, epsilon: 0.050000, episode:  933\n",
            "frames: 1962000, reward: 15.800000, loss: 0.000743, epsilon: 0.050000, episode:  934\n",
            "frames: 1963000, reward: 15.800000, loss: 0.000456, epsilon: 0.050000, episode:  934\n",
            "frames: 1964000, reward: 16.100000, loss: 0.000677, epsilon: 0.050000, episode:  935\n",
            "frames: 1965000, reward: 16.100000, loss: 0.001114, epsilon: 0.050000, episode:  935\n",
            "frames: 1966000, reward: 16.100000, loss: 0.000335, epsilon: 0.050000, episode:  935\n",
            "frames: 1967000, reward: 15.600000, loss: 0.000232, epsilon: 0.050000, episode:  936\n",
            "frames: 1968000, reward: 15.600000, loss: 0.000421, epsilon: 0.050000, episode:  936\n",
            "frames: 1969000, reward: 15.500000, loss: 0.000401, epsilon: 0.050000, episode:  937\n",
            "frames: 1970000, reward: 15.500000, loss: 0.000298, epsilon: 0.050000, episode:  937\n",
            "frames: 1971000, reward: 15.800000, loss: 0.000759, epsilon: 0.050000, episode:  938\n",
            "frames: 1972000, reward: 15.800000, loss: 0.000177, epsilon: 0.050000, episode:  938\n",
            "frames: 1973000, reward: 15.800000, loss: 0.001805, epsilon: 0.050000, episode:  939\n",
            "frames: 1974000, reward: 15.800000, loss: 0.000353, epsilon: 0.050000, episode:  939\n",
            "frames: 1975000, reward: 15.600000, loss: 0.000280, epsilon: 0.050000, episode:  940\n",
            "frames: 1976000, reward: 15.600000, loss: 0.000304, epsilon: 0.050000, episode:  940\n",
            "frames: 1977000, reward: 16.200000, loss: 0.000257, epsilon: 0.050000, episode:  941\n",
            "frames: 1978000, reward: 16.200000, loss: 0.000665, epsilon: 0.050000, episode:  941\n",
            "frames: 1979000, reward: 16.200000, loss: 0.000441, epsilon: 0.050000, episode:  942\n",
            "frames: 1980000, reward: 16.200000, loss: 0.000390, epsilon: 0.050000, episode:  942\n",
            "frames: 1981000, reward: 16.600000, loss: 0.000428, epsilon: 0.050000, episode:  943\n",
            "frames: 1982000, reward: 16.600000, loss: 0.000715, epsilon: 0.050000, episode:  943\n",
            "frames: 1983000, reward: 16.600000, loss: 0.000833, epsilon: 0.050000, episode:  944\n",
            "frames: 1984000, reward: 16.600000, loss: 0.000605, epsilon: 0.050000, episode:  944\n",
            "frames: 1985000, reward: 16.600000, loss: 0.000311, epsilon: 0.050000, episode:  944\n",
            "frames: 1986000, reward: 16.500000, loss: 0.000215, epsilon: 0.050000, episode:  945\n",
            "frames: 1987000, reward: 16.500000, loss: 0.000218, epsilon: 0.050000, episode:  945\n",
            "frames: 1988000, reward: 16.900000, loss: 0.003287, epsilon: 0.050000, episode:  946\n",
            "frames: 1989000, reward: 16.900000, loss: 0.001033, epsilon: 0.050000, episode:  946\n",
            "frames: 1990000, reward: 16.800000, loss: 0.003101, epsilon: 0.050000, episode:  947\n",
            "frames: 1991000, reward: 16.800000, loss: 0.000310, epsilon: 0.050000, episode:  947\n",
            "frames: 1992000, reward: 16.800000, loss: 0.000337, epsilon: 0.050000, episode:  947\n",
            "frames: 1993000, reward: 16.500000, loss: 0.000652, epsilon: 0.050000, episode:  948\n",
            "frames: 1994000, reward: 16.300000, loss: 0.000347, epsilon: 0.050000, episode:  949\n",
            "frames: 1995000, reward: 16.300000, loss: 0.000230, epsilon: 0.050000, episode:  949\n",
            "frames: 1996000, reward: 16.300000, loss: 0.000269, epsilon: 0.050000, episode:  949\n",
            "frames: 1997000, reward: 16.900000, loss: 0.000628, epsilon: 0.050000, episode:  950\n",
            "frames: 1998000, reward: 16.900000, loss: 0.000261, epsilon: 0.050000, episode:  950\n",
            "frames: 1999000, reward: 16.700000, loss: 0.001040, epsilon: 0.050000, episode:  951\n"
          ]
        }
      ],
      "source": [
        "# if __name__ == '__main__':\n",
        "\n",
        "# Training DQN in PongNoFrameskip-v4\n",
        "env = gym.make('PongNoFrameskip-v4')\n",
        "env = AtariPreprocessing(env,\n",
        "                         scale_obs=False,\n",
        "                         terminal_on_life_loss=True,\n",
        "                         )\n",
        "env = FrameStack(env, num_stack=4)\n",
        "\n",
        "gamma = 0.99\n",
        "epsilon_max = 1\n",
        "epsilon_min = 0.05\n",
        "eps_decay = 30000\n",
        "frames = 2000000\n",
        "USE_CUDA = False\n",
        "learning_rate = 2e-4\n",
        "max_buff = 100000\n",
        "update_tar_interval = 1000\n",
        "batch_size = 32\n",
        "print_interval = 1000\n",
        "log_interval = 1000\n",
        "learning_start = 10000\n",
        "win_reward = 18     # Pong-v4\n",
        "win_break = True\n",
        "\n",
        "action_space = env.action_space\n",
        "action_dim = env.action_space.n\n",
        "state_dim = env.observation_space.shape[1]\n",
        "state_channel = env.observation_space.shape[0]\n",
        "agent = DQNAgent(in_channels = state_channel, \n",
        "                 action_space = action_space, \n",
        "                 USE_CUDA = USE_CUDA, \n",
        "                 lr = learning_rate,\n",
        "                 memory_size = max_buff)\n",
        "\n",
        "frame, _ = env.reset()\n",
        "\n",
        "episode_reward = 0\n",
        "all_rewards = []\n",
        "losses = []\n",
        "episode_num = 0\n",
        "is_win = False\n",
        "# tensorboard\n",
        "summary_writer = SummaryWriter(log_dir = \"DQN_stackframe\", comment= \"good_makeatari\")\n",
        "\n",
        "# e-greedy decay\n",
        "epsilon_by_frame = lambda frame_idx: epsilon_min + (epsilon_max - epsilon_min) * math.exp(\n",
        "            -1. * frame_idx / eps_decay)\n",
        "# plt.plot([epsilon_by_frame(i) for i in range(10000)])\n",
        "\n",
        "for i in range(frames):\n",
        "    epsilon = epsilon_by_frame(i)\n",
        "    state_tensor = agent.observe(frame)\n",
        "    action = agent.act(state_tensor, epsilon)\n",
        "\n",
        "    next_frame, reward, terminated, truncated, _ = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    \n",
        "    episode_reward += reward\n",
        "    agent.memory_buffer.push(frame, action, reward, next_frame, done)\n",
        "    frame = next_frame\n",
        "\n",
        "    loss = 0\n",
        "    if agent.memory_buffer.size() >= learning_start:\n",
        "        loss = agent.learn_from_experience(batch_size)\n",
        "        losses.append(loss)\n",
        "\n",
        "    if i % print_interval == 0:\n",
        "        print(\"frames: %5d, reward: %5f, loss: %4f, epsilon: %5f, episode: %4d\" % (i, np.mean(all_rewards[-10:]), loss, epsilon, episode_num))\n",
        "        summary_writer.add_scalar(\"Temporal Difference Loss\", loss, i)\n",
        "        summary_writer.add_scalar(\"Mean Reward\", np.mean(all_rewards[-10:]), i)\n",
        "        summary_writer.add_scalar(\"Epsilon\", epsilon, i)\n",
        "\n",
        "    if i % update_tar_interval == 0:\n",
        "        agent.DQN_target.load_state_dict(agent.DQN.state_dict())\n",
        "\n",
        "    if done:\n",
        "\n",
        "        frame, _ = env.reset()\n",
        "\n",
        "        all_rewards.append(episode_reward)\n",
        "        episode_reward = 0\n",
        "        episode_num += 1\n",
        "        avg_reward = float(np.mean(all_rewards[-100:]))\n",
        "\n",
        "summary_writer.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "下面我们使用matplotlib库画出游戏得分和loss曲线。\n",
        "\n",
        "从左边的图我们可以看到，DQN智能体在玩了200把游戏后开始快速学习，大概在300把游戏之后学习成功（达到20+分）。\n",
        "\n",
        "从右边的图我们可以看到，在表现达到最优之后，Loss还是在不断减小。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_ekyfJGaNroU",
        "outputId": "bbb8cf5a-a90b-4da1-e35d-6b5c224b911b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_training(frame_idx, rewards, losses):\n",
        "    clear_output(True)\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(131)\n",
        "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
        "    plt.plot(rewards)\n",
        "    plt.subplot(132)\n",
        "    plt.title('loss')\n",
        "    plt.plot(losses)\n",
        "    plt.show()\n",
        "\n",
        "plot_training(i, all_rewards, losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeaTvisTCI1K"
      },
      "source": [
        "## 总结\n",
        "\n",
        "感想就是，总结强化学习需要的元素相对容易，真正实现的时候很麻烦，尤其是当模型学不会的时候，你会怀疑是模型的问题还是代码有bug，不要犹豫，是代码有bug。\n",
        "\n",
        "训练模型收敛大概需要2百万步，差不多要24小时+，比较慢，但是很欣慰的是Pong在atari game中是最容易实现的游戏，没有bug的话可以在10小时以内收敛，很良心。\n",
        "\n",
        "DQN算法非常经典，值得学习，建议大家都自己实现一遍。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
